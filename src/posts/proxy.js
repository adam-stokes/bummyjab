{
  "posts": [
    {
      "body": "### Place this in your ~/.muttrc\n\n```\nmy_hdr From: user@example.com (Joe Blow)\nset spoolfile=imaps://mail.server.com/INBOX\nset folder=imaps://mail.server.com/\nset imap_user=username\nset move=no\nset mail_check=60\nset timeout=15\n```\n",
      "date": "2005-07-24T20:00:59",
      "title": "Configuring imap with mutt",
      "tags": [
        "mutt",
        "email"
      ],
      "author": "Adam Stokes",
      "path": "configuring-imap-with-mutt",
      "compiled": "<h3 id=\"place-this-in-your-muttrc\">Place this in your ~/.muttrc</h3>\n<pre><code>my_hdr From: user@example.com (Joe Blow)\n<span class=\"hljs-keyword\">set</span> spoolfile=imaps:<span class=\"hljs-comment\">//mail.server.com/INBOX</span>\n<span class=\"hljs-keyword\">set</span> folder=imaps:<span class=\"hljs-comment\">//mail.server.com/</span>\n<span class=\"hljs-keyword\">set</span> imap_user=username\n<span class=\"hljs-keyword\">set</span> <span class=\"hljs-keyword\">move</span>=<span class=\"hljs-keyword\">no</span>\n<span class=\"hljs-keyword\">set</span> mail_check=60\n<span class=\"hljs-keyword\">set</span> timeout=15\n</code></pre>"
    },
    {
      "body": "Just thought I would post some things I find helpful when working with  \n VIM. Remember if you are running Fedora Core you can install VIM with  \n the following command: Also for those curious, here is my vimrc file.\n\n      yum install vim-enhanced\n\nThat should pick up the dependencies as necessary.\n\n**Setting line numbers and word wrap**  \n Ok to get started I like to have line numbers and no word wrapping in  \n my code. Lets first create our rc file for vim (**_~/.vimrc_**)\n\nNow we are going to add the following 2 lines for the above:\n\n      set nu!\n      set wrap!\n\n**Mapping key binds**\n\nI like to use buffer windows for editing several files and so I need  \n a quick way of switching from windows to windows.\n\n      map &lt;F9&gt; &lt;esc&gt;:bprevious&lt;cr&gt;\n      map &lt;F10&gt; &lt;esc&gt;:bnext&lt;cr&gt;\n      imap &lt;F9&gt; &lt;esc&gt;:bprevious&lt;cr&gt;\n      imap &lt;F10&gt; &lt;esc&gt;:bnext&lt;cr&gt;\n\n**_imap_** is for switching buffers in insert mode.\n\n**General commands and usage within VIM**\n\nBasically from here on all commands can be typed while in VIM by  \n starting the command with ':', for example,\n\n      :color elflord\n\nThis will force VIM to set a general color and for syntax highlighting  \n purposes.\n\n**Simple search and replace**\n\nSearch and replace is fairly straight forward. Normally I will  \n just start at the beginning of a document and search the whole  \n thing replacing as necessary. To do so type the following:\n\n      :%s/word-to-search/replace-with/g\n\nNow if you wish to just search a line and replace whats in the line:\n\n      :s/word-to-search/replace-with/g\n\nPlease note that it is important to end the search string with **/g**.\n\n**Commenting a section of text anywhere in the file**\n\nFirst mark the top of the section you wish to comment out by moving  \n your cursor to that section and type **ma**. Next move to the end  \n of the section you wish to comment and type **mb**. Finally get into  \n command mode by hitting **:** and comment that block of text by  \n typing:\n\n      :'a,'b s/^/#/g\n\nYou may also do this in visual mode by hitting **v** and hilighting  \n the lines you wish to comment out and typing:\n\n      :'a,'b s/^/#/g\n\n**Turning tabs into spaces**\n\n      :set expandtab\n\nTo convert all existing tabs to spaces\n\n      :retab\n\nBelow are links I used for reference:\n\n[vim-tips](\"http://www.rayninfo.co.uk/vimtips.html\")\n\n[vim-survival-guide](\"http://www.nuxified.org/vi_survival_guide\")\n",
      "date": "2005-08-22T20:00:59",
      "title": "VIM tips",
      "tags": [
        "vim"
      ],
      "author": "Adam Stokes",
      "path": "vim-tips",
      "compiled": "<p>Just thought I would post some things I find helpful when working with<br> VIM. Remember if you are running Fedora Core you can install VIM with<br> the following command: Also for those curious, here is my vimrc file.</p>\n<pre><code>  yum <span class=\"hljs-keyword\">install</span> vim-enhanced\n</code></pre><p>That should pick up the dependencies as necessary.</p>\n<p><strong>Setting line numbers and word wrap</strong><br> Ok to get started I like to have line numbers and no word wrapping in<br> my code. Lets first create our rc file for vim (<strong><em>~/.vimrc</em></strong>)</p>\n<p>Now we are going to add the following 2 lines for the above:</p>\n<pre><code>  <span class=\"hljs-built_in\">set</span> nu!\n  <span class=\"hljs-built_in\">set</span> <span class=\"hljs-operator\">wrap</span>!\n</code></pre><p><strong>Mapping key binds</strong></p>\n<p>I like to use buffer windows for editing several files and so I need<br> a quick way of switching from windows to windows.</p>\n<pre><code>  <span class=\"hljs-built_in\">map</span> <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;F9<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>; <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;esc<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;:bprevious<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;cr<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;\n  <span class=\"hljs-built_in\">map</span> <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;F10<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>; <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;esc<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;:bnext<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;cr<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;\n  imap <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;F9<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>; <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;esc<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;:bprevious<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;cr<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;\n  imap <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;F10<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>; <span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;esc<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;:bnext<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">lt</span>;cr<span class=\"hljs-subst\">&amp;</span><span class=\"hljs-literal\">gt</span>;\n</code></pre><p><strong><em>imap</em></strong> is for switching buffers in insert mode.</p>\n<p><strong>General commands and usage within VIM</strong></p>\n<p>Basically from here on all commands can be typed while in VIM by<br> starting the command with &#39;:&#39;, for example,</p>\n<pre><code>  <span class=\"hljs-pseudo\">:color</span> <span class=\"hljs-tag\">elflord</span>\n</code></pre><p>This will force VIM to set a general color and for syntax highlighting<br> purposes.</p>\n<p><strong>Simple search and replace</strong></p>\n<p>Search and replace is fairly straight forward. Normally I will<br> just start at the beginning of a document and search the whole<br> thing replacing as necessary. To do so type the following:</p>\n<pre><code>  <span class=\"hljs-symbol\">:%s/word-to-search/replace-with/g</span>\n</code></pre><p>Now if you wish to just search a line and replace whats in the line:</p>\n<pre><code>  <span class=\"hljs-symbol\">:s/word-to-search/replace-with/g</span>\n</code></pre><p>Please note that it is important to end the search string with <strong>/g</strong>.</p>\n<p><strong>Commenting a section of text anywhere in the file</strong></p>\n<p>First mark the top of the section you wish to comment out by moving<br> your cursor to that section and type <strong>ma</strong>. Next move to the end<br> of the section you wish to comment and type <strong>mb</strong>. Finally get into<br> command mode by hitting <strong>:</strong> and comment that block of text by<br> typing:</p>\n<pre><code>  :<span class=\"hljs-string\">'a,'</span>b s<span class=\"hljs-regexp\">/^/</span><span class=\"hljs-comment\">#/g</span>\n</code></pre><p>You may also do this in visual mode by hitting <strong>v</strong> and hilighting<br> the lines you wish to comment out and typing:</p>\n<pre><code>  :<span class=\"hljs-string\">'a,'</span>b s<span class=\"hljs-regexp\">/^/</span><span class=\"hljs-comment\">#/g</span>\n</code></pre><p><strong>Turning tabs into spaces</strong></p>\n<pre><code>  :<span class=\"hljs-keyword\">set</span> expandtab\n</code></pre><p>To convert all existing tabs to spaces</p>\n<pre><code>  <span class=\"hljs-attribute\">:retab</span>\n</code></pre><p>Below are links I used for reference:</p>\n<p><a href=\"&quot;http://www.rayninfo.co.uk/vimtips.html&quot;\">vim-tips</a></p>\n<p><a href=\"&quot;http://www.nuxified.org/vi_survival_guide&quot;\">vim-survival-guide</a></p>\n"
    },
    {
      "body": "If you run into errors related to this :\n\n```\nmake[1]: Entering directory `/usr/src/kernels/2.6.18-1.2798.fc6-i686'\nCC [M]  /tmp/vmware-config1/vmnet-only/driver.o\nCC [M]  /tmp/vmware-config1/vmnet-only/hub.o\nCC [M]  /tmp/vmware-config1/vmnet-only/userif.o\nCC [M]  /tmp/vmware-config1/vmnet-only/netif.o\nCC [M]  /tmp/vmware-config1/vmnet-only/bridge.o\nCC [M]  /tmp/vmware-config1/vmnet-only/procfs.o\n/tmp/vmware-config1/vmnet-only/procfs.c:33:26: error: linux/config.h: No such file or directory\nmake[2]: *** [/tmp/vmware-config1/vmnet-only/procfs.o] Error 1\nmake[1]: *** [_module_/tmp/vmware-config1/vmnet-only] Error 2\nmake[1]: Leaving directory `/usr/src/kernels/2.6.18-1.2798.fc6-i686'\nmake: *** [vmnet.ko] Error 2\nmake: Leaving directory `/tmp/vmware-config1/vmnet-only 'Unable to build the vmnet module.\n```\n\nThat is because config.h does not exist and is being deprecated in 2.6.18-1.2798.fc6 and beyond.To solve this :\n\n```\n# touch /usr/src/kernels/2.6.18-1.2798.fc6-i686/include/linux/config.h\n```\n\nOnce complete your VMware server should successfully complete vmware-config.pl and you can continue using this product.If it stills fails please see this thread for other ideas :  http://www.vmware.com/community/thread.jspa?messageID=501043&amp;#501043\n",
      "date": "2006-11-08T19:00:59",
      "title": "VMWare Server installed as host on FC6",
      "tags": [
        "vmware"
      ],
      "author": "Adam Stokes",
      "path": "vmware-server-installed-as-host-on-fc6",
      "compiled": "<p>If you run into errors related to this :</p>\n<pre><code>make[1]: Entering directory `/usr/src/kernels/2.6.18-1.2798.fc6-i686'\n<span class=\"hljs-keyword\">CC</span> [<span class=\"hljs-keyword\">M</span>]  /tmp/vmware-config1/vmnet-only/driver.o\n<span class=\"hljs-keyword\">CC</span> [<span class=\"hljs-keyword\">M</span>]  /tmp/vmware-config1/vmnet-only/hub.o\n<span class=\"hljs-keyword\">CC</span> [<span class=\"hljs-keyword\">M</span>]  /tmp/vmware-config1/vmnet-only/userif.o\n<span class=\"hljs-keyword\">CC</span> [<span class=\"hljs-keyword\">M</span>]  /tmp/vmware-config1/vmnet-only/netif.o\n<span class=\"hljs-keyword\">CC</span> [<span class=\"hljs-keyword\">M</span>]  /tmp/vmware-config1/vmnet-only/bridge.o\n<span class=\"hljs-keyword\">CC</span> [<span class=\"hljs-keyword\">M</span>]  /tmp/vmware-config1/vmnet-only/procfs.o\n/tmp/vmware-config1/vmnet-only/procfs.c:33:26: <span class=\"hljs-keyword\">error</span>: linux/config.<span class=\"hljs-keyword\">h</span>: <span class=\"hljs-keyword\">No</span> such <span class=\"hljs-keyword\">file</span> or directory\nmake[2]: *** [/tmp/vmware-config1/vmnet-only/procfs.o] <span class=\"hljs-keyword\">Error</span> 1\nmake[1]: *** [_module_/tmp/vmware-config1/vmnet-only] <span class=\"hljs-keyword\">Error</span> 2\nmake[1]: Leaving directory `/usr/src/kernels/2.6.18-1.2798.fc6-i686'\nmake: *** [vmnet.ko] <span class=\"hljs-keyword\">Error</span> 2\nmake: Leaving directory `/tmp/vmware-config1/vmnet-only 'Unable to build the vmnet module.\n</code></pre><p>That is because config.h does not exist and is being deprecated in 2.6.18-1.2798.fc6 and beyond.To solve this :</p>\n<pre><code># touch <span class=\"hljs-regexp\">/usr/</span>src<span class=\"hljs-regexp\">/kernels/</span><span class=\"hljs-number\">2.6</span>.<span class=\"hljs-number\">18</span>-<span class=\"hljs-number\">1.2798</span>.fc6-i686<span class=\"hljs-regexp\">/include/</span>linux<span class=\"hljs-regexp\">/config.h</span>\n</code></pre><p>Once complete your VMware server should successfully complete vmware-config.pl and you can continue using this product.If it stills fails please see this thread for other ideas :  <a href=\"http://www.vmware.com/community/thread.jspa?messageID=501043&amp;#501043\">http://www.vmware.com/community/thread.jspa?messageID=501043&amp;#501043</a></p>\n"
    },
    {
      "body": "<p>Using a T61 or any IBM laptop that has the fingerprint scanner install the package thinkfinger :</p>\n<pre class=&#34;prettyprint&#34;>\n# yum install thinkfinger\n</pre>\n<p>Add your user:</p>\n<pre class=&#34;prettyprint&#34;>\n# su -\n# tf-tool --add-user adam\n</pre>\n<p>Swipe your finger 3 times.</p>\n<p>Alter /etc/pam.d/system-auth to include the think_finger pam module. Mine looks like :</p>\n<pre class=&#34;prettyprint&#34;>\n#%PAM-1.0# This file is auto-generated.\n# User changes will be destroyed the next time authconfig is run.\nauth        required      pam_env.so\nauth        sufficient    pam_thinkfinger.so\nauth        sufficient    pam_unix.so nullok try_first_pass\nauth        requisite     pam_succeed_if.so uid >= 500 quiet\nauth        required      pam_deny.so\naccount     required      pam_unix.so\naccount     sufficient    pam_localuser.so\naccount     sufficient    pam_succeed_if.so uid \naccount     required      pam_permit.so\npassword    requisite     pam_cracklib.so try_first_pass retry=3\npassword    sufficient    pam_unix.so md5 shadow nullok try_first_pass use_authtok\npassword    required      pam_deny.so\nsession     optional      pam_keyinit.so revoke\nsession     required      pam_limits.so\nsession     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid\nsession     required      pam_unix.so\n</pre>\n<p>Once complete logout of Gnome, and attempt to login by clicking or typing your associated user name and then swipe your finger :)</p>\n",
      "date": "2008-02-20T00:00:59",
      "title": "Fedora 8, Thinkpad T61, fingerprint authentication",
      "tags": [],
      "author": "Adam Stokes",
      "path": "fedora-8-thinkpad-t61-fingerprint-authentication",
      "compiled": "<p>Using a T61 or any IBM laptop that has the fingerprint scanner install the package thinkfinger :</p>\n<pre class=&#34;prettyprint&#34;>\n# yum install thinkfinger\n</pre>\n<p>Add your user:</p>\n<pre class=&#34;prettyprint&#34;>\n# su -\n# tf-tool --add-user adam\n</pre>\n<p>Swipe your finger 3 times.</p>\n<p>Alter /etc/pam.d/system-auth to include the think_finger pam module. Mine looks like :</p>\n<pre class=&#34;prettyprint&#34;>\n#%PAM-1.0# This file is auto-generated.\n# User changes will be destroyed the next time authconfig is run.\nauth        required      pam_env.so\nauth        sufficient    pam_thinkfinger.so\nauth        sufficient    pam_unix.so nullok try_first_pass\nauth        requisite     pam_succeed_if.so uid &gt;= 500 quiet\nauth        required      pam_deny.so\naccount     required      pam_unix.so\naccount     sufficient    pam_localuser.so\naccount     sufficient    pam_succeed_if.so uid \naccount     required      pam_permit.so\npassword    requisite     pam_cracklib.so try_first_pass retry=3\npassword    sufficient    pam_unix.so md5 shadow nullok try_first_pass use_authtok\npassword    required      pam_deny.so\nsession     optional      pam_keyinit.so revoke\nsession     required      pam_limits.so\nsession     [success=1 default=ignore] pam_succeed_if.so service in crond quiet use_uid\nsession     required      pam_unix.so\n</pre>\n<p>Once complete logout of Gnome, and attempt to login by clicking or typing your associated user name and then swipe your finger :)</p>\n"
    },
    {
      "body": "<p>One of the things with matahari is that we didn&#8217;t want our agents to be tied down to just 1 broker. With qpid we can setup broker federation and squash any of the use case scenarios that may involve differences in location, etc.</p>\n<p>To start setup 2-3 brokers, in this writeup there are 2 brokers running on one machine and a 3rd on a second machine.</p>\n<p>BrokerA has ip 192.168.1.3 and a port 10001<br />\nBrokerB has ip 192.168.1.3 and a port 10002<br />\nBrokerC has ip 192.168.1.5 and a port 10001</p>\n<p>Startup all three brokers and for the 2 that are on the same machine some options will need to be set</p>\n<pre class=&#34;prettyprint&#34;>\n# BrokerA\n# qpidd -p 10001 --pid-dir /tmp/brokera --data-dir /tmp/brokera --auth no\n# BrokerB\n# qpidd -p 10002 --pid-dir /tmp/brokerb --data-dir /tmp/brokerb --auth no\n# BrokerC\n# qpidd -p 10001 --pid-dir /tmp/brokerc --data-dir /tmp/brokerc --auth no\n</pre>\n<p>Now we need to link all 3 together (federated) into a broker exchange. To do so run the following on any of the machines with brokers to be linked or a machine with no broker at all. The next tools being listed do not require a broker to be running in order to network the brokers together.</p>\n<p>qpid-route is the utility being used and for simplicities sake we will be setting up dynamic routes (described in section 1.4.3.2 of the previous link)</p>\n<pre class=&#34;prettyprint&#34;>\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.3:10002 amq.direct\n# qpid-route dynamic add 192.168.1.3:10002 192.168.1.3:10001 amq.direct\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.5:10001 amq.direct\n# qpid-route dynamic add 192.168.1.5:10001 192.168.1.3:10001 amq.direct\n\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.3:10002 qmf.default.direct\n# qpid-route dynamic add 192.168.1.3:10002 192.168.1.3:10001 qmf.default.direct\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.5:10001 qmf.default.direct\n# qpid-route dynamic add 192.168.1.5:10001 192.168.1.3:10001 qmf.default.direct\n\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.3:10002 qmf.default.topic\n# qpid-route dynamic add 192.168.1.3:10002 192.168.1.3:10001 qmf.default.topic\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.5:10001 qmf.default.topic\n# qpid-route dynamic add 192.168.1.5:10001 192.168.1.3:10001 qmf.default.topic\n</pre>\n<p>Now I know this looks like a lot of repetition but the above is required since we are creating a bidirectional route. Looking carefully we see that the brokers are being flipped an added to the same exchange.</p>\n<p>Speaking of broker exchange you&#8217;ll notice amq.direct, qmf.default.direct, qmf.default.topic. These exchanges are the default exchanges that need to be supported in any AMQP broker. To get a better idea of these routing algorithms there is a blogpost that covers it pretty clearly.</p>\n<p>Moving on we need to do a quick check on the topology which can be accomplished with the following</p>\n<pre class=&#34;prettyprint&#34;>\n# qpid-route route map 192.168.13:10001\n\nFinding Linked Brokers:\n192.168.1.3:10001... Ok\n192.168.1.5:10001... Ok\n192.168.1.3:10002... Ok\n\nDynamic Routes:\n\nExchange qmf.default.topic:\n192.168.1.5:10001 <=> 192.168.1.3:10001\n192.168.1.3:10002 <=> 192.168.1.3:10001\n\nExchange qmf.default.direct:\n192.168.1.5:10001 <=> 192.168.1.3:10001\n192.168.1.3:10002 <=> 192.168.1.3:10001\n\nExchange amq.direct:\n192.168.1.5:10001 <=> 192.168.1.3:10001\n192.168.1.3:10002 <=> 192.168.1.3:10001\n\nStatic Routes:\nnone found\n</pre>\n<p>The brokers are now federated (networked together) so lets do something useful. We will connect one of matahari&#8217;s core agent to any of the brokers on both machines.</p>\n<pre class=&#34;prettyprint&#34;>\n# matahari-hostd --port 10001 --broker 192.168.1.5\n\n# matahari-hostd --port 10001 --broker 192.168.1.3\n</pre>\n<p>Above we&#8217;ve just connected the agent on one machine to the broker on the other and vice versa. So now if we bring up qpid-tool on BrokerB we should see that 2 agents are connected within this broker network and we will be able to interact with those agents no matter where we are.</p>\n<pre class=&#34;prettyprint&#34;>\n# qpid-tool 192.168.1.3:10002\n\nqpid: agents\nAgent Name                                                 Label QMF version\n1.0 BrokerAgent                                            QMFv2\n1.redhat.com:matahari:4d3d4442-562a-4514-a639-b366ef17e306 QMFv2 Agent 2\n1.redhat.com:matahari:fb7584d4-8d10-4cea-ab30-ae4afaea1060 QMFv2 Agent 2\n</pre>\n<p>With both agents connected we can access their methods and pull some data from it.</p>\n<pre class=&#34;prettyprint&#34;>\n    qpid: list host\n    Object Summary:\n       ID   Created   Destroyed  Index\n       =====================================================\n       161  22:03:47  -          com.redhat.matahari:host:\n       101  21:05:51  -          com.redhat.matahari:host:\n\n    qpid: show 161\n    Object of type: com.redhat.matahari:host:_data(7297d90c-5e2a-557c-7b58-90cdd4d916f2)\n       Attribute         161\n       ===================================================================\n       uuid              ec742c182da05427605f96b300000014\n       hostname          im.gangstar.com\n       is_virtual        False\n       operating_system  Linux (2.6.34.7-61.fc13.i686)\n       memory            3057352\n       swap              2047996\n       arch              i686\n       hypervisor       \n       platform          32\n       processors        2\n       cores             4\n       model             Intel(R) Core(TM)2 Duo CPU     T9600  @ 2.80GHz\n       last_updated_seq  83\n       last_updated      Fri Nov 12 22:10:37 2010\n       load_average_1    0.000000\n       load_average_5    0.020000\n       load_average_15   0.000000\n       memFree           186788\n       swapFree          1987552\n       procTotal         394\n       procRunning       1\n\n    qpid: show 101\n    Object of type: com.redhat.matahari:host:_data(7297d90c-5e2a-557c-7b58-90cdd4d916f2)\n       Attribute         101\n       ===================================================================\n       uuid              3d4c71ac60c0b113d8ce73b700000016\n       hostname         im.gangster-twice.com\n       is_virtual        False\n       operating_system  Linux (2.6.34.7-61.fc13.i686)\n       memory            2036688\n       swap              4095996\n       arch              i686\n       hypervisor       \n       platform          32\n       processors        2\n       cores             4\n       model             Intel(R) Core(TM)2 Duo CPU     T7500  @ 2.20GHz\n       last_updated_seq  795\n       last_updated      Fri Nov 12 22:12:03 2010\n       load_average_1    0.120000\n       load_average_5    0.120000\n       load_average_15   0.110000\n       memFree           168912\n       swapFree          4091164\n       procTotal         384\n       procRunning       4\n</pre>\n<p>Pretty simple and really cool :D</p>\n",
      "date": "2010-02-12T00:00:59",
      "title": "Setup a broker federation in qpid",
      "tags": [],
      "author": "Adam Stokes",
      "path": "setup-a-broker-federation-in-qpid",
      "compiled": "<p>One of the things with matahari is that we didn&#8217;t want our agents to be tied down to just 1 broker. With qpid we can setup broker federation and squash any of the use case scenarios that may involve differences in location, etc.</p>\n<p>To start setup 2-3 brokers, in this writeup there are 2 brokers running on one machine and a 3rd on a second machine.</p>\n<p>BrokerA has ip 192.168.1.3 and a port 10001<br />\nBrokerB has ip 192.168.1.3 and a port 10002<br />\nBrokerC has ip 192.168.1.5 and a port 10001</p>\n<p>Startup all three brokers and for the 2 that are on the same machine some options will need to be set</p>\n<pre class=&#34;prettyprint&#34;>\n# BrokerA\n# qpidd -p 10001 --pid-dir /tmp/brokera --data-dir /tmp/brokera --auth no\n# BrokerB\n# qpidd -p 10002 --pid-dir /tmp/brokerb --data-dir /tmp/brokerb --auth no\n# BrokerC\n# qpidd -p 10001 --pid-dir /tmp/brokerc --data-dir /tmp/brokerc --auth no\n</pre>\n<p>Now we need to link all 3 together (federated) into a broker exchange. To do so run the following on any of the machines with brokers to be linked or a machine with no broker at all. The next tools being listed do not require a broker to be running in order to network the brokers together.</p>\n<p>qpid-route is the utility being used and for simplicities sake we will be setting up dynamic routes (described in section 1.4.3.2 of the previous link)</p>\n<pre class=&#34;prettyprint&#34;>\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.3:10002 amq.direct\n# qpid-route dynamic add 192.168.1.3:10002 192.168.1.3:10001 amq.direct\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.5:10001 amq.direct\n# qpid-route dynamic add 192.168.1.5:10001 192.168.1.3:10001 amq.direct\n\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.3:10002 qmf.default.direct\n# qpid-route dynamic add 192.168.1.3:10002 192.168.1.3:10001 qmf.default.direct\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.5:10001 qmf.default.direct\n# qpid-route dynamic add 192.168.1.5:10001 192.168.1.3:10001 qmf.default.direct\n\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.3:10002 qmf.default.topic\n# qpid-route dynamic add 192.168.1.3:10002 192.168.1.3:10001 qmf.default.topic\n# qpid-route dynamic add 192.168.1.3:10001 192.168.1.5:10001 qmf.default.topic\n# qpid-route dynamic add 192.168.1.5:10001 192.168.1.3:10001 qmf.default.topic\n</pre>\n<p>Now I know this looks like a lot of repetition but the above is required since we are creating a bidirectional route. Looking carefully we see that the brokers are being flipped an added to the same exchange.</p>\n<p>Speaking of broker exchange you&#8217;ll notice amq.direct, qmf.default.direct, qmf.default.topic. These exchanges are the default exchanges that need to be supported in any AMQP broker. To get a better idea of these routing algorithms there is a blogpost that covers it pretty clearly.</p>\n<p>Moving on we need to do a quick check on the topology which can be accomplished with the following</p>\n<pre class=&#34;prettyprint&#34;>\n# qpid-route route map 192.168.13:10001\n\nFinding Linked Brokers:\n192.168.1.3:10001... Ok\n192.168.1.5:10001... Ok\n192.168.1.3:10002... Ok\n\nDynamic Routes:\n\nExchange qmf.default.topic:\n192.168.1.5:10001 &lt;=&gt; 192.168.1.3:10001\n192.168.1.3:10002 &lt;=&gt; 192.168.1.3:10001\n\nExchange qmf.default.direct:\n192.168.1.5:10001 &lt;=&gt; 192.168.1.3:10001\n192.168.1.3:10002 &lt;=&gt; 192.168.1.3:10001\n\nExchange amq.direct:\n192.168.1.5:10001 &lt;=&gt; 192.168.1.3:10001\n192.168.1.3:10002 &lt;=&gt; 192.168.1.3:10001\n\nStatic Routes:\nnone found\n</pre>\n<p>The brokers are now federated (networked together) so lets do something useful. We will connect one of matahari&#8217;s core agent to any of the brokers on both machines.</p>\n<pre class=&#34;prettyprint&#34;>\n# matahari-hostd --port 10001 --broker 192.168.1.5\n\n# matahari-hostd --port 10001 --broker 192.168.1.3\n</pre>\n<p>Above we&#8217;ve just connected the agent on one machine to the broker on the other and vice versa. So now if we bring up qpid-tool on BrokerB we should see that 2 agents are connected within this broker network and we will be able to interact with those agents no matter where we are.</p>\n<pre class=&#34;prettyprint&#34;>\n# qpid-tool 192.168.1.3:10002\n\nqpid: agents\nAgent Name                                                 Label QMF version\n1.0 BrokerAgent                                            QMFv2\n1.redhat.com:matahari:4d3d4442-562a-4514-a639-b366ef17e306 QMFv2 Agent 2\n1.redhat.com:matahari:fb7584d4-8d10-4cea-ab30-ae4afaea1060 QMFv2 Agent 2\n</pre>\n<p>With both agents connected we can access their methods and pull some data from it.</p>\n<pre class=&#34;prettyprint&#34;>\n    qpid: list host\n    Object Summary:\n       ID   Created   Destroyed  Index\n       =====================================================\n       161  22:03:47  -          com.redhat.matahari:host:\n       101  21:05:51  -          com.redhat.matahari:host:\n\n    qpid: show 161\n    Object of type: com.redhat.matahari:host:_data(7297d90c-5e2a-557c-7b58-90cdd4d916f2)\n       Attribute         161\n       ===================================================================\n       uuid              ec742c182da05427605f96b300000014\n       hostname          im.gangstar.com\n       is_virtual        False\n       operating_system  Linux (2.6.34.7-61.fc13.i686)\n       memory            3057352\n       swap              2047996\n       arch              i686\n       hypervisor<br>       platform          32\n       processors        2\n       cores             4\n       model             Intel(R) Core(TM)2 Duo CPU     T9600  @ 2.80GHz\n       last_updated_seq  83\n       last_updated      Fri Nov 12 22:10:37 2010\n       load_average_1    0.000000\n       load_average_5    0.020000\n       load_average_15   0.000000\n       memFree           186788\n       swapFree          1987552\n       procTotal         394\n       procRunning       1\n\n    qpid: show 101\n    Object of type: com.redhat.matahari:host:_data(7297d90c-5e2a-557c-7b58-90cdd4d916f2)\n       Attribute         101\n       ===================================================================\n       uuid              3d4c71ac60c0b113d8ce73b700000016\n       hostname         im.gangster-twice.com\n       is_virtual        False\n       operating_system  Linux (2.6.34.7-61.fc13.i686)\n       memory            2036688\n       swap              4095996\n       arch              i686\n       hypervisor<br>       platform          32\n       processors        2\n       cores             4\n       model             Intel(R) Core(TM)2 Duo CPU     T7500  @ 2.20GHz\n       last_updated_seq  795\n       last_updated      Fri Nov 12 22:12:03 2010\n       load_average_1    0.120000\n       load_average_5    0.120000\n       load_average_15   0.110000\n       memFree           168912\n       swapFree          4091164\n       procTotal         384\n       procRunning       4\n</pre>\n<p>Pretty simple and really cool :D</p>\n"
    },
    {
      "body": "<p>Been messing around lately with CMake and how to intregrate<br />\nadditional testing frameworks such as CxxTest. So far everything<br />\nhas been very simple to configure and get setup so I thought<br />\nI&#39;d post my findings here.</p>\n<ul>\n<li>Fedora provides both cmake and cxxtest so install these first.</li>\n<li>CMake provides a convenience macro called FindCxxTest.cmake</li>\n<li>In your CMakeLists.txt append the following:</li>\n</ul>\n<pre class=&#34;prettyprint&#34;>\n# cxxtest\nfind_package(CxxTest)\nif(CXXTEST_FOUND)\nset(CXXTEST_USE_PYTHON TRUE)\ninclude_directories(${CXXTEST_INCLUDE_DIR})\nenable_testing()\nCXXTEST_ADD_TEST(unittest_sos check_sos.cpp ${SOS_TEST_PATH}/check_sos.h)\ntarget_link_libraries(unittest_sos sos)\nendif()\n</pre>\n<p>The only custom variable here is SOS_TEST_PATH which basically points to $HOME/sos/tests/check_sos.h. See the &#39;set&#39; function in the cmake documentation.<br />\nThis is really all you need to do here. One note is to set the<br />\nCXXTEST_USE_PYTHON to TRUE b/c cmake provided in Fedora doesn&#39;t<br />\ncontain the perl version of the test generator.  I&#39;m not going<br />\nto post how I setup the testcases b/c right now they are very simple,<br />\nhowever, if you would like to use my project as an example for implementing<br />\ncmake into your code have a look at: libsos</p>\n<p>If anyone has any good information on using cmake with python build scripts I&#39;d love to see those. For RPM Builders the spec file was very simple. I used<br />\nthe syntax within the kde builds:</p>\n<pre class=&#34;prettyprint&#34;>\n%build\nmkdir -p %{_target_platform}\npushd %{_target_platform}\ncmake ..\npopd\nmake %{?_smp_mflags} -C %{_target_platform}\n%install\nrm -rf $RPM_BUILD_ROOT\nmake -C %{_target_platform} install DESTDIR=$RPM_BUILD_ROOT\n%clean\nrm -rf $RPM_BUILD_ROOT\n%post -p /sbin/ldconfig\n%postun -p /sbin/ldconfig\n%files\n%defattr(-,root,root,-)\n%doc\n%{_libdir}/%{name}.so.*\n%files devel\n%defattr(-,root,root,-)\n%doc\n%{_includedir}/%{name}\n%{_libdir}/%{name}.so*\n%{_libdir}/pkgconfig/%{name}.pc\n</pre>\n<p>Hope this little bit will help others who are interested in cmake.</p>\n",
      "date": "2010-03-20T00:00:59",
      "title": "c++, cxxtest, cmake",
      "tags": [],
      "author": "Adam Stokes",
      "path": "c-cxxtest-cmake",
      "compiled": "<p>Been messing around lately with CMake and how to intregrate<br />\nadditional testing frameworks such as CxxTest. So far everything<br />\nhas been very simple to configure and get setup so I thought<br />\nI&#39;d post my findings here.</p>\n<ul>\n<li>Fedora provides both cmake and cxxtest so install these first.</li>\n<li>CMake provides a convenience macro called FindCxxTest.cmake</li>\n<li>In your CMakeLists.txt append the following:</li>\n</ul>\n<pre class=&#34;prettyprint&#34;>\n# cxxtest\nfind_package(CxxTest)\nif(CXXTEST_FOUND)\nset(CXXTEST_USE_PYTHON TRUE)\ninclude_directories(${CXXTEST_INCLUDE_DIR})\nenable_testing()\nCXXTEST_ADD_TEST(unittest_sos check_sos.cpp ${SOS_TEST_PATH}/check_sos.h)\ntarget_link_libraries(unittest_sos sos)\nendif()\n</pre>\n<p>The only custom variable here is SOS_TEST_PATH which basically points to $HOME/sos/tests/check_sos.h. See the &#39;set&#39; function in the cmake documentation.<br />\nThis is really all you need to do here. One note is to set the<br />\nCXXTEST_USE_PYTHON to TRUE b/c cmake provided in Fedora doesn&#39;t<br />\ncontain the perl version of the test generator.  I&#39;m not going<br />\nto post how I setup the testcases b/c right now they are very simple,<br />\nhowever, if you would like to use my project as an example for implementing<br />\ncmake into your code have a look at: libsos</p>\n<p>If anyone has any good information on using cmake with python build scripts I&#39;d love to see those. For RPM Builders the spec file was very simple. I used<br />\nthe syntax within the kde builds:</p>\n<pre class=&#34;prettyprint&#34;>\n%build\nmkdir -p %{_target_platform}\npushd %{_target_platform}\ncmake ..\npopd\nmake %{?_smp_mflags} -C %{_target_platform}\n%install\nrm -rf $RPM_BUILD_ROOT\nmake -C %{_target_platform} install DESTDIR=$RPM_BUILD_ROOT\n%clean\nrm -rf $RPM_BUILD_ROOT\n%post -p /sbin/ldconfig\n%postun -p /sbin/ldconfig\n%files\n%defattr(-,root,root,-)\n%doc\n%{_libdir}/%{name}.so.<em>\n%files devel\n%defattr(-,root,root,-)\n%doc\n%{_includedir}/%{name}\n%{_libdir}/%{name}.so</em>\n%{_libdir}/pkgconfig/%{name}.pc\n</pre>\n<p>Hope this little bit will help others who are interested in cmake.</p>\n"
    },
    {
      "body": "<p>Working on <a href=&#34;http://tornadoweb.org&#34;>Tornado</a> web application server has been a great<br />\nexperience. I&#39;ve written a few simple OAuth mixin&#39;s and this<br />\none is for dropbox. It&#39;s been tested and works, however, I am<br />\nprobably including way to many method overrides. If anyone<br />\nwould like to update the gist please feel free and I&#39;ll make<br />\nsure to link it in this post.</p>\n<pre class=&#34;prettyprint&#34;>\nclass DropboxMixin(tornado.auth.OAuthMixin):\n    &#34;&#34;&#34; Dropbox  OAuth authentication.\n    &#34;&#34;&#34;\n    _OAUTH_REQUEST_TOKEN_URL = &#34;https://api.dropbox.com/1/oauth/request_token&#34;\n    _OAUTH_ACCESS_TOKEN_URL = &#34;https://api.dropbox.com/1/oauth/access_token&#34;\n    _OAUTH_AUTHORIZE_URL = &#34;https://www.dropbox.com/1/oauth/authorize&#34;\n    _OAUTH_VERSION = &#34;1.0&#34;\n    _OAUTH_NO_CALLBACKS = False\n\n    def authorize_redirect(self, callback_uri=None, extra_params=None,\n                           http_client=None):\n        &#34;&#34;&#34;Redirects the user to obtain OAuth authorization for this service.\n\n        Twitter and FriendFeed both require that you register a Callback\n        URL with your application. You should call this method to log the\n        user in, and then call get_authenticated_user() in the handler\n        you registered as your Callback URL to complete the authorization\n        process.\n\n        This method sets a cookie called _oauth_request_token which is\n        subsequently used (and cleared) in get_authenticated_user for\n        security purposes.\n        &#34;&#34;&#34;\n        http_client = httpclient.AsyncHTTPClient()\n        http_client.fetch(\n            self._oauth_request_token_url(), self.async_callback(\n            self._on_request_token, self._OAUTH_AUTHORIZE_URL, callback_uri))\n\n    def get_authenticated_user(self, callback, http_client=None):\n        &#34;&#34;&#34;Gets the OAuth authorized user and access token on callback.\n\n        This method should be called from the handler for your registered\n        OAuth Callback URL to complete the registration process. We call\n        callback with the authenticated user, which in addition to standard\n        attributes like &#39;name&#39; includes the &#39;access_key&#39; attribute, which\n        contains the OAuth access you can use to make authorized requests\n        to this service on behalf of the user.\n\n        &#34;&#34;&#34;\n        request_key = escape.utf8(self.get_argument(&#34;oauth_token&#34;))\n        oauth_verifier = self.get_argument(&#34;oauth_verifier&#34;, None)\n        request_cookie = self.get_cookie(&#34;_oauth_request_token&#34;)\n        if not request_cookie:\n            logging.warning(&#34;Missing OAuth request token cookie&#34;)\n            callback(None)\n            return\n        self.clear_cookie(&#34;_oauth_request_token&#34;)\n        cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split(&#34;|&#34;)]\n        if cookie_key != request_key:\n            logging.info((cookie_key, request_key, request_cookie))\n            logging.warning(&#34;Request token does not match cookie&#34;)\n            callback(None)\n            return\n        token = dict(key=cookie_key, secret=cookie_secret)\n        if oauth_verifier:\n            token[&#34;verifier&#34;] = oauth_verifier\n        if http_client is None:\n            http_client = httpclient.AsyncHTTPClient()\n        http_client.fetch(self._oauth_access_token_url(token),\n                          self.async_callback(self._on_access_token, callback))\n\n    def _on_access_token(self, callback, response):\n        if response.error:\n            logging.warning(&#34;Could not fetch access token&#34;)\n            callback(None)\n            return\n\n        access_token = _oauth_parse_response(response.body)\n        self._oauth_get_user(access_token, self.async_callback(\n             self._on_oauth_get_user, access_token, callback))\n\n    def _on_oauth_get_user(self, access_token, callback, user):\n        if not user:\n            callback(None)\n            return\n        user[&#34;access_token&#34;] = access_token\n        callback(user)\n\n    def dropbox_request(self, path, callback, access_token=None,\n                        post_args=None, **args):\n        # Add the OAuth resource request signature if we have credentials\n        url = &#34;https://api.dropbox.com/1&#34; + path\n        if access_token:\n            all_args = {}\n            all_args.update(args)\n            all_args.update(post_args or {})\n            method = &#34;POST&#34; if post_args is not None else &#34;GET&#34;\n            oauth = self._oauth_request_parameters(\n                url, access_token, all_args, method=method)\n            args.update(oauth)\n        if args: url += &#34;?&#34; + urllib.urlencode(args)\n        callback = self.async_callback(self._on_dropbox_request, callback)\n        http = httpclient.AsyncHTTPClient()\n        if post_args is not None:\n            http.fetch(url, method=&#34;POST&#34;, body=urllib.urlencode(post_args),\n                       callback=callback)\n        else:\n            http.fetch(url, callback=callback)\n\n    def _on_dropbox_request(self, callback, response):\n        if response.error:\n            print(&#34;Error response %s fetching %s&#34;, response.error,\n                            response.request.url)\n            callback(None)\n            return\n        callback(escape.json_decode(response.body))\n\n    def _oauth_consumer_token(self):\n        self.require_setting(&#34;dropbox_consumer_key&#34;, &#34;Dropbox OAuth&#34;)\n        self.require_setting(&#34;dropbox_consumer_secret&#34;, &#34;Dropbox OAuth&#34;)\n        return dict(\n            key=self.settings[&#34;dropbox_consumer_key&#34;],\n            secret=self.settings[&#34;dropbox_consumer_secret&#34;])\n\n    def _oauth_get_user(self, access_token, callback):\n        callback = self.async_callback(self._parse_user_response, callback)\n        self.dropbox_request(\n            &#34;/account/info&#34;,\n            access_token=access_token,\n            callback=callback)\n\n    def _parse_user_response(self, callback, user):\n        if user:\n            user[&#34;username&#34;] = user[&#34;display_name&#34;]\n        callback(user)\n</pre>\n",
      "date": "2012-09-27T00:00:59",
      "title": "Tornado 2.3+ dropbox auth mixin",
      "tags": [],
      "author": "Adam Stokes",
      "path": "tornado-2-3-dropbox-auth-mixin",
      "compiled": "<p><p>Working on <a href=&#34;http://tornadoweb.org&#34;>Tornado</a> web application server has been a great<br />\nexperience. I&#39;ve written a few simple OAuth mixin&#39;s and this<br />\none is for dropbox. It&#39;s been tested and works, however, I am<br />\nprobably including way to many method overrides. If anyone<br />\nwould like to update the gist please feel free and I&#39;ll make<br />\nsure to link it in this post.</p></p>\n<pre class=&#34;prettyprint&#34;>\nclass DropboxMixin(tornado.auth.OAuthMixin):\n    &#34;&#34;&#34; Dropbox  OAuth authentication.\n    &#34;&#34;&#34;\n    _OAUTH_REQUEST_TOKEN_URL = &#34;https://api.dropbox.com/1/oauth/request_token&#34;\n    _OAUTH_ACCESS_TOKEN_URL = &#34;https://api.dropbox.com/1/oauth/access_token&#34;\n    _OAUTH_AUTHORIZE_URL = &#34;https://www.dropbox.com/1/oauth/authorize&#34;\n    _OAUTH_VERSION = &#34;1.0&#34;\n    _OAUTH_NO_CALLBACKS = False\n\n    def authorize_redirect(self, callback_uri=None, extra_params=None,\n                           http_client=None):\n        &#34;&#34;&#34;Redirects the user to obtain OAuth authorization for this service.\n\n        Twitter and FriendFeed both require that you register a Callback\n        URL with your application. You should call this method to log the\n        user in, and then call get_authenticated_user() in the handler\n        you registered as your Callback URL to complete the authorization\n        process.\n\n        This method sets a cookie called _oauth_request_token which is\n        subsequently used (and cleared) in get_authenticated_user for\n        security purposes.\n        &#34;&#34;&#34;\n        http_client = httpclient.AsyncHTTPClient()\n        http_client.fetch(\n            self._oauth_request_token_url(), self.async_callback(\n            self._on_request_token, self._OAUTH_AUTHORIZE_URL, callback_uri))\n\n    def get_authenticated_user(self, callback, http_client=None):\n        &#34;&#34;&#34;Gets the OAuth authorized user and access token on callback.\n\n        This method should be called from the handler for your registered\n        OAuth Callback URL to complete the registration process. We call\n        callback with the authenticated user, which in addition to standard\n        attributes like &#39;name&#39; includes the &#39;access_key&#39; attribute, which\n        contains the OAuth access you can use to make authorized requests\n        to this service on behalf of the user.\n\n        &#34;&#34;&#34;\n        request_key = escape.utf8(self.get_argument(&#34;oauth_token&#34;))\n        oauth_verifier = self.get_argument(&#34;oauth_verifier&#34;, None)\n        request_cookie = self.get_cookie(&#34;_oauth_request_token&#34;)\n        if not request_cookie:\n            logging.warning(&#34;Missing OAuth request token cookie&#34;)\n            callback(None)\n            return\n        self.clear_cookie(&#34;_oauth_request_token&#34;)\n        cookie_key, cookie_secret = [base64.b64decode(escape.utf8(i)) for i in request_cookie.split(&#34;|&#34;)]\n        if cookie_key != request_key:\n            logging.info((cookie_key, request_key, request_cookie))\n            logging.warning(&#34;Request token does not match cookie&#34;)\n            callback(None)\n            return\n        token = dict(key=cookie_key, secret=cookie_secret)\n        if oauth_verifier:\n            token[&#34;verifier&#34;] = oauth_verifier\n        if http_client is None:\n            http_client = httpclient.AsyncHTTPClient()\n        http_client.fetch(self._oauth_access_token_url(token),\n                          self.async_callback(self._on_access_token, callback))\n\n    def _on_access_token(self, callback, response):\n        if response.error:\n            logging.warning(&#34;Could not fetch access token&#34;)\n            callback(None)\n            return\n\n        access_token = _oauth_parse_response(response.body)\n        self._oauth_get_user(access_token, self.async_callback(\n             self._on_oauth_get_user, access_token, callback))\n\n    def _on_oauth_get_user(self, access_token, callback, user):\n        if not user:\n            callback(None)\n            return\n        user[&#34;access_token&#34;] = access_token\n        callback(user)\n\n    def dropbox_request(self, path, callback, access_token=None,\n                        post_args=None, **args):\n        # Add the OAuth resource request signature if we have credentials\n        url = &#34;https://api.dropbox.com/1&#34; + path\n        if access_token:\n            all_args = {}\n            all_args.update(args)\n            all_args.update(post_args or {})\n            method = &#34;POST&#34; if post_args is not None else &#34;GET&#34;\n            oauth = self._oauth_request_parameters(\n                url, access_token, all_args, method=method)\n            args.update(oauth)\n        if args: url += &#34;?&#34; + urllib.urlencode(args)\n        callback = self.async_callback(self._on_dropbox_request, callback)\n        http = httpclient.AsyncHTTPClient()\n        if post_args is not None:\n            http.fetch(url, method=&#34;POST&#34;, body=urllib.urlencode(post_args),\n                       callback=callback)\n        else:\n            http.fetch(url, callback=callback)\n\n    def _on_dropbox_request(self, callback, response):\n        if response.error:\n            print(&#34;Error response %s fetching %s&#34;, response.error,\n                            response.request.url)\n            callback(None)\n            return\n        callback(escape.json_decode(response.body))\n\n    def _oauth_consumer_token(self):\n        self.require_setting(&#34;dropbox_consumer_key&#34;, &#34;Dropbox OAuth&#34;)\n        self.require_setting(&#34;dropbox_consumer_secret&#34;, &#34;Dropbox OAuth&#34;)\n        return dict(\n            key=self.settings[&#34;dropbox_consumer_key&#34;],\n            secret=self.settings[&#34;dropbox_consumer_secret&#34;])\n\n    def _oauth_get_user(self, access_token, callback):\n        callback = self.async_callback(self._parse_user_response, callback)\n        self.dropbox_request(\n            &#34;/account/info&#34;,\n            access_token=access_token,\n            callback=callback)\n\n    def _parse_user_response(self, callback, user):\n        if user:\n            user[&#34;username&#34;] = user[&#34;display_name&#34;]\n        callback(user)\n</pre>\n"
    },
    {
      "body": "<p>Sorry was away, been busy. Setup and migrated my old blog posts over<br />\nto octopress and hosting it on Linode.com. Some of the older blog<br />\nposts may see double titles. The migration script I used automatically<br />\nadded them and eventually I&#39;ll get to cleaning them up. With that I&#39;ve<br />\nbeen messing around with some Ruby to wrap my head around it and<br />\nhopefully get some Rails development going for certain projects.</p>\n<p>Lately, I&#39;ve started noticing a disconnect in services making it<br />\ndifficult for people to decide what products they should pay for in<br />\ndeveloping a web application. I feel the common items should be<br />\nincluded in whatever platform you decide to go with.  For example,<br />\nwufoo.com provides a Form building service. While they are good at<br />\nwhat they provide I don&#39;t entirely agree with making this a service<br />\nthat requires any type of payment. The limit is 3 forms for their free<br />\naccount and once those are used up it starts at $15/mo. These are<br />\nsimple forms with a pretty UI for building.</p>\n<p>Simply put, this is not a service that should require payment to<br />\nbuild. This falls under a notable feature of a bigger product along<br />\nwith convenience of having it all accessable through a single<br />\ninterface. I realize there is an API provided for their service, but,<br />\nthere again it&#39;ll cost you additional fees if you need to do anything<br />\nmore than simple contact forms.</p>\n<h2 id=&#34;writingrubyplugins&#34;>Writing Ruby plugins</h2>\n<p>I was searching around for helpers for building gems for Ruby.  Come<br />\nto find out it isn&#39;t that difficult to write a gemspec, however, I did<br />\nfind an interesting application that pretty much acts in a sane way<br />\nwhen building a Ruby gem. <a href=&#34;https://github.com/lazyatom/gem-this&#34;>gem-this</a> Pretty sweet little application<br />\nas it doesn&#39;t add a bunch of less than useful files and pretty much<br />\nsticks to the convention of keeping everything in a Rakefile and<br />\nhaving that generate your gemspec during build. Not a bad idea and I<br />\nlike gem-this simplicity when it comes to building documentation,<br />\nadding binaries, little-to-no learning curve, and overall keeping<br />\nsimple tasks simple.</p>\n<pre class=&#34;prettyprint&#34;>\n$ gem install gem-this\n</pre>\n<p>One of the best things about gem-this is that it works on existing<br />\nprojects.  You&#39;d be suprised how many of these gem helpers require<br />\nbuilding a new project and including them as dependencies :\\</p>\n<pre class=&#34;prettyprint&#34;>\n$ gem-this .\n</pre>\n<p>It&#39;ll append to your existing Rakefile or create a new one. Gemspecs<br />\nare then generated with a rake task.</p>\n<pre class=&#34;prettyprint&#34;>\n$ rake gemspec\n</pre>\n<p>Other little nice things are including rdoc support and building into<br />\nits own directory for easy cleanup.</p>\n<pre class=&#34;prettyprint&#34;>\n$ rake gem\n</pre>\n",
      "date": "2012-09-27T00:00:59",
      "title": "What happened?",
      "tags": [],
      "author": "Adam Stokes",
      "path": "what-happened",
      "compiled": "<p><p>Sorry was away, been busy. Setup and migrated my old blog posts over<br />\nto octopress and hosting it on Linode.com. Some of the older blog<br />\nposts may see double titles. The migration script I used automatically<br />\nadded them and eventually I&#39;ll get to cleaning them up. With that I&#39;ve<br />\nbeen messing around with some Ruby to wrap my head around it and<br />\nhopefully get some Rails development going for certain projects.</p></p>\n<p><p>Lately, I&#39;ve started noticing a disconnect in services making it<br />\ndifficult for people to decide what products they should pay for in<br />\ndeveloping a web application. I feel the common items should be<br />\nincluded in whatever platform you decide to go with.  For example,<br />\nwufoo.com provides a Form building service. While they are good at<br />\nwhat they provide I don&#39;t entirely agree with making this a service<br />\nthat requires any type of payment. The limit is 3 forms for their free<br />\naccount and once those are used up it starts at $15/mo. These are<br />\nsimple forms with a pretty UI for building.</p></p>\n<p><p>Simply put, this is not a service that should require payment to<br />\nbuild. This falls under a notable feature of a bigger product along<br />\nwith convenience of having it all accessable through a single<br />\ninterface. I realize there is an API provided for their service, but,<br />\nthere again it&#39;ll cost you additional fees if you need to do anything<br />\nmore than simple contact forms.</p></p>\n<p><h2 id=&#34;writingrubyplugins&#34;>Writing Ruby plugins</h2></p>\n<p><p>I was searching around for helpers for building gems for Ruby.  Come<br />\nto find out it isn&#39;t that difficult to write a gemspec, however, I did<br />\nfind an interesting application that pretty much acts in a sane way<br />\nwhen building a Ruby gem. <a href=&#34;https://github.com/lazyatom/gem-this&#34;>gem-this</a> Pretty sweet little application<br />\nas it doesn&#39;t add a bunch of less than useful files and pretty much<br />\nsticks to the convention of keeping everything in a Rakefile and<br />\nhaving that generate your gemspec during build. Not a bad idea and I<br />\nlike gem-this simplicity when it comes to building documentation,<br />\nadding binaries, little-to-no learning curve, and overall keeping<br />\nsimple tasks simple.</p></p>\n<pre class=&#34;prettyprint&#34;>\n$ gem install gem-this\n</pre>\n<p>One of the best things about gem-this is that it works on existing<br />\nprojects.  You&#39;d be suprised how many of these gem helpers require<br />\nbuilding a new project and including them as dependencies :\\</p>\n<pre class=&#34;prettyprint&#34;>\n$ gem-this .\n</pre>\n<p>It&#39;ll append to your existing Rakefile or create a new one. Gemspecs<br />\nare then generated with a rake task.</p>\n<pre class=&#34;prettyprint&#34;>\n$ rake gemspec\n</pre>\n<p>Other little nice things are including rdoc support and building into<br />\nits own directory for easy cleanup.</p>\n<pre class=&#34;prettyprint&#34;>\n$ rake gem\n</pre>\n"
    },
    {
      "body": "<p>Usually when I&#39;m working in Emacs it is running as a daemon. A lot of<br />\ntimes when I&#39;m doing patch work and commits it&#39;ll want to dump me into<br />\nan editor set by my shell settings. More times than not this is<br />\nproblematic because my editor may be set to nano or vim and rendering<br />\nin the eshell is ugly. So far all emacs/eshell sessions I wanted to<br />\nmake sure my EDITOR/VISUAL environment variables were defined with<br />\n&#39;emacsclient -n&#39; in order to push all commit changes into a new buffer<br />\nwindow to be edited.</p>\n<p>To remedy this I use a eshell hook to automatically set my environment<br />\nvariables while in the shell without messing with anything I may have<br />\nset outside of emacs.</p>\n<pre class=&#34;prettyprint&#34;>\n    (add-hook &#39;eshell-mode-hook\n              &#39;(lambda nil\n                 (eshell/export &#34;EDITOR=emacsclient -n&#34;)\n                 (eshell/export &#34;VISUAL=emacsclient -n&#34;)))\n</pre>\n<p>Pretty straight forward and keeps my eshell editing happy.</p>\n",
      "date": "2012-10-18T00:00:59",
      "title": "Exporting variables for Eshell",
      "tags": [],
      "author": "Adam Stokes",
      "path": "exporting-variables-for-eshell",
      "compiled": "<p>Usually when I&#39;m working in Emacs it is running as a daemon. A lot of<br />\ntimes when I&#39;m doing patch work and commits it&#39;ll want to dump me into<br />\nan editor set by my shell settings. More times than not this is<br />\nproblematic because my editor may be set to nano or vim and rendering<br />\nin the eshell is ugly. So far all emacs/eshell sessions I wanted to<br />\nmake sure my EDITOR/VISUAL environment variables were defined with<br />\n&#39;emacsclient -n&#39; in order to push all commit changes into a new buffer<br />\nwindow to be edited.</p>\n<p>To remedy this I use a eshell hook to automatically set my environment<br />\nvariables while in the shell without messing with anything I may have<br />\nset outside of emacs.</p>\n<pre class=&#34;prettyprint&#34;>\n    (add-hook &#39;eshell-mode-hook\n              &#39;(lambda nil\n                 (eshell/export &#34;EDITOR=emacsclient -n&#34;)\n                 (eshell/export &#34;VISUAL=emacsclient -n&#34;)))\n</pre>\n<p>Pretty straight forward and keeps my eshell editing happy.</p>\n"
    },
    {
      "body": "<p>Some tips for getting around the lack of tablet functionality with Ubuntu Precise and even Quantal. First is a small shell script for disabling finger touch on the tablet when you want to use the stylus for writing/drawing.</p>\n<pre class=&#34;prettyprint&#34;>\n    #!/bin/bash\n    # This script can be used to toggle enable state of wacom multitouch screen for\n    # Thinkpad Tablet Series. You may need to change the name of multitouch device \n    # which can be found by running *xinput list* command\n\n    TOGGLE=$HOME/.multitouch_toggle\n\n    if [ ! -e $TOGGLE ]; then\n        touch $TOGGLE\n        xinput set-prop &#39;Wacom ISDv4 E6 Finger touch&#39; &#39;Device Enabled&#39; 0\n    else\n        rm $TOGGLE\n        xinput set-prop &#39;Wacom ISDv4 E6 Finger touch&#39; &#39;Device Enabled&#39; 1\n    fi\n</pre>\n<p>This allows you to place your hand comfortably down on the tablet while you hand write notes in applications such as Xournal or drawing in applications such as MyPaint.</p>\n<p>Another script for rotating the orientation and making sure the mouse recognizes the new quadrants (rather than up being down, down being up, etc) can be found on github. The url for that project is <a href=&#34;https://github.com/martin-ueding/think-rotate.git&#34;>think-rotate</a>. You can rotate left, right, and back to default. This works in all desktop environments and window managers, however, attempting to navigate smoothly through the UI like you would within a smartphone or android/iphone tablet still needs some more work. As of right now Unity is the same UI no matter the resolution or orientation of the device.</p>\n<p>I am going to do some more work and hopefully get some integrated hotkey events into udev so that you may simply swivel the screen into a tablet and the orientation happens automatically.</p>\n",
      "date": "2012-11-01T00:00:59",
      "title": "Lenovo x230 Tablet tips",
      "tags": [],
      "author": "Adam Stokes",
      "path": "lenovo-x230-tablet-tips",
      "compiled": "<p>Some tips for getting around the lack of tablet functionality with Ubuntu Precise and even Quantal. First is a small shell script for disabling finger touch on the tablet when you want to use the stylus for writing/drawing.</p>\n<pre class=&#34;prettyprint&#34;>\n    #!/bin/bash\n    # This script can be used to toggle enable state of wacom multitouch screen for\n    # Thinkpad Tablet Series. You may need to change the name of multitouch device \n    # which can be found by running <em>xinput list</em> command\n\n    TOGGLE=$HOME/.multitouch_toggle\n\n    if [ ! -e $TOGGLE ]; then\n        touch $TOGGLE\n        xinput set-prop &#39;Wacom ISDv4 E6 Finger touch&#39; &#39;Device Enabled&#39; 0\n    else\n        rm $TOGGLE\n        xinput set-prop &#39;Wacom ISDv4 E6 Finger touch&#39; &#39;Device Enabled&#39; 1\n    fi\n</pre>\n<p>This allows you to place your hand comfortably down on the tablet while you hand write notes in applications such as Xournal or drawing in applications such as MyPaint.</p>\n<p>Another script for rotating the orientation and making sure the mouse recognizes the new quadrants (rather than up being down, down being up, etc) can be found on github. The url for that project is <a href=&#34;https://github.com/martin-ueding/think-rotate.git&#34;>think-rotate</a>. You can rotate left, right, and back to default. This works in all desktop environments and window managers, however, attempting to navigate smoothly through the UI like you would within a smartphone or android/iphone tablet still needs some more work. As of right now Unity is the same UI no matter the resolution or orientation of the device.</p>\n<p>I am going to do some more work and hopefully get some integrated hotkey events into udev so that you may simply swivel the screen into a tablet and the orientation happens automatically.</p>\n"
    },
    {
      "body": "<p>I started messing around with some clojure code recently to see what I<br />\ncould come up with in a short period of time. My main goal was to<br />\nprovide some sort of overlay to adding a specific dispatch to handle<br />\ndifferent datatypes when inserting into a database. So for my<br />\nexperiment I decided to use the jdbc interface within Clojure and some<br />\nbuilt-in function/macros to try and make light of my idea.</p>\n<p>First I created my namespace to keep everything organized.</p>\n<pre class=&#34;prettyprint&#34;>\n    (ns rosay.models\n      (:require [clojure.java.jdbc :as sql]))\n</pre>\n<p>Next I defined a postgres database to use and already had some tables<br />\ncreated with a few simple constraints. I won&#39;t go into those details<br />\nbut I&#39;ll show you what the connection looks like.</p>\n<pre class=&#34;prettyprint&#34;>\n    (def rosay-db\n      {:subprotocol &#34;postgresql&#34;\n       :subname &#34;//localhost/rosaydb&#34;\n       :user &#34;adbuser&#34;\n       :password &#34;dbpass&#34;})\n</pre>\n<p>From there I defined a helper function to deal with inserting the<br />\nrecord into the database.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn- db-insert\n      [table record]\n      &#34;Inserts record based on table/record map&#34;\n      (sql/with-connection\n        rosay-db\n        (sql/transaction\n         (sql/insert-record table record))))\n</pre>\n<p>All this was outlined in the relevant api documentation. From this<br />\npoint I setup a protocol to hopefully help me abstract out what to do<br />\nfor different datatypes I wish to store.</p>\n<pre class=&#34;prettyprint&#34;>\n    ;; public interface\n    (defprotocol DBFactory\n      (add-item [_] &#34;Adds item to db&#34;))\n</pre>\n<p>I&#39;ve defined <strong>add-item</strong> in order to facilitate what it is I wish to<br />\ndo to each record. The records I am current concentrating on are<br />\nthese:</p>\n<pre class=&#34;prettyprint&#34;>\n    (defrecord Page [name description keywords frontpage client_id pages_type_id]\n      DBFactory\n      (add-item [_]\n        (db-insert :pages {:name name\n                                      :description description\n                                      :keywords keywords\n                                      :frontpage frontpage\n                                      :client_id client_id\n                                      :pages_type_id pages_type_id})))\n\n    (defrecord Client [username password email domain]\n      DBFactory\n      (add-item [_]\n        (db-insert :clients {:username username\n                             :password password\n                             :email email\n                             :domain domain})))\n</pre>\n<p>With this code in place I load up my REPL and attempt to add a Client<br />\nand a Page to my database.</p>\n<pre class=&#34;prettyprint&#34;>\n    rosay.server=> (use &#39;rosay.models)\n     nil\n     rosay.server=> (add-item (->Client &#34;booyaka&#34; &#34;fark&#34; &#34;mailzer&#34; &#34;domain.com&#34;))\n     {:updated_on nil, :created_on #inst\n     &#34;2012-12-04T04:25:22.672462000-00:00&#34;, :email &#34;mailzer&#34;,\n     :domain &#34;domain.com&#34;, :password &#34;fark&#34;, :username &#34;booyaka&#34;, :id 10}\n\n     rosay.server=> (add-item (->Page &#34;im a new page&#34; &#34;description of new page&#34; &#34;somekeywords,keywords true 10 1))\n    {:updated_on nil, :created_on #inst &#34;2012-12-04T04:41:41.716319000-00:00&#34;, :pages_type_id 1, :client_id 10, :frontpage true, :keywords &#34;somekeywords,keywords&#34;, :description &#34;description of new page&#34;, :name &#34;im a new page&#34;, :id 4}\n</pre>\n<p>So it looked like it added my records based on the type to the correct<br />\ntables.</p>\n<p>In summary, it was pretty easy to setup and the approach seems<br />\nstraight forward to me. Although, I&#39;ve created a SO post to get input<br />\nfrom the more experienced clojure developers on whether or not this<br />\neven makes sense. Hopefully, I&#39;m not to far off base with attempting<br />\nto abstract out the low-level database interactions when wanting to<br />\nadd some sort of dispatch-like system when adding records to a<br />\ndatabase.</p>\n<p><strong><em>NB</em></strong> This entire post could be completely off as I am in no-way a<br />\nseasoned clojure/lisp programmer. Recommendations/changes are always welcomed!</p>\n",
      "date": "2012-12-04T15:00:00",
      "title": "Experimenting with clojure and protocols",
      "tags": [],
      "author": "Adam Stokes",
      "path": "experimenting-with-clojure-and-protocols",
      "compiled": "<p>I started messing around with some clojure code recently to see what I<br />\ncould come up with in a short period of time. My main goal was to<br />\nprovide some sort of overlay to adding a specific dispatch to handle<br />\ndifferent datatypes when inserting into a database. So for my<br />\nexperiment I decided to use the jdbc interface within Clojure and some<br />\nbuilt-in function/macros to try and make light of my idea.</p>\n<p>First I created my namespace to keep everything organized.</p>\n<pre class=&#34;prettyprint&#34;>\n    (ns rosay.models\n      (:require [clojure.java.jdbc :as sql]))\n</pre>\n<p>Next I defined a postgres database to use and already had some tables<br />\ncreated with a few simple constraints. I won&#39;t go into those details<br />\nbut I&#39;ll show you what the connection looks like.</p>\n<pre class=&#34;prettyprint&#34;>\n    (def rosay-db\n      {:subprotocol &#34;postgresql&#34;\n       :subname &#34;//localhost/rosaydb&#34;\n       :user &#34;adbuser&#34;\n       :password &#34;dbpass&#34;})\n</pre>\n<p>From there I defined a helper function to deal with inserting the<br />\nrecord into the database.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn- db-insert\n      [table record]\n      &#34;Inserts record based on table/record map&#34;\n      (sql/with-connection\n        rosay-db\n        (sql/transaction\n         (sql/insert-record table record))))\n</pre>\n<p>All this was outlined in the relevant api documentation. From this<br />\npoint I setup a protocol to hopefully help me abstract out what to do<br />\nfor different datatypes I wish to store.</p>\n<pre class=&#34;prettyprint&#34;>\n    ;; public interface\n    (defprotocol DBFactory\n      (add-item [<em>] &#34;Adds item to db&#34;))\n</pre>\n<p>I&#39;ve defined <strong>add-item</strong> in order to facilitate what it is I wish to<br />\ndo to each record. The records I am current concentrating on are<br />\nthese:</p>\n<pre class=&#34;prettyprint&#34;>\n    (defrecord Page [name description keywords frontpage client_id pages_type_id]\n      DBFactory\n      (add-item [</em>]\n        (db-insert :pages {:name name\n                                      :description description\n                                      :keywords keywords\n                                      :frontpage frontpage\n                                      :client<em>id client_id\n                                      :pages_type_id pages_type_id})))\n\n    (defrecord Client [username password email domain]\n      DBFactory\n      (add-item [</em>]\n        (db-insert :clients {:username username\n                             :password password\n                             :email email\n                             :domain domain})))\n</pre>\n<p>With this code in place I load up my REPL and attempt to add a Client<br />\nand a Page to my database.</p>\n<pre class=&#34;prettyprint&#34;>\n    rosay.server=&gt; (use &#39;rosay.models)\n     nil\n     rosay.server=&gt; (add-item (-&gt;Client &#34;booyaka&#34; &#34;fark&#34; &#34;mailzer&#34; &#34;domain.com&#34;))\n     {:updated_on nil, :created_on #inst\n     &#34;2012-12-04T04:25:22.672462000-00:00&#34;, :email &#34;mailzer&#34;,\n     :domain &#34;domain.com&#34;, :password &#34;fark&#34;, :username &#34;booyaka&#34;, :id 10}\n\n     rosay.server=&gt; (add-item (-&gt;Page &#34;im a new page&#34; &#34;description of new page&#34; &#34;somekeywords,keywords true 10 1))\n    {:updated_on nil, :created_on #inst &#34;2012-12-04T04:41:41.716319000-00:00&#34;, :pages_type_id 1, :client_id 10, :frontpage true, :keywords &#34;somekeywords,keywords&#34;, :description &#34;description of new page&#34;, :name &#34;im a new page&#34;, :id 4}\n</pre>\n<p>So it looked like it added my records based on the type to the correct<br />\ntables.</p>\n<p>In summary, it was pretty easy to setup and the approach seems<br />\nstraight forward to me. Although, I&#39;ve created a SO post to get input<br />\nfrom the more experienced clojure developers on whether or not this<br />\neven makes sense. Hopefully, I&#39;m not to far off base with attempting<br />\nto abstract out the low-level database interactions when wanting to<br />\nadd some sort of dispatch-like system when adding records to a<br />\ndatabase.</p>\n<p><strong><em>NB</em></strong> This entire post could be completely off as I am in no-way a<br />\nseasoned clojure/lisp programmer. Recommendations/changes are always welcomed!</p>\n"
    },
    {
      "body": "<p><strong><em>NB</em></strong> Most of these articles are geared towards those are who not<br />\nreally familiar with Clojure and are just getting started. (like me)</p>\n<p>As I&#39;m continuing to dig through clojure and specifically database<br />\ninteractions I&#39;ve been writing some simple sql statements with a few<br />\njoins. First off we&#39;ll define our namespace:</p>\n<pre class=&#34;prettyprint&#34;>\n    (ns rosay.models\n      (:require [clojure.java.jdbc :as sql]\n                [clojure.string :as string]))\n</pre>\n<p>Next I&#39;ve written a simple helper function that will read in an sql<br />\nstatement with optional arguments.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn db-read\n      &#34;processes query returns result&#34;\n      [query &#38; args]\n      (sql/with-connection\n        rosay-db\n        (sql/with-query-results res (vec (cons query args)) (doall res))))\n</pre>\n<p>From here we can do something like:</p>\n<pre class=&#34;prettyprint&#34;>\n    rosay.server=> (def client-id 1)\n    rosay.server=> (db-read &#34;select * from clients where id=?&#34; client-id)\n</pre>\n<p>This is simple and straightforward approach, but, I&#39;d like to be able<br />\nto add more complexity to the sql statement and still keep things<br />\nrather readable in emacs.</p>\n<p>This helper function basically takes a vector and joins it with a<br />\n<em>space</em>. Nothing fancy or even fault tolerant but for this experiment<br />\nit works.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn- simple-query\n      [query]\n      &#34;Vector of query data for multiline sql statements&#34;\n      (string/join &#34; &#34; query))\n</pre>\n<p>Now that I have this simple query builder I can expand on the<br />\ncomplexity of my SQL statements but still keep it readable.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn get-pages [client-id]\n      &#34;return associated client pages&#34;\n      (db-read (simple-query [&#34;SELECT p.*, c.username, pt.name as page_type from pages p&#34;\n                              &#34;LEFT OUTER JOIN clients as c on p.client_id = c.id&#34;\n                              &#34;LEFT OUTER JOIN pages_types as pt on p.pages_type_id = pt.id&#34;\n                              &#34;WHERE client_id=?&#34;\n                              ]) client-id))\n</pre>\n<p>From my research there wasn&#39;t really a decent way to do multiline like<br />\nabove so this was the simplest thing I could come up with.</p>\n<p>Finally, to test from the nrepl I can run:</p>\n<pre class=&#34;prettyprint&#34;>\n    rosay.server=> (use &#39;rosay.models)\n    nil\n    rosay.server=> (get-pages 19)\n    ({:created_on #inst &#34;2012-12-04T19:23:06.614156000-00:00&#34;, :keywords\n    &#34;words&#34;, :pages_type_id 11, :name &#34;nameo&#34;, :updated_on nil, :client_id\n    19, :username &#34;beef, :page_type &#34;article&#34;, :frontpage true, :id 7,\n    :description &#34;description&#34;} {:created_on #inst\n    &#34;2012-12-04T19:23:09.109556000-00:00&#34;, :keywords &#34;words&#34;,\n    :pages_type_id 11, :name &#34;nameo&#34;, :updated_on nil, :client_id 19,\n    :username beef&#34;, :page_type &#34;article&#34;, :frontpage true, :id 8,\n    :description &#34;description&#34;})\n</pre>\n<p>I&#39;ll be improving on these in time but in the distant future this is<br />\nsuitable for my experiements.</p>\n",
      "date": "2012-12-04T15:00:00",
      "title": "Multiline sql statements in clojure",
      "tags": [],
      "author": "Adam Stokes",
      "path": "multiline-sql-statements-in-clojure",
      "compiled": "<p><strong><em>NB</em></strong> Most of these articles are geared towards those are who not<br />\nreally familiar with Clojure and are just getting started. (like me)</p>\n<p>As I&#39;m continuing to dig through clojure and specifically database<br />\ninteractions I&#39;ve been writing some simple sql statements with a few<br />\njoins. First off we&#39;ll define our namespace:</p>\n<pre class=&#34;prettyprint&#34;>\n    (ns rosay.models\n      (:require [clojure.java.jdbc :as sql]\n                [clojure.string :as string]))\n</pre>\n<p>Next I&#39;ve written a simple helper function that will read in an sql<br />\nstatement with optional arguments.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn db-read\n      &#34;processes query returns result&#34;\n      [query &#38; args]\n      (sql/with-connection\n        rosay-db\n        (sql/with-query-results res (vec (cons query args)) (doall res))))\n</pre>\n<p>From here we can do something like:</p>\n<pre class=&#34;prettyprint&#34;>\n    rosay.server=&gt; (def client-id 1)\n    rosay.server=&gt; (db-read &#34;select <em> from clients where id=?&#34; client-id)\n</pre>\n<p>This is simple and straightforward approach, but, I&#39;d like to be able<br />\nto add more complexity to the sql statement and still keep things<br />\nrather readable in emacs.</p>\n<p>This helper function basically takes a vector and joins it with a<br />\n<em>space</em>. Nothing fancy or even fault tolerant but for this experiment<br />\nit works.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn- simple-query\n      [query]\n      &#34;Vector of query data for multiline sql statements&#34;\n      (string/join &#34; &#34; query))\n</pre>\n<p>Now that I have this simple query builder I can expand on the<br />\ncomplexity of my SQL statements but still keep it readable.</p>\n<pre class=&#34;prettyprint&#34;>\n    (defn get-pages [client-id]\n      &#34;return associated client pages&#34;\n      (db-read (simple-query [&#34;SELECT p.</em>, c.username, pt.name as page_type from pages p&#34;\n                              &#34;LEFT OUTER JOIN clients as c on p.client_id = c.id&#34;\n                              &#34;LEFT OUTER JOIN pages_types as pt on p.pages_type_id = pt.id&#34;\n                              &#34;WHERE client_id=?&#34;\n                              ]) client-id))\n</pre>\n<p>From my research there wasn&#39;t really a decent way to do multiline like<br />\nabove so this was the simplest thing I could come up with.</p>\n<p>Finally, to test from the nrepl I can run:</p>\n<pre class=&#34;prettyprint&#34;>\n    rosay.server=&gt; (use &#39;rosay.models)\n    nil\n    rosay.server=&gt; (get-pages 19)\n    ({:created_on #inst &#34;2012-12-04T19:23:06.614156000-00:00&#34;, :keywords\n    &#34;words&#34;, :pages_type_id 11, :name &#34;nameo&#34;, :updated_on nil, :client_id\n    19, :username &#34;beef, :page_type &#34;article&#34;, :frontpage true, :id 7,\n    :description &#34;description&#34;} {:created_on #inst\n    &#34;2012-12-04T19:23:09.109556000-00:00&#34;, :keywords &#34;words&#34;,\n    :pages_type_id 11, :name &#34;nameo&#34;, :updated_on nil, :client_id 19,\n    :username beef&#34;, :page_type &#34;article&#34;, :frontpage true, :id 8,\n    :description &#34;description&#34;})\n</pre>\n<p>I&#39;ll be improving on these in time but in the distant future this is<br />\nsuitable for my experiements.</p>\n"
    },
    {
      "body": "<p>Sosreport is a set of tools is designed to provide information to support organizations<br />\nin an extensible manner, allowing third parties, package maintainers, and<br />\nanyone else to provide plugins that will collect and report information that<br />\nis useful for supporting software packages.</p>\n<p>This project is hosted at <a href=&#34;http://github.com/sosreport/sosreport&#34;>Github</a> For the latest<br />\nversion, to contribute, and for more information, please visit there.</p>\n<p>Installing it through Launchpad PPA:</p>\n<pre class=&#34;prettyprint&#34;>\n    sudo add-apt-repository ppa:debugmonkeys/sosreport\n    sudo apt-get update\n    sudo apt-get install sosreport\n</pre>\n<p>If you are coming from a Red Hat Enterprise Linux or Fedora background and are familiar with sosreport we&#39;d like to invite you to participate in porting over plugins to work across these distributions as well. Several plugins have been ported over that you can use as a guide for making other plugins distribution aware.</p>\n",
      "date": "2013-01-08T15:00:00",
      "title": "SOSreport now supports Debian/Ubuntu",
      "tags": [
        "ubuntu",
        "linux",
        "sosreport"
      ],
      "author": "Adam Stokes",
      "path": "sosreport-now-supports-debianubuntu",
      "compiled": "<p>Sosreport is a set of tools is designed to provide information to support organizations<br />\nin an extensible manner, allowing third parties, package maintainers, and<br />\nanyone else to provide plugins that will collect and report information that<br />\nis useful for supporting software packages.</p>\n<p>This project is hosted at <a href=&#34;http://github.com/sosreport/sosreport&#34;>Github</a> For the latest<br />\nversion, to contribute, and for more information, please visit there.</p>\n<p>Installing it through Launchpad PPA:</p>\n<pre class=&#34;prettyprint&#34;>\n    sudo add-apt-repository ppa:debugmonkeys/sosreport\n    sudo apt-get update\n    sudo apt-get install sosreport\n</pre>\n<p>If you are coming from a Red Hat Enterprise Linux or Fedora background and are familiar with sosreport we&#39;d like to invite you to participate in porting over plugins to work across these distributions as well. Several plugins have been ported over that you can use as a guide for making other plugins distribution aware.</p>\n"
    },
    {
      "body": "<p>Some notes on getting Storm used as a database backend for Django. Props to James Henstridge for doing the heavy lifting.</p>\n<h3 id=&#34;setupvirtualenvandinstalldependencies:&#34;>Setup virtualenv and install dependencies:</h3>\n<pre class=&#34;prettyprint&#34;>\n$ virtualenv --prompt=stormy venv\n$ source venv/bin/activate\n$ pip install django storm psycopg2 pytz python-dateutil\n$ pip freeze > requirements.txt\n</pre>\n<h3 id=&#34;setupdjangoskeleton&#34;>Setup django skeleton</h3>\n<pre class=&#34;prettyprint&#34;>\n$ django-admin.py startproject myproject\n$ cd myproject\n$ python manage.py startapp common\n</pre>\n<h3 id=&#34;editsettings.pytoincludethepropermiddlewareandstorm_stores&#34;>Edit <strong>settings.py</strong> to include the proper middleware and STORM_STORES</h3>\n<pre class=&#34;prettyprint&#34;>\nMIDDLEWARE_CLASSES = (\n        &#39;django.middleware.common.CommonMiddleware&#39;,\n        &#39;django.contrib.sessions.middleware.SessionMiddleware&#39;,\n        &#39;django.middleware.csrf.CsrfViewMiddleware&#39;,\n        &#39;django.contrib.auth.middleware.AuthenticationMiddleware&#39;,\n        &#39;django.contrib.messages.middleware.MessageMiddleware&#39;,\n        &#39;storm.django.middleware.ZopeTransactionMiddleware&#39;,       # Added this line\n        # Uncomment the next line for simple clickjacking pro\n        )\n\nSTORM_STORES = { &#39;default&#39; : &#34;postgres://adam@localhost/testdb&#34; }\n</pre>\n<h3 id=&#34;nextinmyappaddsomemodels&#34;>Next in my app add some models</h3>\n<pre class=&#34;prettyprint&#34;>\nfrom django.db import models\nfrom storm.sqlobject import StringCol, UtcDateTimeCol, BoolCol, IntCol\nfrom storm.locals import Int\nfrom storm.expr import SQL\nfrom datetime import datetime\nfrom pytz import UTC\nimport dateutil.parser\n\nclass Bug(models.Model):\n      __storm_table__ = &#34;bug&#34;\n      id = Int(primary=True,)\n      date_created = UtcDateTimeCol(notNull=True,)\n      date_last_message = UtcDateTimeCol()\n      date_last_updated = UtcDateTimeCol()\n      date_made_private = UtcDateTimeCol()\n      description = StringCol(notNull=True,)\n      duplicate_of = IntCol()\n      heat = IntCol()\n      gravity = IntCol()\n      information_type = StringCol()\n      latest_patch_uploaded = UtcDateTimeCol()\n      message_count = IntCol(notNull=True,)\n      number_of_duplicates = IntCol()\n      other_users_affected_count_with_dupes = IntCol()\n      owner = IntCol(notNull=True,)\n      private = BoolCol(notNull=True, default=False,)\n      security_related = BoolCol(notNull=True, default=True,)\n      tags = StringCol()\n      title = StringCol(notNull=True,)\n      users_affected_count = IntCol()\n      users_affected_count_with_dupes = IntCol()\n      web_link = StringCol()\n      who_made_private = IntCol()\n</pre>\n<h3 id=&#34;pullthedataintotheview&#34;>Pull the data into the view</h3>\n<pre class=&#34;prettyprint&#34;>\nfrom django.core.context_processors import csrf\nfrom django.shortcuts import render_to_response, HttpResponseRedirect\nfrom storm.django.stores import *\nfrom myproject.common.models import *\n\ndef index(request):\n    store = get_store(&#39;default&#39;)\n    bug = store.find(Bug)\n    return render_to_response(&#34;common/index.html&#34;, { &#39;bug&#39; : bug })\n</pre>\n<h3 id=&#34;finallyeditthetemplatetodisplaythedata&#34;>Finally, edit the template to display the data</h3>\n<pre class=&#34;prettyprint&#34;>\n{% raw %}\n{% extends &#39;layout.html&#39; %}\n\n{% block page_name %}Home{% endblock %}\n\n{% block content %}\n{% for b in bug %}\n  {{ b.id }} : {{ b.title }}\n{% endfor %}\n{% endblock content %}\n{% endraw %}\n</pre>\n<p>Things to do:</p>\n<ul>\n<li>Have <strong>get_store</strong> persisted when the application starts</li>\n<li>Integrate migrations with South</li>\n<li>Integrate with something like celery for running some background jobs</li>\n</ul>\n<p>I haven&#39;t done anything major other than a few queries so time will tell how well this does when this project really gets into making use of Storm.</p>\n",
      "date": "2013-02-21T15:00:00",
      "title": "Mental Note: Django 1.4.x and Storm .19",
      "tags": "ubuntu",
      "author": "Adam Stokes",
      "path": "mental-note-django-1-4-x-and-storm-19",
      "compiled": "<p>Some notes on getting Storm used as a database backend for Django. Props to James Henstridge for doing the heavy lifting.</p>\n<h3 id=&#34;setupvirtualenvandinstalldependencies:&#34;>Setup virtualenv and install dependencies:</h3>\n<pre class=&#34;prettyprint&#34;>\n$ virtualenv --prompt=stormy venv\n$ source venv/bin/activate\n$ pip install django storm psycopg2 pytz python-dateutil\n$ pip freeze &gt; requirements.txt\n</pre>\n<h3 id=&#34;setupdjangoskeleton&#34;>Setup django skeleton</h3>\n<pre class=&#34;prettyprint&#34;>\n$ django-admin.py startproject myproject\n$ cd myproject\n$ python manage.py startapp common\n</pre>\n<h3 id=&#34;editsettings.pytoincludethepropermiddlewareandstorm_stores&#34;>Edit <strong>settings.py</strong> to include the proper middleware and STORM<em>STORES</h3>\n<pre class=&#34;prettyprint&#34;>\nMIDDLEWARE<em>CLASSES = (\n        &#39;django.middleware.common.CommonMiddleware&#39;,\n        &#39;django.contrib.sessions.middleware.SessionMiddleware&#39;,\n        &#39;django.middleware.csrf.CsrfViewMiddleware&#39;,\n        &#39;django.contrib.auth.middleware.AuthenticationMiddleware&#39;,\n        &#39;django.contrib.messages.middleware.MessageMiddleware&#39;,\n        &#39;storm.django.middleware.ZopeTransactionMiddleware&#39;,       # Added this line\n        # Uncomment the next line for simple clickjacking pro\n        )\n\nSTORM_STORES = { &#39;default&#39; : &#34;postgres://adam@localhost/testdb&#34; }\n</pre>\n<h3 id=&#34;nextinmyappaddsomemodels&#34;>Next in my app add some models</h3>\n<pre class=&#34;prettyprint&#34;>\nfrom django.db import models\nfrom storm.sqlobject import StringCol, UtcDateTimeCol, BoolCol, IntCol\nfrom storm.locals import Int\nfrom storm.expr import SQL\nfrom datetime import datetime\nfrom pytz import UTC\nimport dateutil.parser\n\nclass Bug(models.Model):\n      __storm_table</em></em> = &#34;bug&#34;\n      id = Int(primary=True,)\n      date_created = UtcDateTimeCol(notNull=True,)\n      date_last_message = UtcDateTimeCol()\n      date_last_updated = UtcDateTimeCol()\n      date_made_private = UtcDateTimeCol()\n      description = StringCol(notNull=True,)\n      duplicate_of = IntCol()\n      heat = IntCol()\n      gravity = IntCol()\n      information_type = StringCol()\n      latest_patch_uploaded = UtcDateTimeCol()\n      message_count = IntCol(notNull=True,)\n      number_of_duplicates = IntCol()\n      other_users_affected_count_with_dupes = IntCol()\n      owner = IntCol(notNull=True,)\n      private = BoolCol(notNull=True, default=False,)\n      security_related = BoolCol(notNull=True, default=True,)\n      tags = StringCol()\n      title = StringCol(notNull=True,)\n      users_affected_count = IntCol()\n      users_affected_count_with_dupes = IntCol()\n      web_link = StringCol()\n      who_made_private = IntCol()\n</pre>\n<h3 id=&#34;pullthedataintotheview&#34;>Pull the data into the view</h3>\n<pre class=&#34;prettyprint&#34;>\nfrom django.core.context_processors import csrf\nfrom django.shortcuts import render_to_response, HttpResponseRedirect\nfrom storm.django.stores import <em>\nfrom myproject.common.models import </em>\n\ndef index(request):\n    store = get_store(&#39;default&#39;)\n    bug = store.find(Bug)\n    return render_to_response(&#34;common/index.html&#34;, { &#39;bug&#39; : bug })\n</pre>\n<h3 id=&#34;finallyeditthetemplatetodisplaythedata&#34;>Finally, edit the template to display the data</h3>\n<pre class=&#34;prettyprint&#34;>\n{% raw %}\n{% extends &#39;layout.html&#39; %}\n\n{% block page_name %}Home{% endblock %}\n\n{% block content %}\n{% for b in bug %}\n  {{ b.id }} : {{ b.title }}\n{% endfor %}\n{% endblock content %}\n{% endraw %}\n</pre>\n<p>Things to do:</p>\n<ul>\n<li>Have <strong>get_store</strong> persisted when the application starts</li>\n<li>Integrate migrations with South</li>\n<li>Integrate with something like celery for running some background jobs</li>\n</ul>\n<p>I haven&#39;t done anything major other than a few queries so time will tell how well this does when this project really gets into making use of Storm.</p>\n"
    },
    {
      "body": "<h2 id=&#34;recap&#34;>Recap</h2>\n<p>I can ping all devices on the network <em>except</em> the gateway<br />\n(192.168.0.1) and in turn can not access outside of the network<br />\nwithout proxying through another device.</p>\n<p>The system:</p>\n<p>Lenovo x230 Tablet with a Realtek wifi adapter running on Quantal:</p>\n<p>Network controller: Realtek Semiconductor Co., Ltd. RTL8188CE<br />\n802.11b/g/n WiFi Adapter (rev 01)</p>\n<p>The wtf:</p>\n<p>I can obtain an IP from the router</p>\n<pre class=&#34;prettyprint&#34;>\nwlan0 Link encap:Ethernet HWaddr e0:06:e6:c2:d2:e0\ninet addr:192.168.0.102 Bcast:192.168.0.255 Mask:255.255.255.0\ninet6 addr: fe80::e206:e6ff:fec2:d2e0/64 Scope:Link\nUP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\nRX packets:178844 errors:0 dropped:0 overruns:0 frame:0\nTX packets:101517 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:1000\nRX bytes:121465876 (121.4 MB) TX bytes:10612848 (10.6 MB)\n</pre>\n<p>I can ping other devices:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ ping 192.168.0.101\nPING 192.168.0.101 (192.168.0.101) 56(84) bytes of data.\n64 bytes from 192.168.0.101: icmp_req=1 ttl=64 time=3.84 ms\n64 bytes from 192.168.0.101: icmp_req=2 ttl=64 time=1.32 ms\n</pre>\n<p>I can not ping the gateway:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ ping 192.168.0.1\nPING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.\nFrom 192.168.0.102 icmp_seq=1 Destination Host Unreachable\nFrom 192.168.0.102 icmp_seq=2 Destination Host Unreachable\n</pre>\n<p>My resolv.conf is autogenerated with:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ cat /etc/resolv.conf\n# Dynamic resolv.conf(5) file for glibc resolver(3) generated by\nresolvconf(8)\n# DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\nnameserver 127.0.1.1\nsearch nc.rr.com\n</pre>\n<p>My /etc/hosts:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ cat /etc/hosts\n127.0.0.1 localhost\n127.0.1.1 quantal\n</pre>\n<p>My routing table:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ route\nKernel IP routing table\nDestination Gateway Genmask Flags Metric Ref Use Iface\ndefault 192.168.0.1 0.0.0.0 UG 0 0 0 wlan0\nlink-local * 255.255.0.0 U 1000 0 0 wlan0\n192.168.0.0 * 255.255.255.0 U 9 0 0 wlan0\n</pre>\n<p>Lastly, my module info for device:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ modinfo rtl8192ce\nfilename: /lib/modules/3.5.0-17-generic/kernel/drivers/net/wireless/rtlwifi/rtl8192ce/rtl8192ce.ko\nfirmware: rtlwifi/rtl8192cfw.bin\ndescription: Realtek 8192C/8188C 802.11n PCI wireless\nlicense: GPL\nauthor: Larry Finger <Larry.Finger@lwfinger.net>\nauthor: Realtek WlanFAE <wlanfae@realtek.com>\nauthor: lizhaoming <chaoming_li@realsil.com.cn>\nsrcversion: DD4F3D83A75531AC98862F2\nalias: pci:v000010ECd00008176sv*sd*bc*sc*i*\nalias: pci:v000010ECd00008177sv*sd*bc*sc*i*\nalias: pci:v000010ECd00008178sv*sd*bc*sc*i*\nalias: pci:v000010ECd00008191sv*sd*bc*sc*i*\ndepends: rtlwifi,mac80211\nvermagic: 3.5.0-17-generic SMP mod_unload modversions\nparm: swlps:bool\nparm: swenc:using hardware crypto (default 0 [hardware])\n(bool)\nparm: ips:using no link power save (default 1 is open)\n(bool)\nparm: fwlps:using linked fw control power save (default 1 is open)\n(bool)\n</pre>\n<p>Things I&#39;ve attempted:</p>\n<p>Turning off fwlps, ips. Attempted to compile a driver from upstream<br />\nand even tried the latest daily mainline kernel for Quantal.</p>\n<p>Has anyone seen this before? What really baffles me is that I can not<br />\nping the gateway. To verify I can ping the gateway from another<br />\nsystem:</p>\n<pre class=&#34;prettyprint&#34;>\n~ : ping 192.168.0.1\nPING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.\n64 bytes from 192.168.0.1: icmp_req=1 ttl=64 time=1.35 ms\n64 bytes from 192.168.0.1: icmp_req=2 ttl=64 time=1.22 ms\n64 bytes from 192.168.0.1: icmp_req=3 ttl=64 time=5.11 ms\n</pre>\n<p>This also doesn&#39;t happen outside of my network as I was able to use<br />\nthis laptop at UDS-R which kind of points to a router issue but<br />\nanything without a Realtek adapter works :\\</p>\n<h2 id=&#34;solution&#34;>Solution</h2>\n<p>Turns out that this particular laptop was having issues resolving dns queries because on my particular cable modem/router there was an option for &#34;Enable DNS relay&#34; that was not checked (off). Once I checked that option my laptop suddenly started working! I tried to do some more research on what could be a possible reason as to why this specific laptop/wifi combo requires dns relay to be enabled on the router in order to access anything outside my network? Another odd thing is that if I directly connect the laptop to the router everything works so I assume it is something to do with the actual wifi driver/hardware. Anyway, I&#39;m finally back to being able to use my recently purchased laptop :)</p>\n<p>p.s - Im in London next week so if any kernel guys are feeling gracious and would like to look at my laptop I&#39;ll have it with me.</p>\n",
      "date": "2013-03-22T15:00:00",
      "title": "x230T, realtek wifi, and my solution",
      "tags": [
        "ubuntu",
        "linux",
        "sosreport"
      ],
      "author": "Adam Stokes",
      "path": "x230t-realtek-wifi-and-my-solution",
      "compiled": "<p><h2 id=&#34;recap&#34;>Recap</h2></p>\n<p>I can ping all devices on the network <em>except</em> the gateway<br />\n(192.168.0.1) and in turn can not access outside of the network<br />\nwithout proxying through another device.</p>\n<p>The system:</p>\n<p>Lenovo x230 Tablet with a Realtek wifi adapter running on Quantal:</p>\n<p>Network controller: Realtek Semiconductor Co., Ltd. RTL8188CE<br />\n802.11b/g/n WiFi Adapter (rev 01)</p>\n<p>The wtf:</p>\n<p>I can obtain an IP from the router</p>\n<pre class=&#34;prettyprint&#34;>\nwlan0 Link encap:Ethernet HWaddr e0:06:e6:c2:d2:e0\ninet addr:192.168.0.102 Bcast:192.168.0.255 Mask:255.255.255.0\ninet6 addr: fe80::e206:e6ff:fec2:d2e0/64 Scope:Link\nUP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1\nRX packets:178844 errors:0 dropped:0 overruns:0 frame:0\nTX packets:101517 errors:0 dropped:0 overruns:0 carrier:0\ncollisions:0 txqueuelen:1000\nRX bytes:121465876 (121.4 MB) TX bytes:10612848 (10.6 MB)\n</pre>\n<p>I can ping other devices:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ ping 192.168.0.101\nPING 192.168.0.101 (192.168.0.101) 56(84) bytes of data.\n64 bytes from 192.168.0.101: icmp_req=1 ttl=64 time=3.84 ms\n64 bytes from 192.168.0.101: icmp_req=2 ttl=64 time=1.32 ms\n</pre>\n<p>I can not ping the gateway:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ ping 192.168.0.1\nPING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.\nFrom 192.168.0.102 icmp_seq=1 Destination Host Unreachable\nFrom 192.168.0.102 icmp_seq=2 Destination Host Unreachable\n</pre>\n<p>My resolv.conf is autogenerated with:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ cat /etc/resolv.conf\n# Dynamic resolv.conf(5) file for glibc resolver(3) generated by\nresolvconf(8)\n# DO NOT EDIT THIS FILE BY HAND -- YOUR CHANGES WILL BE OVERWRITTEN\nnameserver 127.0.1.1\nsearch nc.rr.com\n</pre>\n<p>My /etc/hosts:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ cat /etc/hosts\n127.0.0.1 localhost\n127.0.1.1 quantal\n</pre>\n<p>My routing table:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ route\nKernel IP routing table\nDestination Gateway Genmask Flags Metric Ref Use Iface\ndefault 192.168.0.1 0.0.0.0 UG 0 0 0 wlan0\nlink-local <em> 255.255.0.0 U 1000 0 0 wlan0\n192.168.0.0 </em> 255.255.255.0 U 9 0 0 wlan0\n</pre>\n<p>Lastly, my module info for device:</p>\n<pre class=&#34;prettyprint&#34;>\n&#10140; ~ modinfo rtl8192ce\nfilename: /lib/modules/3.5.0-17-generic/kernel/drivers/net/wireless/rtlwifi/rtl8192ce/rtl8192ce.ko\nfirmware: rtlwifi/rtl8192cfw.bin\ndescription: Realtek 8192C/8188C 802.11n PCI wireless\nlicense: GPL\nauthor: Larry Finger <a href=\"&#109;&#x61;&#105;&#x6c;&#x74;&#111;&#x3a;&#76;&#97;&#x72;&#114;&#x79;&#x2e;&#x46;&#x69;&#110;&#103;&#x65;&#x72;&#64;&#x6c;&#119;&#x66;&#x69;&#x6e;&#103;&#101;&#x72;&#46;&#x6e;&#x65;&#116;\">&#76;&#97;&#x72;&#114;&#x79;&#x2e;&#x46;&#x69;&#110;&#103;&#x65;&#x72;&#64;&#x6c;&#119;&#x66;&#x69;&#x6e;&#103;&#101;&#x72;&#46;&#x6e;&#x65;&#116;</a>\nauthor: Realtek WlanFAE <a href=\"&#x6d;&#x61;&#105;&#x6c;&#x74;&#x6f;&#58;&#x77;&#x6c;&#x61;&#x6e;&#102;&#97;&#101;&#64;&#x72;&#101;&#97;&#x6c;&#x74;&#101;&#107;&#46;&#99;&#x6f;&#109;\">&#x77;&#x6c;&#x61;&#x6e;&#102;&#97;&#101;&#64;&#x72;&#101;&#97;&#x6c;&#x74;&#101;&#107;&#46;&#99;&#x6f;&#109;</a>\nauthor: lizhaoming <a href=\"&#x6d;&#x61;&#105;&#108;&#x74;&#x6f;&#x3a;&#x63;&#x68;&#97;&#111;&#109;&#x69;&#110;&#103;&#x5f;&#108;&#105;&#64;&#114;&#101;&#97;&#108;&#115;&#105;&#x6c;&#x2e;&#99;&#x6f;&#109;&#46;&#99;&#x6e;\">&#x63;&#x68;&#97;&#111;&#109;&#x69;&#110;&#103;&#x5f;&#108;&#105;&#64;&#114;&#101;&#97;&#108;&#115;&#105;&#x6c;&#x2e;&#99;&#x6f;&#109;&#46;&#99;&#x6e;</a>\nsrcversion: DD4F3D83A75531AC98862F2\nalias: pci:v000010ECd00008176sv<em>sd</em>bc<em>sc</em>i<em>\nalias: pci:v000010ECd00008177sv</em>sd<em>bc</em>sc<em>i</em>\nalias: pci:v000010ECd00008178sv<em>sd</em>bc<em>sc</em>i<em>\nalias: pci:v000010ECd00008191sv</em>sd<em>bc</em>sc<em>i</em>\ndepends: rtlwifi,mac80211\nvermagic: 3.5.0-17-generic SMP mod_unload modversions\nparm: swlps:bool\nparm: swenc:using hardware crypto (default 0 [hardware])\n(bool)\nparm: ips:using no link power save (default 1 is open)\n(bool)\nparm: fwlps:using linked fw control power save (default 1 is open)\n(bool)\n</pre>\n<p>Things I&#39;ve attempted:</p>\n<p>Turning off fwlps, ips. Attempted to compile a driver from upstream<br />\nand even tried the latest daily mainline kernel for Quantal.</p>\n<p>Has anyone seen this before? What really baffles me is that I can not<br />\nping the gateway. To verify I can ping the gateway from another<br />\nsystem:</p>\n<pre class=&#34;prettyprint&#34;>\n~ : ping 192.168.0.1\nPING 192.168.0.1 (192.168.0.1) 56(84) bytes of data.\n64 bytes from 192.168.0.1: icmp_req=1 ttl=64 time=1.35 ms\n64 bytes from 192.168.0.1: icmp_req=2 ttl=64 time=1.22 ms\n64 bytes from 192.168.0.1: icmp_req=3 ttl=64 time=5.11 ms\n</pre>\n<p>This also doesn&#39;t happen outside of my network as I was able to use<br />\nthis laptop at UDS-R which kind of points to a router issue but<br />\nanything without a Realtek adapter works :\\</p>\n<h2 id=&#34;solution&#34;>Solution</h2>\n<p>Turns out that this particular laptop was having issues resolving dns queries because on my particular cable modem/router there was an option for &#34;Enable DNS relay&#34; that was not checked (off). Once I checked that option my laptop suddenly started working! I tried to do some more research on what could be a possible reason as to why this specific laptop/wifi combo requires dns relay to be enabled on the router in order to access anything outside my network? Another odd thing is that if I directly connect the laptop to the router everything works so I assume it is something to do with the actual wifi driver/hardware. Anyway, I&#39;m finally back to being able to use my recently purchased laptop :)</p>\n<p>p.s - Im in London next week so if any kernel guys are feeling gracious and would like to look at my laptop I&#39;ll have it with me.</p>\n"
    },
    {
      "body": "<p>I've got a project going to utilize Salesforce.com api over json and oauth rather than soap. Today I uploaded the package to the cheeseshop in hopes to pull in some interest from the community.</p>\n<p>Right now the library contains authorization over OAuth 1.0a and client methods for retrieving basic Account, Case, and Asset information. My goal is to be api complete by the end of the year.</p>\n<p>I would love to have contributors join the project in order to shape this young project into a well documented, tested, and easy to use library. As far as I can tell there isn't another python library like this that doesn't utilize SOAP for its endpoints.</p>\n<p>Using the library is pretty straight forward, currently, I have 2 scripts that provide a simple way to authorize yourself and communicate with the endpoints.</p>\n<p><strong>sf-exchange-auth</strong> provides a local ssl enabled web server for going through the OAuth process and storing your token/secret.</p>\n<p><strong>sf-cli</strong> provides some arguments for pulling in rudimentary account and case information. Usage documentation is provided for this script.</p>\n<p>The current focus is to stick to the <a href=\"http://en.wikipedia.org/wiki/You_Ain%27t_Gonna_Need_It\">YAGNI</a> principles and utilize OO when it makes sense. This may or may not be the way to go so I am open to ideas and patches :D.</p>\n<p>You can currently install python-salesforce through pip</p>\n<pre><code>$ pip install python-salesforce\n</code></pre>\n<p>The project page is located at</p>\n<p>http://python.salesforce.astokes.org</p>\n<p>Looking forward to hearing from you.</p>\n",
      "date": "2013-05-20T23:04:34",
      "title": "python-salesforce on pypi",
      "tags": [
        "ubuntu",
        "linux",
        "sosreport"
      ],
      "author": "Adam Stokes",
      "path": "python-salesforce-on-pypi",
      "compiled": "<p>I&#39;ve got a project going to utilize Salesforce.com api over json and oauth rather than soap. Today I uploaded the package to the cheeseshop in hopes to pull in some interest from the community.</p>\n<p>Right now the library contains authorization over OAuth 1.0a and client methods for retrieving basic Account, Case, and Asset information. My goal is to be api complete by the end of the year.</p>\n<p>I would love to have contributors join the project in order to shape this young project into a well documented, tested, and easy to use library. As far as I can tell there isn&#39;t another python library like this that doesn&#39;t utilize SOAP for its endpoints.</p>\n<p>Using the library is pretty straight forward, currently, I have 2 scripts that provide a simple way to authorize yourself and communicate with the endpoints.</p>\n<p><strong>sf-exchange-auth</strong> provides a local ssl enabled web server for going through the OAuth process and storing your token/secret.</p>\n<p><strong>sf-cli</strong> provides some arguments for pulling in rudimentary account and case information. Usage documentation is provided for this script.</p>\n<p>The current focus is to stick to the <a href=\"http://en.wikipedia.org/wiki/You_Ain%27t_Gonna_Need_It\">YAGNI</a> principles and utilize OO when it makes sense. This may or may not be the way to go so I am open to ideas and patches :D.</p>\n<p>You can currently install python-salesforce through pip</p>\n<pre><code>$ pip install python-salesforce\n</code></pre>\n<p>The project page is located at</p>\n<p><a href=\"http://python.salesforce.astokes.org\">http://python.salesforce.astokes.org</a></p>\n<p>Looking forward to hearing from you.</p>\n"
    },
    {
      "body": "<p>I was using octopress for awhile but I still have mixed feelings about<br />\nruby. There isn&#39;t anything wrong with ruby, but, as the creator of<br />\nruby said &#34;its how you feel when writing in a language&#34; and I don&#39;t<br />\nthink me and ruby are on the same page.</p>\n<p>I started looking around for a simple one file blogging system with<br />\nminimal dependencies and could be extended easily. I attempted to<br />\nwrite my own with using a cpan package called fatpacker. The idea<br />\nbehind it is cool, however, I couldn&#39;t get it to fully work with the<br />\nmodules I needed. I scratched that project the first day and just<br />\nhappened to stumble across <a href=&#34;https://github.com/avenj/blagger&#34;>blagger</a>. It is relatively new and<br />\ndoesn&#39;t have a lot of features (which I believe was the authors<br />\npoint).</p>\n<p>What got me interested was it is written in Perl, easy to hack on, and<br />\nhas a small amount of dependencies. It uses Mojolicious as a web<br />\nframework which allowed me to put all code and templates within the<br />\nblagger file. The code itself is well written and allowed me to get up<br />\nto speed on the design quickly.</p>\n<p>I&#39;ve converted my current blog to <a href=&#34;https://github.com/battlemidget/blagger&#34;>blagger with my own<br />\nmodifications</a>. Some additional features include:</p>\n<ul>\n<li>Categories</li>\n<li>RSS Feeds for /*/:category/atom.xml and the root path for all<br />\narticles.</li>\n<li>Generates posts with YYYY/MM/DD prepended (keeps everything in a<br />\ngood order)</li>\n<li>Gravatar support (elementary, could stand to use something other<br />\nthan hard coded urls :))</li>\n</ul>\n<p>Some things I plan on adding</p>\n<ul>\n<li>gist support</li>\n<li>syntax highlighter</li>\n</ul>\n<p>I don&#39;t plan on adding much more than the bare minimum for someone who<br />\nwrites about coding projects and an occasional rant. Patches are<br />\ndefinately welcomed.</p>\n",
      "date": "2013-05-21T02:13:41",
      "title": "blagger - perl blogging software",
      "tags": [
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "blagger-perl-blogging-software",
      "compiled": "<p>I was using octopress for awhile but I still have mixed feelings about<br />\nruby. There isn&#39;t anything wrong with ruby, but, as the creator of<br />\nruby said &#34;its how you feel when writing in a language&#34; and I don&#39;t<br />\nthink me and ruby are on the same page.</p>\n<p>I started looking around for a simple one file blogging system with<br />\nminimal dependencies and could be extended easily. I attempted to<br />\nwrite my own with using a cpan package called fatpacker. The idea<br />\nbehind it is cool, however, I couldn&#39;t get it to fully work with the<br />\nmodules I needed. I scratched that project the first day and just<br />\nhappened to stumble across <a href=&#34;https://github.com/avenj/blagger&#34;>blagger</a>. It is relatively new and<br />\ndoesn&#39;t have a lot of features (which I believe was the authors<br />\npoint).</p>\n<p>What got me interested was it is written in Perl, easy to hack on, and<br />\nhas a small amount of dependencies. It uses Mojolicious as a web<br />\nframework which allowed me to put all code and templates within the<br />\nblagger file. The code itself is well written and allowed me to get up<br />\nto speed on the design quickly.</p>\n<p>I&#39;ve converted my current blog to <a href=&#34;https://github.com/battlemidget/blagger&#34;>blagger with my own<br />\nmodifications</a>. Some additional features include:</p>\n<ul>\n<li>Categories</li>\n<li>RSS Feeds for /*/:category/atom.xml and the root path for all<br />\narticles.</li>\n<li>Generates posts with YYYY/MM/DD prepended (keeps everything in a<br />\ngood order)</li>\n<li>Gravatar support (elementary, could stand to use something other<br />\nthan hard coded urls :))</li>\n</ul>\n<p>Some things I plan on adding</p>\n<ul>\n<li>gist support</li>\n<li>syntax highlighter</li>\n</ul>\n<p>I don&#39;t plan on adding much more than the bare minimum for someone who<br />\nwrites about coding projects and an occasional rant. Patches are<br />\ndefinately welcomed.</p>\n"
    },
    {
      "body": "<p>If you come from a python or ruby background and are used to services<br />\nsuch as virtualenv, rbenv then this document should be easy to<br />\nfollow. If not, no problem it is still easy :)</p>\n<h2 id=&#34;pre-reqs&#34;>Pre-reqs</h2>\n<p>Youll want to install perlbrew which is perl&#39;s equivalent to virtualenv and rbenv.</p>\n<pre class=&#34;prettyprint&#34;>\n$ curl -kL http://install.perlbrew.pl | bash\n</pre>\n<p>Follow the on screen instructions and install your desired perl version (this doc uses 5.18.1)</p>\n<pre class=&#34;prettyprint&#34;>\n$ perlbrew install perl-5.18.1\n$ perlbrew switch perl-5.18.1\n</pre>\n<p>Install cpanm</p>\n<pre class=&#34;prettyprint&#34;>\n$ perlbrew install-cpanm\n</pre>\n<h2 id=&#34;setup&#34;>Setup</h2>\n<h3 id=&#34;checkoutsourcelocallyandonremoteserver&#34;>Checkout source locally and on remote server</h3>\n<p>It is best to fork the code into your github account since you&#39;ll be<br />\nstoring your own posts. This is for demonstration only.</p>\n<pre class=&#34;prettyprint&#34;>\n$ git clone git://github.com/battlemidget/ztunzeed.git\n</pre>\n<h3 id=&#34;installdependencieslocallyandonremoteserver&#34;>Install dependencies locally and on remote server</h3>\n<p>This is equivalent to python&#39;s pip or ruby&#39;s gem.</p>\n<pre class=&#34;prettyprint&#34;>\n$ cpanm --installdeps .\n</pre>\n<h3 id=&#34;setupnginxonremoteserver&#34;>Setup nginx on remote server</h3>\n<pre class=&#34;prettyprint&#34;>\n$ cp blog.nginx.conf /etc/nginx/sites-enabled/blog.conf\n</pre>\n<p>Edit the configuration to match your hostname and root directory for this application.</p>\n<h3 id=&#34;setupubicontheremoteserverwhereyouhostyourblog&#34;>Setup <a href=&#34;https://metacpan.org/release/Ubic&#34;>Ubic</a> on the remote server where you host your blog</h3>\n<p>You can install this right in your home directory to keep your application self-contained.</p>\n<pre class=&#34;prettyprint&#34;>\n$ ubic-admin setup\n</pre>\n<p>Place the following in your $HOME/ubic/service/blog</p>\n<pre class=&#34;prettyprint&#34;>\nuse Ubic::Service::Plack;\nreturn Ubic::Service::Plack->new({\n   server => &#34;Starman&#34;,\n   server_args => {\n   env => &#39;production&#39;,\n   host => &#39;127.0.0.1&#39;,\n   workers => 5,\n   port => 9001,\n },\n app => &#39;/home/blagger/blagger&#39;,\n app_name => &#39;blagger&#39;,\n});\n</pre>\n<p>Start the service monitor</p>\n<pre class=&#34;prettyprint&#34;>\n$ ubic start blog\n</pre>\n<h2 id=&#34;writeablogpost&#34;>Write a blog post</h2>\n<pre class=&#34;prettyprint&#34;>\n$ ./blagger blag a-new-blog-post\n</pre>\n<h2 id=&#34;commitanddeploy&#34;>Commit and deploy</h2>\n<pre class=&#34;prettyprint&#34;>\n$ git commit -asm &#39;new blog post&#39; &#38;&#38; git push -q\n$ rex deploy\n</pre>\n<p>This will deploy and checkout your source remotely via <a href=&#34;http://rexify.org&#34;>Rex</a> and restart the gaurdian service for the blog.</p>\n<p>Once you&#39;ve done the first deployment any future posts only require you to commit to git and deploy.</p>\n",
      "date": "2013-05-23T15:24:15",
      "title": "Deploy blagger with starman, rex and ubic",
      "tags": [
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "deploy-blagger-with-starman-rex-and-ubic",
      "compiled": "<p>If you come from a python or ruby background and are used to services<br />\nsuch as virtualenv, rbenv then this document should be easy to<br />\nfollow. If not, no problem it is still easy :)</p>\n<h2 id=&#34;pre-reqs&#34;>Pre-reqs</h2>\n<p>Youll want to install perlbrew which is perl&#39;s equivalent to virtualenv and rbenv.</p>\n<pre class=&#34;prettyprint&#34;>\n$ curl -kL <a href=\"http://install.perlbrew.pl\">http://install.perlbrew.pl</a> | bash\n</pre>\n<p>Follow the on screen instructions and install your desired perl version (this doc uses 5.18.1)</p>\n<pre class=&#34;prettyprint&#34;>\n$ perlbrew install perl-5.18.1\n$ perlbrew switch perl-5.18.1\n</pre>\n<p>Install cpanm</p>\n<pre class=&#34;prettyprint&#34;>\n$ perlbrew install-cpanm\n</pre>\n<h2 id=&#34;setup&#34;>Setup</h2>\n<h3 id=&#34;checkoutsourcelocallyandonremoteserver&#34;>Checkout source locally and on remote server</h3>\n<p>It is best to fork the code into your github account since you&#39;ll be<br />\nstoring your own posts. This is for demonstration only.</p>\n<pre class=&#34;prettyprint&#34;>\n$ git clone git://github.com/battlemidget/ztunzeed.git\n</pre>\n<h3 id=&#34;installdependencieslocallyandonremoteserver&#34;>Install dependencies locally and on remote server</h3>\n<p>This is equivalent to python&#39;s pip or ruby&#39;s gem.</p>\n<pre class=&#34;prettyprint&#34;>\n$ cpanm --installdeps .\n</pre>\n<h3 id=&#34;setupnginxonremoteserver&#34;>Setup nginx on remote server</h3>\n<pre class=&#34;prettyprint&#34;>\n$ cp blog.nginx.conf /etc/nginx/sites-enabled/blog.conf\n</pre>\n<p>Edit the configuration to match your hostname and root directory for this application.</p>\n<h3 id=&#34;setupubicontheremoteserverwhereyouhostyourblog&#34;>Setup <a href=&#34;https://metacpan.org/release/Ubic&#34;>Ubic</a> on the remote server where you host your blog</h3>\n<p>You can install this right in your home directory to keep your application self-contained.</p>\n<pre class=&#34;prettyprint&#34;>\n$ ubic-admin setup\n</pre>\n<p>Place the following in your $HOME/ubic/service/blog</p>\n<pre class=&#34;prettyprint&#34;>\nuse Ubic::Service::Plack;\nreturn Ubic::Service::Plack-&gt;new({\n   server =&gt; &#34;Starman&#34;,\n   server_args =&gt; {\n   env =&gt; &#39;production&#39;,\n   host =&gt; &#39;127.0.0.1&#39;,\n   workers =&gt; 5,\n   port =&gt; 9001,\n },\n app =&gt; &#39;/home/blagger/blagger&#39;,\n app_name =&gt; &#39;blagger&#39;,\n});\n</pre>\n<p>Start the service monitor</p>\n<pre class=&#34;prettyprint&#34;>\n$ ubic start blog\n</pre>\n<h2 id=&#34;writeablogpost&#34;>Write a blog post</h2>\n<pre class=&#34;prettyprint&#34;>\n$ ./blagger blag a-new-blog-post\n</pre>\n<h2 id=&#34;commitanddeploy&#34;>Commit and deploy</h2>\n<pre class=&#34;prettyprint&#34;>\n$ git commit -asm &#39;new blog post&#39; &#38;&#38; git push -q\n$ rex deploy\n</pre>\n<p>This will deploy and checkout your source remotely via <a href=&#34;http://rexify.org&#34;>Rex</a> and restart the gaurdian service for the blog.</p>\n<p>Once you&#39;ve done the first deployment any future posts only require you to commit to git and deploy.</p>\n"
    },
    {
      "body": "<p>New plugin in the works to integrate a simple blogging system as a plugin for<br />\n<a href=&#34;http://mojolicio.us&#34;>Mojolicious</a>.</p>\n<p>So far it supports most relational databases through DBIx::Connector and<br />\nsupport for some social networks are coming soon.</p>\n<p>Getting it going is straightforward a simple Mojolicious lite_app with a blog<br />\ncan be done in as a little as a few lines.</p>\n<h3 id=&#34;example&#34;>Example</h3>\n<pre class=&#34;prettyprint&#34;>\n# Set authentication condition\nmy $conditions = {\n  authenticated => sub {\n    my $self = shift;\n    unless ($self->session(&#39;authenticated&#39;)) {\n      $self->flash(\n        class   => &#39;alert alert-info&#39;,\n        message => &#39;Please log in first!&#39;\n      );\n      $self->redirect_to(&#39;/login&#39;);\n      return;\n    }\n    return 1;\n  },\n};\n\n# Mojolicious full\n$self->plugin(&#39;Blog&#39; => {\n  authCondition => $conditions\n  dsn => &#34;dbi:Pg:dbname=myblog&#34;,\n  dbuser => &#39;zef&#39;,\n  dbpass => &#39;letmein&#39;,\n  }\n);\n\n# Mojolicious::Lite\nplugin &#39;Blog&#39; => {\n  authCondition => $conditions,\n  dsn => &#34;dbi:Pg:dbname=myblog&#34;,\n  dbuser => &#39;zef&#39;,\n  dbpass => &#39;letmein&#39;,\n};\n</pre>\n<p>Support for user authentication is handled through an <strong>authCondition</strong> and<br />\na routing bridge. Community contributions is always welcomed and you can visit<br />\nthe <a href=&#34;https://github.com/battlemidget/Mojolicious-Plugin-Blog&#34;>Project Page</a> to<br />\nfind out more.</p>\n<p>Some immediate future plans are to integrate disqus comments, twitter activity,<br />\nand cross posting to sites like <a href=&#34;https://coderwall.com&#34;>coderwall</a> and gravatar<br />\nsupport.</p>\n",
      "date": "2013-06-01T00:34:18",
      "title": "A new Mojolicious Plugin Blog in the works",
      "tags": [
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "a-new-mojolicious-plugin-blog-in-the-works",
      "compiled": "<p>New plugin in the works to integrate a simple blogging system as a plugin for<br />\n<a href=&#34;http://mojolicio.us&#34;>Mojolicious</a>.</p>\n<p>So far it supports most relational databases through DBIx::Connector and<br />\nsupport for some social networks are coming soon.</p>\n<p>Getting it going is straightforward a simple Mojolicious lite_app with a blog<br />\ncan be done in as a little as a few lines.</p>\n<h3 id=&#34;example&#34;>Example</h3>\n<pre class=&#34;prettyprint&#34;>\n# Set authentication condition\nmy $conditions = {\n  authenticated =&gt; sub {\n    my $self = shift;\n    unless ($self-&gt;session(&#39;authenticated&#39;)) {\n      $self-&gt;flash(\n        class   =&gt; &#39;alert alert-info&#39;,\n        message =&gt; &#39;Please log in first!&#39;\n      );\n      $self-&gt;redirect_to(&#39;/login&#39;);\n      return;\n    }\n    return 1;\n  },\n};\n\n# Mojolicious full\n$self-&gt;plugin(&#39;Blog&#39; =&gt; {\n  authCondition =&gt; $conditions\n  dsn =&gt; &#34;dbi:Pg:dbname=myblog&#34;,\n  dbuser =&gt; &#39;zef&#39;,\n  dbpass =&gt; &#39;letmein&#39;,\n  }\n);\n\n# Mojolicious::Lite\nplugin &#39;Blog&#39; =&gt; {\n  authCondition =&gt; $conditions,\n  dsn =&gt; &#34;dbi:Pg:dbname=myblog&#34;,\n  dbuser =&gt; &#39;zef&#39;,\n  dbpass =&gt; &#39;letmein&#39;,\n};\n</pre>\n<p>Support for user authentication is handled through an <strong>authCondition</strong> and<br />\na routing bridge. Community contributions is always welcomed and you can visit<br />\nthe <a href=&#34;https://github.com/battlemidget/Mojolicious-Plugin-Blog&#34;>Project Page</a> to<br />\nfind out more.</p>\n<p>Some immediate future plans are to integrate disqus comments, twitter activity,<br />\nand cross posting to sites like <a href=&#34;https://coderwall.com&#34;>coderwall</a> and gravatar<br />\nsupport.</p>\n"
    },
    {
      "body": "<h2 id=&#34;newrelease&#34;>New release!</h2>\n<p>After what seems like the longest development cycle ever we&#39;ve finally released<br />\nsosreport 3.0.</p>\n<p>Because of the lengthy development cycle I am just going to point you to the<br />\n<a href=&#34;https://github.com/sosreport/sosreport/commits/master&#34;>commits</a> to see what<br />\nchanges were made. The most notable changes are:</p>\n<ul>\n<li>Mult-distribution (Debian, Ubuntu, Fedora, RHEL)</li>\n<li>Increase speed, roughly 2-3s for an average of 61 plugins tested against.</li>\n<li>Cloud technologies included (but not limited too):\n<ul>\n<li>openstack</li>\n<li>juju</li>\n<li>maas</li>\n<li>openshift</li>\n<li>azure</li>\n<li>cloudforms</li>\n</ul>\n</li>\n<li>Cleaner codebase.</li>\n</ul>\n<p>I&#39;ve also uploaded sosreport to Debian archive and now just waiting on<br />\nftpmaster approval. Until then keep an eye out on my<br />\n<a href=&#34;https://launchpad.net/~debugmonkeys/+archive/sosreport&#34;>ppa</a> for updates.</p>\n<p>Thanks to everyone involved!</p>\n",
      "date": "2013-06-10T14:09:55",
      "title": "SOSreport reaches 3.0",
      "tags": [
        "ubuntu",
        "linux",
        "sosreport"
      ],
      "author": "Adam Stokes",
      "path": "sosreport-reaches-3-0",
      "compiled": "<p><h2 id=&#34;newrelease&#34;>New release!</h2></p>\n<p>After what seems like the longest development cycle ever we&#39;ve finally released<br />\nsosreport 3.0.</p>\n<p>Because of the lengthy development cycle I am just going to point you to the<br />\n<a href=&#34;https://github.com/sosreport/sosreport/commits/master&#34;>commits</a> to see what<br />\nchanges were made. The most notable changes are:</p>\n<ul>\n<li>Mult-distribution (Debian, Ubuntu, Fedora, RHEL)</li>\n<li>Increase speed, roughly 2-3s for an average of 61 plugins tested against.</li>\n<li>Cloud technologies included (but not limited too):\n<ul>\n<li>openstack</li>\n<li>juju</li>\n<li>maas</li>\n<li>openshift</li>\n<li>azure</li>\n<li>cloudforms</li>\n</ul>\n</li>\n<li>Cleaner codebase.</li>\n</ul>\n<p>I&#39;ve also uploaded sosreport to Debian archive and now just waiting on<br />\nftpmaster approval. Until then keep an eye out on my<br />\n<a href=&#34;https://launchpad.net/~debugmonkeys/+archive/sosreport&#34;>ppa</a> for updates.</p>\n<p>Thanks to everyone involved!</p>\n"
    },
    {
      "body": "<p>Im working on some wordpress stuff recently and realized how much I dislike<br />\nsetting up php development environments. Specifically anything prior to php 5.4<br />\nbecause of the lack of a built in web server.</p>\n<p>I decided at this point it is a good time to invest some time into <a href=&#34;http://vagrantup.com&#34;>vagrant</a> and<br />\nattempt to get a more tolerable way of hacking on anything php. I managed to<br />\ncome across a <a href=&#34;https://github.com/chad-thompson/vagrantpress&#34;>github project</a> that allows me to setup a vagrant session and have<br />\nwordpress installed and configured with no fuss.</p>\n<p>Fortunately, the developer is receptive to pull requests and merged a few of my<br />\nadditions to make this project a great way to get started with wordpress<br />\neasily.</p>\n<p>Here are the simple steps to getting a wordpress development environment setup<br />\nin Ubuntu Precise (12.04) and on your way to hacking a new exciting plugin :)</p>\n<p>First install VirtualBox</p>\n<pre class=&#34;prettyprint&#34;>\n$ sudo apt-get install virtualbox\n</pre>\n<p>Install <a href=&#34;http://vagrantup.com&#34;>vagrant</a> from their site. Once that is done follow the next steps to<br />\nget up and running.</p>\n<pre class=&#34;prettyprint&#34;>\n$ git clone https://github.com/chad-thompson/vagrantpress.git\n$ cd vagrantpress\n$ vagrant up\n</pre>\n<p>You can view your wordpress installation at </p>\n<pre class=&#34;prettyprint&#34;>\nhttp://localhost:8080/wordpress\n# or for a more fqdn approach\nhttp://lvh.me:8080/wordpress\n</pre>\n",
      "date": "2013-06-18T22:06:41",
      "title": "Simple way to get wordpress going in vagrant",
      "tags": [],
      "author": "Adam Stokes",
      "path": "simple-way-to-get-wordpress-going-in-vagrant",
      "compiled": "<p><p>Im working on some wordpress stuff recently and realized how much I dislike<br />\nsetting up php development environments. Specifically anything prior to php 5.4<br />\nbecause of the lack of a built in web server.</p></p>\n<p><p>I decided at this point it is a good time to invest some time into <a href=&#34;http://vagrantup.com&#34;>vagrant</a> and<br />\nattempt to get a more tolerable way of hacking on anything php. I managed to<br />\ncome across a <a href=&#34;https://github.com/chad-thompson/vagrantpress&#34;>github project</a> that allows me to setup a vagrant session and have<br />\nwordpress installed and configured with no fuss.</p></p>\n<p><p>Fortunately, the developer is receptive to pull requests and merged a few of my<br />\nadditions to make this project a great way to get started with wordpress<br />\neasily.</p></p>\n<p><p>Here are the simple steps to getting a wordpress development environment setup<br />\nin Ubuntu Precise (12.04) and on your way to hacking a new exciting plugin :)</p></p>\n<p><p>First install VirtualBox</p></p>\n<pre class=&#34;prettyprint&#34;>\n$ sudo apt-get install virtualbox\n</pre>\n<p>Install <a href=&#34;http://vagrantup.com&#34;>vagrant</a> from their site. Once that is done follow the next steps to<br />\nget up and running.</p>\n<pre class=&#34;prettyprint&#34;>\n$ git clone https://github.com/chad-thompson/vagrantpress.git\n$ cd vagrantpress\n$ vagrant up\n</pre>\n<p>You can view your wordpress installation at </p>\n<pre class=&#34;prettyprint&#34;>\nhttp://localhost:8080/wordpress\n# or for a more fqdn approach\nhttp://lvh.me:8080/wordpress\n</pre>\n"
    },
    {
      "body": "<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n<pre><code>$ morbo <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n\n</code></pre>\n<h2>RUN (Production)</h2>\n<p>I use Ubic to manage the process</p>\n<pre><code>use Ubic::Service::SimpleDaemon; \nmy $service = Ubic::Service::SimpleDaemon-&gt;new( \n          bin =&gt; \"hypnotoad -f <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n<pre><code>$ morbo <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n\n</code></pre>\n<h2>RUN (Production)</h2>\n<p>I use Ubic to manage the process</p>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n<pre><code>$ morbo <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you're comfortable with. I won't judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable's dir)\n## %homedir% (current $HOME) \npost_directory =&gt; '%homedir%/blog/posts', \ntemplate_directory =&gt; '%homedir%/blog/templates',\nmedia_directory =&gt; '%homedir%/blog/public', \n</code></pre>\n<p>You'll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; 'post',\nindex_template =&gt; 'index',\nabout_template =&gt; 'about',\ncss_template =&gt; 'style',\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n\n</code></pre>\n<h2>RUN (Production)</h2>\n<p>I use Ubic to manage the process</p>\n\", \n          cwd =&gt; \"/home/username\", \n          stdout =&gt; \"/tmp/blog.log\", \n          stderr =&gt; \"/tmp/blog.err.log\", \n          ubic_log =&gt; \"/tmp/blog.ubic.log\", \n          user =&gt; \"username\" );\n</code></pre>\n",
      "date": "2013-06-20T00:42:00",
      "title": "Get up and running with skryf a perl blog engine",
      "tags": [
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "get-up-and-running-with-skryf-a-perl-blog-engine",
      "compiled": "<p><p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p></p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n<pre><code>$ morbo <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n\n<p></code></pre></p>\n<h2>RUN (Production)</h2>\n<p>I use Ubic to manage the process</p>\n<pre><code>use Ubic::Service::SimpleDaemon; \nmy $service = Ubic::Service::SimpleDaemon-&gt;new( \n          bin =&gt; &quot;hypnotoad -f <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n<pre><code>$ morbo <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n\n<p></code></pre></p>\n<h2>RUN (Production)</h2>\n<p>I use Ubic to manage the process</p>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n<pre><code>$ morbo <p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\nwhich skryf<p>Another blog engine utilizing Mojolicious, Markdown, Hypnotoad, Rex, and Ubic for a more streamlined deployable approach.</p>\n<h2>PREREQS</h2>\n<p>I like <a href=\"http://perlbrew.pl\">perlbrew</a>, but, whatever you&#39;re comfortable with. I won&#39;t judge.</p>\n<h2>INSTALLATION (SOURCE)</h2>\n<pre><code>$ git clone git://github.com/battlemidget/App-skryf.git\n$ cpanm --installdeps . \n</code></pre>\n<h2>SETUP</h2>\n<p>By default <strong>skryf</strong> will look in <em>dist_dir</em> for templates and media. To override that make sure <strong>~/.skryf.conf</strong> points to the locations of your templates, posts, and media. For example, this is a simple directory structure for managing your blog.</p>\n<pre><code>$ mkdir -p ~/blog/{posts,templates,public}\n</code></pre>\n<p>Another useful reference would be to check out <a href=\"https://github.com/battlemidget/stokes-blog\">my git repo</a> that hosts this site.</p>\n<p>Edit <strong>~/.skryf.conf</strong> to reflect those directories in media_directory, post_directory, and template_directory.</p>\n<pre><code>## Available vars: ## %bindir% (path to executable&#39;s dir)\n## %homedir% (current $HOME) \npost_directory =&gt; &#39;%homedir%/blog/posts&#39;, \ntemplate_directory =&gt; &#39;%homedir%/blog/templates&#39;,\nmedia_directory =&gt; &#39;%homedir%/blog/public&#39;, \n</code></pre>\n<p>You&#39;ll want to make sure that files exist that reflect the template configuration options.</p>\n<pre><code>post_template =&gt; &#39;post&#39;,\nindex_template =&gt; &#39;index&#39;,\nabout_template =&gt; &#39;about&#39;,\ncss_template =&gt; &#39;style&#39;,\n</code></pre>\n<p>So <strong>~/blog/templates/{post.html.ep,index.html.ep,about.html.ep}</strong> and <strong>~/blog/public/style.css</strong></p>\n<h2>DEPLOY</h2>\n<pre><code>$ export BLOGUSER=username\n$ export BLOGSERVER=example.com \n</code></pre>\n<p>If perlbrew is installed Rex will autoload that environment to use remotely. Otherwise more tinkering is required to handle the perl environment remotely.</p>\n<pre><code>$ rex deploy\n</code></pre>\n<h2>RUN (Development)</h2>\n\n<p></code></pre></p>\n<p><h2>RUN (Production)</h2></p>\n<p><p>I use Ubic to manage the process</p>\n&quot;, \n          cwd =&gt; &quot;/home/username&quot;, \n          stdout =&gt; &quot;/tmp/blog.log&quot;, \n          stderr =&gt; &quot;/tmp/blog.err.log&quot;, \n          ubic_log =&gt; &quot;/tmp/blog.ubic.log&quot;, \n          user =&gt; &quot;username&quot; );\n</code></pre></p>\n"
    },
    {
      "body": "<p>A new plugin up on cpan for making it easy to add your Google Analytics<br />\ntracking code. </p>\n<p>To get started just include the plugin in your Mojolicious web application and<br />\nuse the builtin helper.</p>\n<h3 id=&#34;installation&#34;>Installation</h3>\n<pre><code>  $ cpanm Mojolicious::Plugin::GoogleAnalytics\n</code></pre>\n<h3 id=&#34;example&#34;>Example</h3>\n<pre><code>  # Mojolicious\n  $self-&#38;gt;plugin(&#39;GoogleAnalytics&#39;);\n\n  # Mojolicious::Lite\n  plugin &#39;GoogleAnalytics&#39;;\n\n  # In your layout template just before closing head tag\n  &#38;lt;%= analytics_inc &#39;UA-32432-1&#39; %&#38;gt;\n</code></pre>\n<p>Hopefully, that&#39;ll save some few extra lines of typing :D</p>\n",
      "date": "2013-06-22T02:33:32",
      "title": "New Mojolicious plugin: Google Analytics",
      "tags": [
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "new-mojolicious-plugin-google-analytics",
      "compiled": "<p>A new plugin up on cpan for making it easy to add your Google Analytics<br />\ntracking code. </p>\n<p>To get started just include the plugin in your Mojolicious web application and<br />\nuse the builtin helper.</p>\n<h3 id=&#34;installation&#34;>Installation</h3>\n<pre><code>  $ cpanm Mojolicious::Plugin::GoogleAnalytics\n</code></pre>\n<h3 id=&#34;example&#34;>Example</h3>\n<pre><code>  # Mojolicious\n  $self-&#38;gt;plugin(&#39;GoogleAnalytics&#39;);\n\n  # Mojolicious::Lite\n  plugin &#39;GoogleAnalytics&#39;;\n\n  # In your layout template just before closing head tag\n  &#38;lt;%= analytics_inc &#39;UA-32432-1&#39; %&#38;gt;\n</code></pre>\n<p>Hopefully, that&#39;ll save some few extra lines of typing :D</p>\n"
    },
    {
      "body": "<p>Another small plugin for easing inclusion of socially enabled software. This<br />\nplugin only concentrates on including the necessary javascript code to get<br />\ncomments enabled on your blog or web app.<br />\n<a href=&#34;https://metacpan.org/module/Mojolicious::Plugin::Disqus&#34;>Mojolicious::Plugin::Disqus</a> gives you more control over the api if you need<br />\nmore options.</p>\n<p>A quick example on setting up your disqus forum on a mojolicious app:</p>\n<pre><code>  #!/usr/bin/env perl\n  use Mojolicious::Lite;\n\n  plugin &#39;Disqus::Tiny&#39;;\n\n  get &#39;/&#39; =&#38;gt; sub {\n    my $self = shift;\n    $self-&#38;gt;render(&#39;index&#39;);\n  };\n\n  app-&#38;gt;start;\n  __DATA__\n\n  @@ index.html.ep\n  Welcome to the Mojolicious real-time web framework!\n\n  &#38;lt;%= disqus_inc &#39;astokes&#39; %&#38;gt;\n</code></pre>\n<p>You can find the module on <a href=&#34;https://metacpan.org/module/Mojolicious::Plugin::Disqus::Tiny&#34;>cpan</a> and code repository on <a href=&#34;https://github.com/battlemidget/Mojolicious-Plugin-Disqus-Tiny&#34;>github</a>.</p>\n",
      "date": "2013-07-01T14:11:09",
      "title": "New Mojolicious plugin - Disqus::Tiny",
      "tags": [
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "new-mojolicious-plugin-disqustiny",
      "compiled": "<p>Another small plugin for easing inclusion of socially enabled software. This<br />\nplugin only concentrates on including the necessary javascript code to get<br />\ncomments enabled on your blog or web app.<br />\n<a href=&#34;https://metacpan.org/module/Mojolicious::Plugin::Disqus&#34;>Mojolicious::Plugin::Disqus</a> gives you more control over the api if you need<br />\nmore options.</p>\n<p>A quick example on setting up your disqus forum on a mojolicious app:</p>\n<pre><code>  #!/usr/bin/env perl\n  use Mojolicious::Lite;\n\n  plugin &#39;Disqus::Tiny&#39;;\n\n  get &#39;/&#39; =&#38;gt; sub {\n    my $self = shift;\n    $self-&#38;gt;render(&#39;index&#39;);\n  };\n\n  app-&#38;gt;start;\n  <strong>DATA</strong>\n\n  @@ index.html.ep\n  Welcome to the Mojolicious real-time web framework!\n\n  &#38;lt;%= disqus_inc &#39;astokes&#39; %&#38;gt;\n</code></pre>\n<p>You can find the module on <a href=&#34;https://metacpan.org/module/Mojolicious::Plugin::Disqus::Tiny&#34;>cpan</a> and code repository on <a href=&#34;https://github.com/battlemidget/Mojolicious-Plugin-Disqus-Tiny&#34;>github</a>.</p>\n"
    },
    {
      "body": "<p>Goal of this document is to explain how <a href=\"https://wiki.ubuntu.com/christopherarges\">Chris Arges</a> and I managed to get Apache w/SSL proxy to gunicorn which is serving up a django application with postgresql as the database and everything be deployable through Juju.</p>\n<p>As an added bonus I'll also show you how to utilize Launchpad.net's SSO to enable authentication to your web application.</p>\n<p>I will also break this document up into 2 parts with the first part concentrating on configuring your django application for deployment and the other doing the actual bootstrapping and deployment. Make sure you read the document in its entirety since they rely on each other to properly work.</p>\n<h1>Pre-requisites</h1>\n<ul>\n<li>Ubuntu 12.04</li>\n<li>Juju 0.7</li>\n<li>You'll want to have an existing django project created which uses postgresql as the database backend. I won't go into details on setting that up since this focuses purely on deploying with Juju, but, <a href=\"https://docs.djangoproject.com/en/1.4/intro/install/\">Django</a> documentation is excellent in getting up and running.</li>\n</ul>\n<p>The rest of the necessary bits are handled by Juju.</p>\n<h1>The environment</h1>\n<p>In this document I use LXC as the containers for juju deployment. You could easily use AWS or any other supported cloud technologies. The directory layout for this tutorial looks like this:</p>\n<pre><code>  - /home/adam/deployer\n    - djangoapp/\n      - settings.py\n      - manage.py\n      - urls.py\n      - mydjangoapp/\n        - models.py\n        - views.py\n        - urls.py\n    - charms/precise/django-deploy-charm\n      - hooks/\n      - files/\n      - templates/\n      - config.yaml\n      - metadata.yaml\n      - README\n      - revision\n</code></pre>\n<p>The <strong>djangoapp</strong> directory houses my django application and <strong>charms/precise/django-deploy-charm</strong> is my local charm that handles all of the Juju hooks necessary to get my environment up.</p>\n<h1>PART UNO: Configuring your Django application</h1>\n<h2>Enable importing of database overrides from Juju</h2>\n<p>Edit <strong>settings.py</strong> and append the following:</p>\n<pre><code>  # Import juju_settings.py for DB overrides in juju environments\n  try:\n      from djangoapp.juju_settings import *\n  except ImportError:\n      pass\n</code></pre>\n<p>This will override the default database so you can choose to ignore the current databases stanza in the <strong>settings.py</strong> file.</p>\n<h2>Enable Django to properly prefix URLS if coming from an SSL Referer</h2>\n<p>This is the first part of telling Django to expect requests from the Apache reverse proxy over HTTPS.</p>\n<p>Edit <strong>settings.py</strong> and add the following somewhere after the python import statements. (location of this is probably optional, but, im cautious so we add it at the beginning)</p>\n<pre><code>  # Make sure that if we have an SSL referer in the headers that DJANGO\n  # prefixes all urls with HTTPS\n\n  SECURE_PROXY_SSL_HEADER = ('HTTP_X_FORWARDED_PROTO', 'https')\n</code></pre>\n<p>Remember that added bonus? Go ahead and define the necessary Launchpad.net bits</p>\n<p>For Django to work with Launchpad's SSO service you'll want to make sure that <strong>django-openid-auth</strong> is installed. This will be handled by Juju and I'll show you that in <strong>PART DOS</strong>.</p>\n<p>Again edit <strong>settings.py</strong> to include the following OpenID configuration items.</p>\n<pre><code>  ALLOWED_EXTERNAL_OPENID_REDIRECT_DOMAINS = [&amp;#39;lvh.me&amp;#39;, &amp;#39;localhost&amp;#39;, &amp;#39;yourfqdn.com&amp;#39;]\n</code></pre>\n<p>For development purposes I usually use lvh.me to associate a fqdn with my loopback.</p>\n<p>Add the authorization backend to the <strong>AUTHENTICATION_BACKENDS</strong> tuple:</p>\n<pre><code>  # Add support for django-openid-auth\n  AUTHENTICATION_BACKENDS = (\n      &amp;#39;django_openid_auth.auth.OpenIDBackend&amp;#39;,\n      &amp;#39;django.contrib.auth.backends.ModelBackend&amp;#39;,\n  )\n</code></pre>\n<p>Add some helpful options to associating Launchpad accounts with user accounts in your django app.</p>\n<pre><code>  OPENID_CREATE_USERS = True\n  OPENID_UPDATE_DETAILS_FROM_SREG = True\n  OPENID_SSO_SERVER_URL = &amp;#39;https://login.launchpad.net/&amp;#39;\n  OPENID_USE_AS_ADMIN_LOGIN = True\n\n  # The launchpad teams and staff_teams  were manually created at launchpad.net\n  OPENID_LAUNCHPAD_TEAMS_REQUIRED = [\n      &amp;#39;debugmonkeys&amp;#39;,\n      &amp;#39;canonical&amp;#39;,\n  ]\n  OPENID_LAUNCHPAD_STAFF_TEAMS = (\n      &amp;#39;debugmonkeys&amp;#39;,\n  )\n  OPENID_STRICT_USERNAMES = True\n  OPENID_USE_EMAIL_FOR_USERNAME = True\n</code></pre>\n<p>Set the <strong>LOGIN_URL</strong> path to where redirected users will go to login.</p>\n<pre><code>  LOGIN_URL = &amp;#39;/openid/login/&amp;#39;\n  LOGIN_REDIRECT_URL = &amp;#39;/&amp;#39;\n&lt;h2 id=\"summaryofpartuno\"&gt;Summary of Part UNO&lt;/h2&gt; \n</code></pre>\n<p>This configuration will have your django application prepped for juju deployment with the ability to authenticate against launchpad.net and automatically associate the postgres database settings.</p>\n<h1>PART DOS: Configure and deploy your juju charm</h1>\n<h2>Defining your config and metadata options</h2>\n<p>In <strong>config.yaml</strong> youll want to make sure the following options are defined and set:</p>\n<pre><code>  options:\n    requirements:\n      type: string\n      default: &amp;#34;requirements.txt&amp;#34;\n      description: |\n        The relative path to the requirement file. Note that the charm\n        won&amp;#39;t manually upgrade packages defined in this file.\n    instance_type:\n      default: &amp;#34;staging&amp;#34;\n      type: string\n      description: |\n        Selects if we&amp;#39;re deploying to production or development.\n        production == deploying to prodstack\n        staging == local development (lxc/private cloud)\n    user_code_runner:\n        default: &amp;#34;webguy&amp;#34;\n        type: string\n        description: The user that runs the code\n    group_code_runner:\n        default: &amp;#34;webguy&amp;#34;\n        type: string\n        description: The group that runs the code\n    user_code_owner:\n        default: &amp;#34;webops_deploy&amp;#34;\n        type: string\n        description: The user that owns the code\n    group_code_owner:\n        default: &amp;#34;webops_deploy&amp;#34;\n        type: string\n        description: The group that owns the code\n    app_payload:\n      type: string\n      description: |\n        Filename to use to extract the actual django application.\n        This file must be in the files/ directory.\n      default: &amp;#34;djangoapp.tar.bz2&amp;#34;\n    web_app_admin:\n      type: string\n      description: Web application admin email\n      default: &amp;#34;webguy@example.com&amp;#34;\n    wsgi_wsgi_file:\n      type: string\n      description: &amp;#34;The name of the WSGI application.&amp;#34;\n      default: &amp;#34;wsgi&amp;#34;\n    wsgi_worker_class:\n      type: string\n      default: &amp;#34;gevent&amp;#34;\n      description: &amp;#34;Gunicorn workers type. (eventlet|gevent|tornado)&amp;#34;\n</code></pre>\n<p>In the <strong>metadata.yaml</strong> file we need to define the relation information, create that file with the following:</p>\n<pre><code>  name: django-deploy-charm\n  maintainer: [Adam Stokes &amp;#38;lt;adam.stokes@ubuntu.com&amp;#38;gt;]\n  summary: My Django project\n  description: |\n    Django website for My Django App\n  provides:\n    website:\n      interface: http\n    wsgi:\n      interface: wsgi\n      scope: container\n  requires:\n    db:\n      interface: pgsql\n</code></pre>\n<p>The <strong>revision</strong> file keeps a positive integer to let Juju know that a new revision with changes are available. It is also recommended to add a <strong>README</strong> laying out the juju deploy steps for getting your charm up and running.</p>\n<h2>Write your charm hooks</h2>\n<p>This is where the magic happens, all charm hooks will reside in the <strong>hooks</strong> directory and should be executable.</p>\n<h2>A common include file</h2>\n<p>Rather than repeating the defining of variables over and over we'll just source it from a common include file. Create a file called <strong>common.sh</strong> and add the following:</p>\n<pre><code>  #!/bin/bash\n\n  UNIT_NAME=$(echo $JUJU_UNIT_NAME | cut -d/ -f1)\n  UNIT_DIR=/srv/${UNIT_NAME}\n\n  DJANGO_APP_PAYLOAD=$(config-get app_payload)\n  INSTANCE_TYPE=$(config-get instance_type)\n\n  USER_CODE_RUNNER=$(config-get user_code_runner)\n  GROUP_CODE_RUNNER=$(config-get group_code_runner)\n  USER_CODE_OWNER=$(config-get user_code_owner)\n  GROUP_CODE_OWNER=$(config-get group_code_owner)\n\n  function ctrl_service {\n      # Check if there is an upstart or sysvinit service defined and issue the\n      # requested command if there is. This is used to control services in a\n      # friendly way when errexit is on.\n      service_name=$1\n      service_cmd=$2\n      ( service --status-all 2&amp;#38;gt;1 | grep -w $service_name ) &amp;#38;amp;&amp;#38;amp; service $service_name $service_cmd\n      ( initctl list 2&amp;#38;gt;1 | grep -w $service_name ) &amp;#38;amp;&amp;#38;amp; service $service_name $service_cmd\n      return 0\n  }\n</code></pre>\n<h3>The <strong>install</strong> hook This hook handles the extracting, package installation, and permission settings.</h3>\n<pre><code>  #!/bin/bash\n\n  source ${CHARM_DIR}/hooks/common.sh\n\n  juju-log &amp;#34;Jujuing ${UNIT_NAME}&amp;#34;\n\n  ###############################################################################\n  # Directory Structure\n  ###############################################################################\n  function inflate {\n      juju-log &amp;#34;Creating directory structure&amp;#34;\n      mkdir -p ${UNIT_DIR}\n  }\n\n  ###############################################################################\n  #  User / Group permissions\n  ###############################################################################\n  function set_perms {\n      juju-log &amp;#34;Setting permissions&amp;#34;\n\n      getent group ${GROUP_CODE_RUNNER} ${GROUP_CODE_OWNER} &amp;#38;gt;&amp;#38;gt; /dev/null\n      if [[ $? -eq 2 ]]; then\n          addgroup --quiet $GROUP_CODE_OWNER\n          addgroup --quiet $GROUP_CODE_RUNNER\n      fi\n\n      # Check if the users already exists and create a new user if it doesn&amp;#39;t\n      if [[ ! `users` =~ ${USER_CODE_OWNER} ]]; then\n    adduser --quiet --system --disabled-password --ingroup \\\n              ${GROUP_CODE_OWNER} ${USER_CODE_OWNER}\n      fi\n      if [[ ! `users` =~ ${USER_CODE_RUNNER} ]]; then\n    adduser --quiet --system --disabled-password --ingroup \\\n              ${GROUP_CODE_RUNNER} ${USER_CODE_RUNNER}\n      fi\n\n      chown -R $USER_CODE_OWNER:$GROUP_CODE_OWNER ${UNIT_DIR}\n\n      usermod -G www-data ${GROUP_CODE_RUNNER}\n\n  }\n\n  ###############################################################################\n  # Project Install\n  ###############################################################################\n  function app_install {\n      tar -xf ${CHARM_DIR}/files/${DJANGO_APP_PAYLOAD} -C ${UNIT_DIR}\n\n      juju-log &amp;#34;Installing required packages.&amp;#34;\n      # Additional supporting packages\n      /usr/bin/apt-add-repository -y ppa:gunicorn/ppa\n\n      # Common packages between instances\n      common_pkgs=&amp;#34;python-pip python-dev build-essential libpq-dev python-django python-dateutil python-psycopg2 python-jinja2 pwgen ssl-cert gunicorn&amp;#34;\n      # Silence apt-get\n      export DEBIAN_FRONTEND=noninteractive\n      REQUIREMENTS=$(config-get requirements)\n      if [[ ${INSTANCE_TYPE} == &amp;#39;production&amp;#39; ]]; then\n    apt-get -qq update\n\n    # Install required packages\n    apt-get -qq install -y python-amqplib python-anyjson \\\n        python-bzrlib python-celery python-cherrypy \\\n        python-django-celery python-django-openid-auth \\\n        python-django-south python-launchpadlib python-oauth python-openid \\\n        python-psycopg2 python-requests-oauthlib python-urllib3 python-salesforce \\\n        python-cheetah ${common_pkgs}\n      else\n    apt-get -qq update\n    apt-get -qq install -y ${common_pkgs}\n    pip install -q -r ${UNIT_DIR}/${REQUIREMENTS} || true\n      fi\n  }\n\n  ###############################################################################\n  # MAIN\n  # Steps\n  # -----\n  # 1) inflate - build directory stucture\n  # 2) app_install - install bits\n  # 3) set_perms - finalizes permission settings\n  ###############################################################################\n  inflate\n  app_install\n  set_perms\n</code></pre>\n<p>One thing to notice in the <strong>app_install</strong> function is that we are extracting our django application from within the <strong>files/</strong> directory. In order to make this work you'll want to manually tar up your django application and place it into that <strong>files</strong> directory.</p>\n<pre><code>  # Make sure we are a level above the djangoapp directory\n  $ cd /home/adam/deployer\n  $ tar cjf charms/precise/seg-dashboard/files/djangoapp.tar.bz2 -C djangoapp .\n&lt;h2 id=\"the\\_\\_config-changed\\_\\_hook\"&gt;The \n</code></pre>\n<p><strong>config-changed</strong> hook</h2>\n<p> This handles the configuring and populating of the django application. Here we are just concerned with symlinking the static assets from the django application.</p>\n<pre><code>  ###############################################################################\n  # WEB Application Config\n  # 1) Setup django application specific directory\n  # 2) Symlinks admin media directory\n  ###############################################################################\n  # 1)\n  SETTINGS_PY=&amp;#34;${UNIT_DIR}/settings.py&amp;#34;\n\n  # 2)\n  PYTHON_DJANGO_LIB=`python -c &amp;#34;import django; print(django.__path__[0])&amp;#34;`\n  mkdir -p /var/www/static\n  if [ ! -L /var/www/static/admin ]; then\n      ln -s ${PYTHON_DJANGO_LIB}/contrib/admin/static/admin /var/www/static/admin\n  fi\n&lt;h2 id=\"the\\_\\_db-relation-changed\\_\\_hook\"&gt;The \n</code></pre>\n<p><strong>db-relation-changed</strong> hook</h2>\n<p> This hook is where we define our Postgresql database settings to be included by the django application.</p>\n<pre><code>  #!/bin/bash\n\n  # Update the juju_settings.py with the new database credentials\n  source ${CHARM_DIR}/hooks/common.sh\n\n  ###############################################################################\n  # Export Database settings\n  ###############################################################################\n  export DBHOST=`relation-get host`\n  export DBNAME=`relation-get database`\n  export DBUSER=`relation-get user`\n  export DBPASSWD=`relation-get password`\n\n  # All values are set together, so checking on a single value is enough\n  # If $db_user is not set, DB is still setting itself up, we exit awaiting \n  # next run.\n  [ -z &amp;#34;$DBUSER&amp;#34; ] &amp;#38;amp;&amp;#38;amp; exit 0\n\n  cheetah fill --env -p templates/juju_settings.tmpl \\\n      &amp;#38;gt; ${UNIT_DIR}/juju_settings.py\n\n  # Setup database\n  python ${UNIT_DIR}/manage.py syncdb --noinput\n\n  # Create admin fixture\n  cheetah compile --env -p templates/juju_fixtures.tmpl \\\n      &amp;#38;gt; templates/juju_fixtures.py\n  python templates/juju_fixtures.py \\\n      &amp;#38;gt; ${UNIT_DIR}/juju_fixtures.json\n\n  python ${UNIT_DIR}/manage.py loaddata ./juju_fixtures.json\n\n  juju-log &amp;#34;Updating database(${DBNAME}) credentials and importing fixtures&amp;#34;\n\n  ctrl_service gunicorn restart\n</code></pre>\n<p>As you can see we are processing a few templates to import into the django settings and load an admin fixture into the database.</p>\n<h3>The &#42;&#42;juju_settings&#42;&#42; file {#the&#95;&#95;juju_settings&#95;&#95;file}</h3>\n<p>This is the database configuration and should reside in the <strong>templates</strong> directory. Edit <strong>juju_settings.tmpl</strong> and populate with the following:</p>\n<pre><code>  # Generated by db-relation-changed hook\n\n  # Pull in the project&amp;#39;s default settings\n  from djangoapp.settings import *\n\n  # Overrite the database settings\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;ENGINE&amp;#39;] = &amp;#39;django.db.backends.postgresql_psycopg2&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;HOST&amp;#39;] = &amp;#39;${DBHOST}&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;NAME&amp;#39;] = &amp;#39;${DBNAME}&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;USER&amp;#39;] = &amp;#39;${DBUSER}&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;PASSWORD&amp;#39;] = &amp;#39;${DBPASSWD}&amp;#39;\n&lt;h3 id=\"the\\_\\_juju_fixtures\\_\\_file\"&gt;The \n</code></pre>\n<p><strong>juju_fixtures</strong> file</h3>\n<p> Edit <strong>juju_fixtures.tmpl</strong> and add the following:</p>\n<pre><code>  &amp;#38;lt;%\n  import json\n  from subprocess import Popen, PIPE\n\n  def quickrun(cmd):\n      temp = Popen(cmd, stdout=PIPE).communicate()[0]\n      return temp.rstrip()\n\n  adminpasswd = quickrun([&amp;#39;pwgen&amp;#39;, &amp;#39;-s&amp;#39;, &amp;#39;64&amp;#39;, &amp;#39;1&amp;#39;])\n  timestamp = quickrun([&amp;#39;date&amp;#39;, &amp;#39;+%F %R&amp;#39;])\n\n  fixture = { &amp;#34;pk&amp;#34; : 1,\n              &amp;#34;model&amp;#34; : &amp;#34;auth.user&amp;#34;,\n              &amp;#34;fields&amp;#34; : { &amp;#34;username&amp;#34; : &amp;#34;admin&amp;#34;,\n                           &amp;#34;password&amp;#34; : adminpasswd,\n                           &amp;#34;email&amp;#34; : &amp;#34;&amp;#34;,\n                           &amp;#34;first_name&amp;#34; : &amp;#34;&amp;#34;,\n                           &amp;#34;last_name&amp;#34; : &amp;#34;&amp;#34;,\n                           &amp;#34;is_active&amp;#34; : True,\n                           &amp;#34;is_superuser&amp;#34; : True,\n                           &amp;#34;is_staff&amp;#34; : True,\n                           &amp;#34;last_login&amp;#34; : &amp;#34;now&amp;#34;,\n                           &amp;#34;groups&amp;#34; : [],\n                           &amp;#34;user_permissions&amp;#34; : [],\n                           &amp;#34;date_joined&amp;#34; : timestamp\n                           }\n              }\n\n  print json.dumps(fixture)\n  %&amp;#38;gt;\n&lt;h2 id=\"the\\_\\_website-relation-joined\\_\\_and\\_\\_website-relation-changed\\_\\_\"&gt;The \n</code></pre>\n<p><strong>website-relation-joined</strong> and <strong>website-relation-changed</strong></h2>\n<p> The changed hook is just a symlink to <strong>website-relation-joined</strong> in this case. Edit your <strong>website-relation-joined</strong> file and add the following:</p>\n<pre><code>  #!/bin/bash\n\n  unit_name=${JUJU_UNIT_NAME//\\//-}\n\n  relation-set port=8080 hostname=`unit-get private-address`\n  relation-set all_services=&amp;#34;\n    - {service_name: gunicorn, service_port: 8080}\n  &amp;#34;\n</code></pre>\n<p>We are making sure that apache will have access to the private IP and PORT of the gunicorn application server.</p>\n<h2>The &#42;&#42;wsgi-relation-changed&#42;&#42; and &#42;&#42;wsgi-relation-joined&#42;&#42; {#the&#95;&#95;wsgi-relation-changed&#95;&#95;and&#95;&#95;wsgi-relation-joined&#95;&#95;}</h2>\n<p>Again the changed hook is symlinked to the joined hook. Edit <strong>wsgi-relation-joined</strong> and add the following:</p>\n<pre><code>  #!/bin/bash\n\n  UNIT_NAME=`echo $JUJU_UNIT_NAME | cut -d/ -f1`\n\n  relation-set working_dir=&amp;#34;/srv/${UNIT_NAME}/&amp;#34;\n  relation-set django_settings=&amp;#34;${UNIT_DIR}/settings.py&amp;#34;\n  relation-set python_path=`python -c &amp;#34;import django; print(django.__path__[0])&amp;#34;`\n\n  variables=&amp;#34;wsgi_wsgi_file wsgi_workers wsgi_worker_class wsgi_worker_connections wsgi_max_requests wsgi_timeout wsgi_backlog wsgi_keep_alive wsgi_extra wsgi_user wsgi_group wsgi_umask wsgi_log_file wsgi_log_level wsgi_access_logfile wsgi_access_logformat port&amp;#34;\n\n  declare -A VAR\n  for v in $variables;do\n    VAR[$v]=$(config-get $v)\n    if [ ! -z &amp;#34;${VAR[$v]}&amp;#34; ] ; then\n      relation-set &amp;#34;$v=${VAR[$v]}&amp;#34;\n    fi\n  done\n\n  juju-log &amp;#34;Set relation variables: ${VAR[@]}&amp;#34;\n\n  service gunicorn restart\n</code></pre>\n<p>Here the <strong>gunicorn</strong> charm expects a <strong>working_dir</strong> and a <strong>wsgi</strong> interface. These are set with the above relations and also a loop is provided if any other gunicorn options were to be overriden from the defaults provided in that charm.</p>\n<h2>The &#42;&#42;apache_vhost&#42;&#42; template {#the&#95;&#95;apache_vhost&#95;&#95;template}</h2>\n<p>The apache2 virtualhost stanza that will ultimately provide the outside world access to your django application. Edit <strong>apache_vhost.tmpl</strong> and add the following:</p>\n<pre><code>  # Managed by juju\n    &amp;#38;lt; VirtualHost *:80 &amp;#38;gt;\n      ServerName      {{ servername }}\n      Redirect permanent / https://{{ servername }}/\n    &amp;#38;lt; /VirtualHost &amp;#38;gt;\n\n    &amp;#38;lt; VirtualHost {{ servername }}:443 &amp;#38;gt;\n      ServerName      {{ servername }}\n      ServerAdmin     admin@example.com\n\n      CustomLog       /var/log/djangoapp-custom.log combined\n      ErrorLog        /var/log/djangoapp-error.log\n\n\n      SSLEngine on\n      SSLCertificateFile /etc/ssl/certs/ssl-cert-cts.pem\n      SSLCertificateKeyFile /etc/ssl/private/ssl-cert-cts.key\n\n      RequestHeader set X-FORWARDED-SSL &amp;#34;on&amp;#34;\n\n      # This ensures django is seeing the https protocol\n      # and prefixing all URLS with https\n\n      RequestHeader set X-FORWARDED_PROTO &amp;#34;https&amp;#34;\n\n      ProxyRequests off\n      ProxyPreserveHost on\n      &amp;#38;lt;Proxy *&amp;#38;gt;\n          Order Allow,Deny\n          Allow from All\n      &amp;#38;lt;/Proxy&amp;#38;gt;\n\n      ProxyPass / http://{{ djangoapp_gunicorn }}/\n      ProxyPassReverse / http://{{ djangoapp_gunicorn }}/\n    &amp;#38;lt; /VirtualHost &amp;#38;gt;\n</code></pre>\n<p>The items such as SSL, Header modification, and Proxy support are loaded through the apache configuration charm which is discussed below.</p>\n<h2 id=\"summaryofthehooks\">Summary of the hooks</h2>\n<p>These hooks provide the groundwork for making the rest of the deployment possible. I realize some of the templates aren't making sense at the moment but read further to link the missing pieces.</p>\n<h2 id=\"thejujuenvironmentsetup\">The Juju environment setup</h2>\n<p>Once the hooks are done and youve compressed a tarball of your django application and have it sitting in your <strong>files/</strong> directory it is time to bootstrap juju and get on our way to deploying. I am assuming no pre-existing juju setup exists. In the case that you have Juju defined for other things then skip the bootstrap.</p>\n<h2 id=\"bootstrapyourjujuenvironment\">Bootstrap your Juju environment</h2>\n<pre><code>  $ juju bootstrap\n</code></pre>\n<p>This will create a sample <strong>~/.juju/environments.yaml</strong> file that you can alter. Mine looks like the following for an LXC setup.</p>\n<pre><code>  environments:\n    sample:\n      type: local\n      control-bucket: juju-364887954bed48b590b9b6bd112a842a\n      admin-secret: fa8d276204ab4be4b3666cc5afe3bd21\n      default-series: precise\n      ssl-hostname-verification: true\n      data-dir: /home/adam/jujuimgs\n&lt;h2 id=\"deploytheapplicationcharm\"&gt;Deploy the application charm&lt;/h2&gt; \n</code></pre>\n<p>From your toplevel directory, in my case <strong>/home/adam/deployer</strong> execute the following to get the django application deployed.</p>\n<pre><code>  $ juju deploy --repository ./charms local:django-deploy-charm\n&lt;h2 id=\"deploytheapplicationservergunicornandsetuptherelationbetweentheapplicationandapplicationserver\"&gt;Deploy the application server (gunicorn) and setup the relation between the application and application server&lt;/h2&gt; \n\n  $ juju deploy gunicorn\n  $ juju add-relation gunicorn django-deploy-charm\n&lt;h2 id=\"deployapache2andaddtherelationtotheapplicationforreverseproxyingtowork\"&gt;Deploy apache2 and add the relation to the application for reverse proxying to work&lt;/h2&gt; \n\n  $ juju deploy apache2\n  $ juju add-relation apache2:reverseproxy django-deploy-charm\n&lt;h3 id=\"configuretheapache2charmtoloadourvirtualhostandautogeneratethenecessarycertificatesforsslsupport\"&gt;Configure the Apache2 charm to load our Virtual Host and auto generate the necessary certificates for SSL support&lt;/h3&gt; \n\n  $ juju set apache2 &amp;#34;vhost_https_template=$(base64 &amp;#38;lt; templates/apache_vhost.tmpl)&amp;#34;\n  $ juju set apache2 &amp;#34;enable_modules=ssl proxy proxy_http proxy_connect rewrite headers&amp;#34;\n  $ juju set apache2 &amp;#34;ssl_keylocation=ssl-cert-cts.key&amp;#34;\n  $ juju set apache2 &amp;#34;ssl_certlocation=ssl-cert-cts.pem&amp;#34;\n  $ juju set apache2 &amp;#34;ssl_cert=SELFSIGNED&amp;#34;\n</code></pre>\n<p>All of these options are explained in the README of the <strong>apache2</strong> charm. But what this does is basically load a jinja2 supported template, enables the necessary modules in apache for proxy, ssl, and header modification support. Since we are doing a <strong>SELFSIGNED</strong> certificate for development and testing we set the filenames of the certificate and have the <strong>apache2</strong> charm generate the certificates automatically.</p>\n<h2 id=\"deploypostgresqlandsetupthedatabaserelationtoourapplication\">Deploy postgresql and set up the database relation to our application</h2>\n<pre><code>  $ juju deploy postgresql\n  $ juju add-relation django-deploy-charm:db postgresql:db\n&lt;h2 id=\"exposeourapache2servicetotheworld\"&gt;Expose our Apache2 service to the world&lt;/h2&gt; \n\n  $ juju expose apache2\n&lt;h1 id=\"tada\"&gt;Tada&lt;/h1&gt; \n</code></pre>\n<p>After about 5 or 10 minutes all the services should be deployed and you can get the public facing IP of the apache server by the following:</p>\n<pre><code>  $ juju status apache2\n</code></pre>\n<p>For completeness this is what a fully deployed juju stack should look like:</p>\n<pre><code>  machines:\n    0:\n      agent-state: running\n      dns-name: localhost\n      instance-id: local\n      instance-state: running\n  services:\n    apache2:\n      charm: cs:precise/apache2-11\n      exposed: true\n      relations:\n        reverseproxy:\n        - django-deploy-charm\n      units:\n        apache2/0:\n          agent-state: started\n          machine: 0\n          open-ports:\n          - 80/tcp\n          - 443/tcp\n          public-address: 10.0.3.218\n    gunicorn:\n      charm: cs:precise/gunicorn-7\n      relations:\n        wsgi-file:\n        - django-deploy-charm\n      subordinate: true\n      subordinate-to:\n      - django-deploy-charm\n    postgresql:\n      charm: cs:precise/postgresql-30\n      exposed: false\n      relations:\n        replication:\n        - postgresql\n      units:\n        postgresql/0:\n          agent-state: started\n          machine: 0\n          public-address: 10.0.3.119\n    django-deploy-charm:\n      charm: local:precise/django-deploy-charm-8\n      relations:\n        website:\n        - apache2\n        wsgi:\n        - gunicorn\n      units:\n        django-deploy-charm/2:\n          agent-state: started\n          machine: 0\n          public-address: 10.0.3.208\n          relations:\n            wsgi:\n            - gunicorn\n          subordinates:\n            gunicorn/2:\n              agent-state: started\n</code></pre>\n<p>In this case if I go to <strong>https://10.0.3.218</strong> it should bring up your custom django application. If youve setup authentication with Launchpad.net like in the above example visiting <strong>https://10.0.3.218/openid/login</strong> should redirect your to Launchpad's SSO service and allow you authenticate and redirect back to your django application.</p>\n<h2>Contributors welcomed!</h2>\n<p>If you would like to checkout the source for the charm itself you can see it on <a href=\"https://github.com/battlemidget/juju-apache-gunicorn-django.git\">Github</a>. Would love to make this charm general enough to give people a great starting point for setting up their environments. If modifications to the document are needed please post in the comments section and Ill get those implemented.</p>\n<h2>Things not done</h2>\n<ul>\n<li>This tutorial doesn't cover how to setup static files as the static files live on the application server and not the apache server itself.</li>\n<li>I am aware there is a <strong>django</strong> charm that could easily be used in place of taring up your django application, it would be worth looking into that charm to further your deployment options.</li>\n<li>Not tested with Golang version of Juju since LXC support is not available <strong>yet</strong></li>\n</ul>\n",
      "date": "2013-07-14T22:02:00",
      "title": "Juju deploy Apache2+SSL, Gunicorn, Django, Postgresql",
      "tags": [
        "ubuntu",
        "linux",
        "python",
        "juju",
        "shellscript",
        "django"
      ],
      "author": "Adam Stokes",
      "path": "juju-end-to-end-deployment-apache2ssl-gunicorn-django-postgresql",
      "compiled": "<p><p>Goal of this document is to explain how <a href=\"https://wiki.ubuntu.com/christopherarges\">Chris Arges</a> and I managed to get Apache w/SSL proxy to gunicorn which is serving up a django application with postgresql as the database and everything be deployable through Juju.</p></p>\n<p><p>As an added bonus I&#39;ll also show you how to utilize Launchpad.net&#39;s SSO to enable authentication to your web application.</p></p>\n<p><p>I will also break this document up into 2 parts with the first part concentrating on configuring your django application for deployment and the other doing the actual bootstrapping and deployment. Make sure you read the document in its entirety since they rely on each other to properly work.</p></p>\n<p><h1>Pre-requisites</h1></p>\n<ul>\n<li>Ubuntu 12.04</li>\n<li>Juju 0.7</li>\n<li>You&#39;ll want to have an existing django project created which uses postgresql as the database backend. I won&#39;t go into details on setting that up since this focuses purely on deploying with Juju, but, <a href=\"https://docs.djangoproject.com/en/1.4/intro/install/\">Django</a> documentation is excellent in getting up and running.</li>\n</ul>\n<p>The rest of the necessary bits are handled by Juju.</p>\n<h1>The environment</h1>\n<p>In this document I use LXC as the containers for juju deployment. You could easily use AWS or any other supported cloud technologies. The directory layout for this tutorial looks like this:</p>\n<pre><code>  - /home/adam/deployer\n    - djangoapp/\n      - settings.py\n      - manage.py\n      - urls.py\n      - mydjangoapp/\n        - models.py\n        - views.py\n        - urls.py\n    - charms/precise/django-deploy-charm\n      - hooks/\n      - files/\n      - templates/\n      - config.yaml\n      - metadata.yaml\n      - README\n      - revision\n</code></pre>\n<p>The <strong>djangoapp</strong> directory houses my django application and <strong>charms/precise/django-deploy-charm</strong> is my local charm that handles all of the Juju hooks necessary to get my environment up.</p>\n<h1>PART UNO: Configuring your Django application</h1>\n<h2>Enable importing of database overrides from Juju</h2>\n<p>Edit <strong>settings.py</strong> and append the following:</p>\n<pre><code>  # Import juju<em>settings.py for DB overrides in juju environments\n  try:\n      from djangoapp.juju_settings import *\n  except ImportError:\n      pass\n</code></pre>\n<p>This will override the default database so you can choose to ignore the current databases stanza in the <strong>settings.py</strong> file.</p>\n<h2>Enable Django to properly prefix URLS if coming from an SSL Referer</h2>\n<p>This is the first part of telling Django to expect requests from the Apache reverse proxy over HTTPS.</p>\n<p>Edit <strong>settings.py</strong> and add the following somewhere after the python import statements. (location of this is probably optional, but, im cautious so we add it at the beginning)</p>\n<pre><code>  # Make sure that if we have an SSL referer in the headers that DJANGO\n  # prefixes all urls with HTTPS\n\n  SECURE_PROXY_SSL_HEADER = (&#39;HTTP_X_FORWARDED_PROTO&#39;, &#39;https&#39;)\n</code></pre>\n<p>Remember that added bonus? Go ahead and define the necessary Launchpad.net bits</p>\n<p>For Django to work with Launchpad&#39;s SSO service you&#39;ll want to make sure that <strong>django-openid-auth</strong> is installed. This will be handled by Juju and I&#39;ll show you that in <strong>PART DOS</strong>.</p>\n<p>Again edit <strong>settings.py</strong> to include the following OpenID configuration items.</p>\n<pre><code>  ALLOWED_EXTERNAL_OPENID_REDIRECT_DOMAINS = [&amp;#39;lvh.me&amp;#39;, &amp;#39;localhost&amp;#39;, &amp;#39;yourfqdn.com&amp;#39;]\n</code></pre>\n<p>For development purposes I usually use lvh.me to associate a fqdn with my loopback.</p>\n<p>Add the authorization backend to the <strong>AUTHENTICATION_BACKENDS</strong> tuple:</p>\n<pre><code>  # Add support for django-openid-auth\n  AUTHENTICATION_BACKENDS = (\n      &amp;#39;django_openid_auth.auth.OpenIDBackend&amp;#39;,\n      &amp;#39;django.contrib.auth.backends.ModelBackend&amp;#39;,\n  )\n</code></pre>\n<p>Add some helpful options to associating Launchpad accounts with user accounts in your django app.</p>\n<pre><code>  OPENID_CREATE_USERS = True\n  OPENID_UPDATE_DETAILS_FROM_SREG = True\n  OPENID_SSO_SERVER_URL = &amp;#39;<a href=\"https://login.launchpad.net/&amp;#39\">https://login.launchpad.net/&amp;#39</a>;\n  OPENID_USE_AS_ADMIN_LOGIN = True\n\n  # The launchpad teams and staff_teams  were manually created at launchpad.net\n  OPENID_LAUNCHPAD_TEAMS_REQUIRED = [\n      &amp;#39;debugmonkeys&amp;#39;,\n      &amp;#39;canonical&amp;#39;,\n  ]\n  OPENID_LAUNCHPAD_STAFF_TEAMS = (\n      &amp;#39;debugmonkeys&amp;#39;,\n  )\n  OPENID_STRICT_USERNAMES = True\n  OPENID_USE_EMAIL_FOR_USERNAME = True\n</code></pre>\n<p>Set the <strong>LOGIN_URL</strong> path to where redirected users will go to login.</p>\n<pre><code>  LOGIN_URL = &amp;#39;/openid/login/&amp;#39;\n  LOGIN_REDIRECT_URL = &amp;#39;/&amp;#39;\n&lt;h2 id=&quot;summaryofpartuno&quot;&gt;Summary of Part UNO&lt;/h2&gt; \n</code></pre>\n<p>This configuration will have your django application prepped for juju deployment with the ability to authenticate against launchpad.net and automatically associate the postgres database settings.</p>\n<h1>PART DOS: Configure and deploy your juju charm</h1>\n<h2>Defining your config and metadata options</h2>\n<p>In <strong>config.yaml</strong> youll want to make sure the following options are defined and set:</p>\n<pre><code>  options:\n    requirements:\n      type: string\n      default: &amp;#34;requirements.txt&amp;#34;\n      description: |\n        The relative path to the requirement file. Note that the charm\n        won&amp;#39;t manually upgrade packages defined in this file.\n    instance_type:\n      default: &amp;#34;staging&amp;#34;\n      type: string\n      description: |\n        Selects if we&amp;#39;re deploying to production or development.\n        production == deploying to prodstack\n        staging == local development (lxc/private cloud)\n    user_code_runner:\n        default: &amp;#34;webguy&amp;#34;\n        type: string\n        description: The user that runs the code\n    group_code_runner:\n        default: &amp;#34;webguy&amp;#34;\n        type: string\n        description: The group that runs the code\n    user_code_owner:\n        default: &amp;#34;webops_deploy&amp;#34;\n        type: string\n        description: The user that owns the code\n    group_code_owner:\n        default: &amp;#34;webops_deploy&amp;#34;\n        type: string\n        description: The group that owns the code\n    app_payload:\n      type: string\n      description: |\n        Filename to use to extract the actual django application.\n        This file must be in the files/ directory.\n      default: &amp;#34;djangoapp.tar.bz2&amp;#34;\n    web_app_admin:\n      type: string\n      description: Web application admin email\n      default: &amp;#34;webguy@example.com&amp;#34;\n    wsgi_wsgi_file:\n      type: string\n      description: &amp;#34;The name of the WSGI application.&amp;#34;\n      default: &amp;#34;wsgi&amp;#34;\n    wsgi_worker_class:\n      type: string\n      default: &amp;#34;gevent&amp;#34;\n      description: &amp;#34;Gunicorn workers type. (eventlet|gevent|tornado)&amp;#34;\n</code></pre>\n<p>In the <strong>metadata.yaml</strong> file we need to define the relation information, create that file with the following:</p>\n<pre><code>  name: django-deploy-charm\n  maintainer: [Adam Stokes &amp;#38;lt;adam.stokes@ubuntu.com&amp;#38;gt;]\n  summary: My Django project\n  description: |\n    Django website for My Django App\n  provides:\n    website:\n      interface: http\n    wsgi:\n      interface: wsgi\n      scope: container\n  requires:\n    db:\n      interface: pgsql\n</code></pre>\n<p>The <strong>revision</strong> file keeps a positive integer to let Juju know that a new revision with changes are available. It is also recommended to add a <strong>README</strong> laying out the juju deploy steps for getting your charm up and running.</p>\n<h2>Write your charm hooks</h2>\n<p>This is where the magic happens, all charm hooks will reside in the <strong>hooks</strong> directory and should be executable.</p>\n<h2>A common include file</h2>\n<p>Rather than repeating the defining of variables over and over we&#39;ll just source it from a common include file. Create a file called <strong>common.sh</strong> and add the following:</p>\n<pre><code>  #!/bin/bash\n\n  UNIT_NAME=$(echo $JUJU_UNIT_NAME | cut -d/ -f1)\n  UNIT_DIR=/srv/${UNIT_NAME}\n\n  DJANGO_APP_PAYLOAD=$(config-get app_payload)\n  INSTANCE_TYPE=$(config-get instance_type)\n\n  USER_CODE_RUNNER=$(config-get user_code_runner)\n  GROUP_CODE_RUNNER=$(config-get group_code_runner)\n  USER_CODE_OWNER=$(config-get user_code_owner)\n  GROUP_CODE_OWNER=$(config-get group_code_owner)\n\n  function ctrl_service {\n      # Check if there is an upstart or sysvinit service defined and issue the\n      # requested command if there is. This is used to control services in a\n      # friendly way when errexit is on.\n      service_name=$1\n      service_cmd=$2\n      ( service --status-all 2&amp;#38;gt;1 | grep -w $service_name ) &amp;#38;amp;&amp;#38;amp; service $service_name $service_cmd\n      ( initctl list 2&amp;#38;gt;1 | grep -w $service_name ) &amp;#38;amp;&amp;#38;amp; service $service_name $service_cmd\n      return 0\n  }\n</code></pre>\n<h3>The <strong>install</strong> hook This hook handles the extracting, package installation, and permission settings.</h3>\n<pre><code>  #!/bin/bash\n\n  source ${CHARM_DIR}/hooks/common.sh\n\n  juju-log &amp;#34;Jujuing ${UNIT_NAME}&amp;#34;\n\n  ###############################################################################\n  # Directory Structure\n  ###############################################################################\n  function inflate {\n      juju-log &amp;#34;Creating directory structure&amp;#34;\n      mkdir -p ${UNIT_DIR}\n  }\n\n  ###############################################################################\n  #  User / Group permissions\n  ###############################################################################\n  function set_perms {\n      juju-log &amp;#34;Setting permissions&amp;#34;\n\n      getent group ${GROUP_CODE_RUNNER} ${GROUP_CODE_OWNER} &amp;#38;gt;&amp;#38;gt; /dev/null\n      if [[ $? -eq 2 ]]; then\n          addgroup --quiet $GROUP_CODE_OWNER\n          addgroup --quiet $GROUP_CODE_RUNNER\n      fi\n\n      # Check if the users already exists and create a new user if it doesn&amp;#39;t\n      if [[ ! <code>users</code> =~ ${USER_CODE_OWNER} ]]; then\n    adduser --quiet --system --disabled-password --ingroup \\\n              ${GROUP_CODE_OWNER} ${USER_CODE_OWNER}\n      fi\n      if [[ ! <code>users</code> =~ ${USER_CODE_RUNNER} ]]; then\n    adduser --quiet --system --disabled-password --ingroup \\\n              ${GROUP_CODE_RUNNER} ${USER_CODE_RUNNER}\n      fi\n\n      chown -R $USER_CODE_OWNER:$GROUP_CODE_OWNER ${UNIT_DIR}\n\n      usermod -G www-data ${GROUP_CODE_RUNNER}\n\n  }\n\n  ###############################################################################\n  # Project Install\n  ###############################################################################\n  function app_install {\n      tar -xf ${CHARM_DIR}/files/${DJANGO_APP_PAYLOAD} -C ${UNIT_DIR}\n\n      juju-log &amp;#34;Installing required packages.&amp;#34;\n      # Additional supporting packages\n      /usr/bin/apt-add-repository -y ppa:gunicorn/ppa\n\n      # Common packages between instances\n      common_pkgs=&amp;#34;python-pip python-dev build-essential libpq-dev python-django python-dateutil python-psycopg2 python-jinja2 pwgen ssl-cert gunicorn&amp;#34;\n      # Silence apt-get\n      export DEBIAN_FRONTEND=noninteractive\n      REQUIREMENTS=$(config-get requirements)\n      if [[ ${INSTANCE_TYPE} == &amp;#39;production&amp;#39; ]]; then\n    apt-get -qq update\n\n    # Install required packages\n    apt-get -qq install -y python-amqplib python-anyjson \\\n        python-bzrlib python-celery python-cherrypy \\\n        python-django-celery python-django-openid-auth \\\n        python-django-south python-launchpadlib python-oauth python-openid \\\n        python-psycopg2 python-requests-oauthlib python-urllib3 python-salesforce \\\n        python-cheetah ${common_pkgs}\n      else\n    apt-get -qq update\n    apt-get -qq install -y ${common_pkgs}\n    pip install -q -r ${UNIT_DIR}/${REQUIREMENTS} || true\n      fi\n  }\n\n  ###############################################################################\n  # MAIN\n  # Steps\n  # -----\n  # 1) inflate - build directory stucture\n  # 2) app_install - install bits\n  # 3) set_perms - finalizes permission settings\n  ###############################################################################\n  inflate\n  app_install\n  set_perms\n</code></pre>\n<p>One thing to notice in the <strong>app_install</strong> function is that we are extracting our django application from within the <strong>files/</strong> directory. In order to make this work you&#39;ll want to manually tar up your django application and place it into that <strong>files</strong> directory.</p>\n<pre><code>  # Make sure we are a level above the djangoapp directory\n  $ cd /home/adam/deployer\n  $ tar cjf charms/precise/seg-dashboard/files/djangoapp.tar.bz2 -C djangoapp .\n&lt;h2 id=&quot;the\\</em>_config-changed__hook&quot;&gt;The \n</code></pre>\n<p><strong>config-changed</strong> hook</h2>\n<p> This handles the configuring and populating of the django application. Here we are just concerned with symlinking the static assets from the django application.</p>\n<pre><code>  ###############################################################################\n  # WEB Application Config\n  # 1) Setup django application specific directory\n  # 2) Symlinks admin media directory\n  ###############################################################################\n  # 1)\n  SETTINGS<em>PY=&amp;#34;${UNIT<em>DIR}/settings.py&amp;#34;\n\n  # 2)\n  PYTHON<em>DJANGO_LIB=`python -c &amp;#34;import django; print(django.__path</em></em>[0])&amp;#34;`\n  mkdir -p /var/www/static\n  if [ ! -L /var/www/static/admin ]; then\n      ln -s ${PYTHON_DJANGO_LIB}/contrib/admin/static/admin /var/www/static/admin\n  fi\n&lt;h2 id=&quot;the\\</em>_db-relation-changed__hook&quot;&gt;The \n</code></pre>\n<p><strong>db-relation-changed</strong> hook</h2>\n<p> This hook is where we define our Postgresql database settings to be included by the django application.</p>\n<pre><code>  #!/bin/bash\n\n  # Update the juju<em>settings.py with the new database credentials\n  source ${CHARM_DIR}/hooks/common.sh\n\n  ###############################################################################\n  # Export Database settings\n  ###############################################################################\n  export DBHOST=<code>relation-get host</code>\n  export DBNAME=<code>relation-get database</code>\n  export DBUSER=<code>relation-get user</code>\n  export DBPASSWD=<code>relation-get password</code>\n\n  # All values are set together, so checking on a single value is enough\n  # If $db_user is not set, DB is still setting itself up, we exit awaiting \n  # next run.\n  [ -z &amp;#34;$DBUSER&amp;#34; ] &amp;#38;amp;&amp;#38;amp; exit 0\n\n  cheetah fill --env -p templates/juju_settings.tmpl \\\n      &amp;#38;gt; ${UNIT_DIR}/juju_settings.py\n\n  # Setup database\n  python ${UNIT_DIR}/manage.py syncdb --noinput\n\n  # Create admin fixture\n  cheetah compile --env -p templates/juju_fixtures.tmpl \\\n      &amp;#38;gt; templates/juju_fixtures.py\n  python templates/juju_fixtures.py \\\n      &amp;#38;gt; ${UNIT_DIR}/juju_fixtures.json\n\n  python ${UNIT_DIR}/manage.py loaddata ./juju_fixtures.json\n\n  juju-log &amp;#34;Updating database(${DBNAME}) credentials and importing fixtures&amp;#34;\n\n  ctrl_service gunicorn restart\n</code></pre>\n<p>As you can see we are processing a few templates to import into the django settings and load an admin fixture into the database.</p>\n<h3>The &#42;&#42;juju_settings&#42;&#42; file {#the&#95;&#95;juju_settings&#95;&#95;file}</h3>\n<p>This is the database configuration and should reside in the <strong>templates</strong> directory. Edit <strong>juju_settings.tmpl</strong> and populate with the following:</p>\n<pre><code>  # Generated by db-relation-changed hook\n\n  # Pull in the project&amp;#39;s default settings\n  from djangoapp.settings import *\n\n  # Overrite the database settings\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;ENGINE&amp;#39;] = &amp;#39;django.db.backends.postgresql_psycopg2&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;HOST&amp;#39;] = &amp;#39;${DBHOST}&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;NAME&amp;#39;] = &amp;#39;${DBNAME}&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;USER&amp;#39;] = &amp;#39;${DBUSER}&amp;#39;\n  DATABASES[&amp;#39;default&amp;#39;][&amp;#39;PASSWORD&amp;#39;] = &amp;#39;${DBPASSWD}&amp;#39;\n&lt;h3 id=&quot;the\\</em>_juju<em>fixtures\\</em>_file&quot;&gt;The \n</code></pre>\n<p><strong>juju<em>fixtures</strong> file</h3>\n<p> Edit <strong>juju_fixtures.tmpl</strong> and add the following:</p>\n<pre><code>  &amp;#38;lt;%\n  import json\n  from subprocess import Popen, PIPE\n\n  def quickrun(cmd):\n      temp = Popen(cmd, stdout=PIPE).communicate()[0]\n      return temp.rstrip()\n\n  adminpasswd = quickrun([&amp;#39;pwgen&amp;#39;, &amp;#39;-s&amp;#39;, &amp;#39;64&amp;#39;, &amp;#39;1&amp;#39;])\n  timestamp = quickrun([&amp;#39;date&amp;#39;, &amp;#39;+%F %R&amp;#39;])\n\n  fixture = { &amp;#34;pk&amp;#34; : 1,\n              &amp;#34;model&amp;#34; : &amp;#34;auth.user&amp;#34;,\n              &amp;#34;fields&amp;#34; : { &amp;#34;username&amp;#34; : &amp;#34;admin&amp;#34;,\n                           &amp;#34;password&amp;#34; : adminpasswd,\n                           &amp;#34;email&amp;#34; : &amp;#34;&amp;#34;,\n                           &amp;#34;first_name&amp;#34; : &amp;#34;&amp;#34;,\n                           &amp;#34;last_name&amp;#34; : &amp;#34;&amp;#34;,\n                           &amp;#34;is_active&amp;#34; : True,\n                           &amp;#34;is_superuser&amp;#34; : True,\n                           &amp;#34;is_staff&amp;#34; : True,\n                           &amp;#34;last_login&amp;#34; : &amp;#34;now&amp;#34;,\n                           &amp;#34;groups&amp;#34; : [],\n                           &amp;#34;user_permissions&amp;#34; : [],\n                           &amp;#34;date_joined&amp;#34; : timestamp\n                           }\n              }\n\n  print json.dumps(fixture)\n  %&amp;#38;gt;\n&lt;h2 id=&quot;the\\</em>_website-relation-joined__and__website-relation-changed__&quot;&gt;The \n</code></pre>\n<p><strong>website-relation-joined</strong> and <strong>website-relation-changed</strong></h2>\n<p> The changed hook is just a symlink to <strong>website-relation-joined</strong> in this case. Edit your <strong>website-relation-joined</strong> file and add the following:</p>\n<pre><code>  #!/bin/bash\n\n  unit<em>name=${JUJU<em>UNIT_NAME//\\//-}\n\n  relation-set port=8080 hostname=<code>unit-get private-address</code>\n  relation-set all_services=&amp;#34;\n    - {service_name: gunicorn, service_port: 8080}\n  &amp;#34;\n</code></pre>\n<p>We are making sure that apache will have access to the private IP and PORT of the gunicorn application server.</p>\n<h2>The &#42;&#42;wsgi-relation-changed&#42;&#42; and &#42;&#42;wsgi-relation-joined&#42;&#42; {#the&#95;&#95;wsgi-relation-changed&#95;&#95;and&#95;&#95;wsgi-relation-joined&#95;&#95;}</h2>\n<p>Again the changed hook is symlinked to the joined hook. Edit <strong>wsgi-relation-joined</strong> and add the following:</p>\n<pre><code>  #!/bin/bash\n\n  UNIT_NAME=<code>echo $JUJU_UNIT_NAME | cut -d/ -f1</code>\n\n  relation-set working_dir=&amp;#34;/srv/${UNIT_NAME}/&amp;#34;\n  relation-set django_settings=&amp;#34;${UNIT_DIR}/settings.py&amp;#34;\n  relation-set python_path=`python -c &amp;#34;import django; print(django.__path</em></em>[0])&amp;#34;`\n\n  variables=&amp;#34;wsgi_wsgi_file wsgi_workers wsgi_worker_class wsgi_worker_connections wsgi_max_requests wsgi_timeout wsgi_backlog wsgi_keep_alive wsgi_extra wsgi_user wsgi_group wsgi_umask wsgi_log_file wsgi_log_level wsgi_access_logfile wsgi_access_logformat port&amp;#34;\n\n  declare -A VAR\n  for v in $variables;do\n    VAR[$v]=$(config-get $v)\n    if [ ! -z &amp;#34;${VAR[$v]}&amp;#34; ] ; then\n      relation-set &amp;#34;$v=${VAR[$v]}&amp;#34;\n    fi\n  done\n\n  juju-log &amp;#34;Set relation variables: ${VAR[@]}&amp;#34;\n\n  service gunicorn restart\n</code></pre>\n<p>Here the <strong>gunicorn</strong> charm expects a <strong>working_dir</strong> and a <strong>wsgi</strong> interface. These are set with the above relations and also a loop is provided if any other gunicorn options were to be overriden from the defaults provided in that charm.</p>\n<h2>The &#42;&#42;apache_vhost&#42;&#42; template {#the&#95;&#95;apache_vhost&#95;&#95;template}</h2>\n<p>The apache2 virtualhost stanza that will ultimately provide the outside world access to your django application. Edit <strong>apache_vhost.tmpl</strong> and add the following:</p>\n<pre><code>  # Managed by juju\n    &amp;#38;lt; VirtualHost <em>:80 &amp;#38;gt;\n      ServerName      {{ servername }}\n      Redirect permanent / <a href=\"https://{{\">https://{{</a> servername }}/\n    &amp;#38;lt; /VirtualHost &amp;#38;gt;\n\n    &amp;#38;lt; VirtualHost {{ servername }}:443 &amp;#38;gt;\n      ServerName      {{ servername }}\n      ServerAdmin     admin@example.com\n\n      CustomLog       /var/log/djangoapp-custom.log combined\n      ErrorLog        /var/log/djangoapp-error.log\n\n\n      SSLEngine on\n      SSLCertificateFile /etc/ssl/certs/ssl-cert-cts.pem\n      SSLCertificateKeyFile /etc/ssl/private/ssl-cert-cts.key\n\n      RequestHeader set X-FORWARDED-SSL &amp;#34;on&amp;#34;\n\n      # This ensures django is seeing the https protocol\n      # and prefixing all URLS with https\n\n      RequestHeader set X-FORWARDED_PROTO &amp;#34;https&amp;#34;\n\n      ProxyRequests off\n      ProxyPreserveHost on\n      &amp;#38;lt;Proxy </em>&amp;#38;gt;\n          Order Allow,Deny\n          Allow from All\n      &amp;#38;lt;/Proxy&amp;#38;gt;\n\n      ProxyPass / <a href=\"http://{{\">http://{{</a> djangoapp_gunicorn }}/\n      ProxyPassReverse / <a href=\"http://{{\">http://{{</a> djangoapp_gunicorn }}/\n    &amp;#38;lt; /VirtualHost &amp;#38;gt;\n</code></pre>\n<p>The items such as SSL, Header modification, and Proxy support are loaded through the apache configuration charm which is discussed below.</p>\n<h2 id=\"summaryofthehooks\">Summary of the hooks</h2>\n<p>These hooks provide the groundwork for making the rest of the deployment possible. I realize some of the templates aren&#39;t making sense at the moment but read further to link the missing pieces.</p>\n<h2 id=\"thejujuenvironmentsetup\">The Juju environment setup</h2>\n<p>Once the hooks are done and youve compressed a tarball of your django application and have it sitting in your <strong>files/</strong> directory it is time to bootstrap juju and get on our way to deploying. I am assuming no pre-existing juju setup exists. In the case that you have Juju defined for other things then skip the bootstrap.</p>\n<h2 id=\"bootstrapyourjujuenvironment\">Bootstrap your Juju environment</h2>\n<pre><code>  $ juju bootstrap\n</code></pre>\n<p>This will create a sample <strong>~/.juju/environments.yaml</strong> file that you can alter. Mine looks like the following for an LXC setup.</p>\n<pre><code>  environments:\n    sample:\n      type: local\n      control-bucket: juju-364887954bed48b590b9b6bd112a842a\n      admin-secret: fa8d276204ab4be4b3666cc5afe3bd21\n      default-series: precise\n      ssl-hostname-verification: true\n      data-dir: /home/adam/jujuimgs\n&lt;h2 id=&quot;deploytheapplicationcharm&quot;&gt;Deploy the application charm&lt;/h2&gt; \n</code></pre>\n<p>From your toplevel directory, in my case <strong>/home/adam/deployer</strong> execute the following to get the django application deployed.</p>\n<pre><code>  $ juju deploy --repository ./charms local:django-deploy-charm\n&lt;h2 id=&quot;deploytheapplicationservergunicornandsetuptherelationbetweentheapplicationandapplicationserver&quot;&gt;Deploy the application server (gunicorn) and setup the relation between the application and application server&lt;/h2&gt; \n\n  $ juju deploy gunicorn\n  $ juju add-relation gunicorn django-deploy-charm\n&lt;h2 id=&quot;deployapache2andaddtherelationtotheapplicationforreverseproxyingtowork&quot;&gt;Deploy apache2 and add the relation to the application for reverse proxying to work&lt;/h2&gt; \n\n  $ juju deploy apache2\n  $ juju add-relation apache2:reverseproxy django-deploy-charm\n&lt;h3 id=&quot;configuretheapache2charmtoloadourvirtualhostandautogeneratethenecessarycertificatesforsslsupport&quot;&gt;Configure the Apache2 charm to load our Virtual Host and auto generate the necessary certificates for SSL support&lt;/h3&gt; \n\n  $ juju set apache2 &amp;#34;vhost_https_template=$(base64 &amp;#38;lt; templates/apache_vhost.tmpl)&amp;#34;\n  $ juju set apache2 &amp;#34;enable_modules=ssl proxy proxy_http proxy_connect rewrite headers&amp;#34;\n  $ juju set apache2 &amp;#34;ssl_keylocation=ssl-cert-cts.key&amp;#34;\n  $ juju set apache2 &amp;#34;ssl_certlocation=ssl-cert-cts.pem&amp;#34;\n  $ juju set apache2 &amp;#34;ssl_cert=SELFSIGNED&amp;#34;\n</code></pre>\n<p>All of these options are explained in the README of the <strong>apache2</strong> charm. But what this does is basically load a jinja2 supported template, enables the necessary modules in apache for proxy, ssl, and header modification support. Since we are doing a <strong>SELFSIGNED</strong> certificate for development and testing we set the filenames of the certificate and have the <strong>apache2</strong> charm generate the certificates automatically.</p>\n<h2 id=\"deploypostgresqlandsetupthedatabaserelationtoourapplication\">Deploy postgresql and set up the database relation to our application</h2>\n<pre><code>  $ juju deploy postgresql\n  $ juju add-relation django-deploy-charm:db postgresql:db\n&lt;h2 id=&quot;exposeourapache2servicetotheworld&quot;&gt;Expose our Apache2 service to the world&lt;/h2&gt; \n\n  $ juju expose apache2\n&lt;h1 id=&quot;tada&quot;&gt;Tada&lt;/h1&gt; \n</code></pre>\n<p>After about 5 or 10 minutes all the services should be deployed and you can get the public facing IP of the apache server by the following:</p>\n<pre><code>  $ juju status apache2\n</code></pre>\n<p>For completeness this is what a fully deployed juju stack should look like:</p>\n<pre><code>  machines:\n    0:\n      agent-state: running\n      dns-name: localhost\n      instance-id: local\n      instance-state: running\n  services:\n    apache2:\n      charm: cs:precise/apache2-11\n      exposed: true\n      relations:\n        reverseproxy:\n        - django-deploy-charm\n      units:\n        apache2/0:\n          agent-state: started\n          machine: 0\n          open-ports:\n          - 80/tcp\n          - 443/tcp\n          public-address: 10.0.3.218\n    gunicorn:\n      charm: cs:precise/gunicorn-7\n      relations:\n        wsgi-file:\n        - django-deploy-charm\n      subordinate: true\n      subordinate-to:\n      - django-deploy-charm\n    postgresql:\n      charm: cs:precise/postgresql-30\n      exposed: false\n      relations:\n        replication:\n        - postgresql\n      units:\n        postgresql/0:\n          agent-state: started\n          machine: 0\n          public-address: 10.0.3.119\n    django-deploy-charm:\n      charm: local:precise/django-deploy-charm-8\n      relations:\n        website:\n        - apache2\n        wsgi:\n        - gunicorn\n      units:\n        django-deploy-charm/2:\n          agent-state: started\n          machine: 0\n          public-address: 10.0.3.208\n          relations:\n            wsgi:\n            - gunicorn\n          subordinates:\n            gunicorn/2:\n              agent-state: started\n</code></pre>\n<p>In this case if I go to <strong><a href=\"https://10.0.3.218\">https://10.0.3.218</a></strong> it should bring up your custom django application. If youve setup authentication with Launchpad.net like in the above example visiting <strong><a href=\"https://10.0.3.218/openid/login\">https://10.0.3.218/openid/login</a></strong> should redirect your to Launchpad&#39;s SSO service and allow you authenticate and redirect back to your django application.</p>\n<h2>Contributors welcomed!</h2>\n<p>If you would like to checkout the source for the charm itself you can see it on <a href=\"https://github.com/battlemidget/juju-apache-gunicorn-django.git\">Github</a>. Would love to make this charm general enough to give people a great starting point for setting up their environments. If modifications to the document are needed please post in the comments section and Ill get those implemented.</p>\n<h2>Things not done</h2>\n<ul>\n<li>This tutorial doesn&#39;t cover how to setup static files as the static files live on the application server and not the apache server itself.</li>\n<li>I am aware there is a <strong>django</strong> charm that could easily be used in place of taring up your django application, it would be worth looking into that charm to further your deployment options.</li>\n<li>Not tested with Golang version of Juju since LXC support is not available <strong>yet</strong></li>\n</ul>\n"
    },
    {
      "body": "Remembering what to do in order to get your sbuild environment setup\nwith deb caching and configuring Barry Warsaws repotools for those\npackages not in the archive can be a little tedious at times.\n\nFor me I hated upgrading my systems knowing I had to re-setup my\nsbuild environments.\n\nIn order to streamline this I created a project to help package\nbuilders take some of these boilerplate stuff out of the way and just\ncreate the schroot and start your build.\n\nThis vagrant project was modeled after\n[SbuildSimple](https://wiki.ubuntu.com/SimpleSbuild). Please check\nthere for additional information on local packages.\n\nYou can find the project at\n[github](https://github.com/battlemidget/vagrant-sbuild)\n\n## Features\n\n*   supports lxc and virtualbox\n*   apt package caching for quicker builds\n*   automatically set maxcpus available to sbuild\n*   supports building packages against newer/custom local packages\n\nUsing it is fairly simple:\n\n## Setup\n\nInstall virtualbox\n\n`$ sudo apt-get install virtualbox`\n\nInstall [vagrant](http://downloads.vagrantup.com/)\n\nInstall vagrant-sbuild\n\n```bash\n$ git clone git://github.com:battlemidget/vagrant-sbuild.git\n$ cd vagrant-sbuild\n$ git submodule init\n$ git submodule update\n```\n\nInstall [vagrant-lxc](https://github.com/fgrehm/vagrant-lxc)\n\n`$ vagrant plugin install vagrant-lxc`\n\nSet some environment variables\n\n`export DEBEMAIL=Your Name < hi2u@mail.com > export DEBSIGN_KEY=123134`\n\n### Optional\n\nInstall [vagrant-cachier](https://github.com/fgrehm/vagrant-cachier) for improved performance\n\n`$ vagrant plugin install vagrant-cachier`\n\n**Note**: I havent personally tested this as apt-cacher-ng is running\n  for builds, however, for the provisioning itself it may be\n  beneficial if you are doing a lot of provisioning. Make sure you\n  read the **Vagrantfile** and uncomment the section that enables the\n  auto caching feature.\n\n## Vagrant boxes\n\nA list of lxc supported vagrant boxes can be found at the\n[Vagrant LXC wiki](https://github.com/fgrehm/vagrant-lxc/wiki/Base-boxes)\npage.\n\n## Usage\n\n`$ vagrant up`\n\n## Create sbuild environments\n\n`$ vagrant mk-sbuild --series saucy`\n\n## Perform builds\n\n`$ vagrant sbuild --project saucy-amd64 --dsc scratch/PACKAGE\\*.dsc`\n\nIf packages are required that are not in the archive you may place\nthem in the **repo/** directory and they will be included in any\nfuture builds.\n\nOnce complete the build packages should be in your **scratch/**\ndirectory and not once did you have to ssh into your vagrant box :D\n\n## Todo's\n\n*   setup vagrant multi-machine for each series\n*   include a config.yaml file for setting your debian maintainer info and other necessities.\n",
      "date": "2013-07-18T21:21:00",
      "title": "Streamline your build system with vagrant + sbuild",
      "tags": [
        "ubuntu",
        "linux",
        "sbuild",
        "vagrant"
      ],
      "author": "Adam Stokes",
      "path": "streamline-your-build-system-with-vagrant-sbuild",
      "compiled": "<p>Remembering what to do in order to get your sbuild environment setup\nwith deb caching and configuring Barry Warsaws repotools for those\npackages not in the archive can be a little tedious at times.</p>\n<p>For me I hated upgrading my systems knowing I had to re-setup my\nsbuild environments.</p>\n<p>In order to streamline this I created a project to help package\nbuilders take some of these boilerplate stuff out of the way and just\ncreate the schroot and start your build.</p>\n<p>This vagrant project was modeled after\n<a href=\"https://wiki.ubuntu.com/SimpleSbuild\">SbuildSimple</a>. Please check\nthere for additional information on local packages.</p>\n<p>You can find the project at\n<a href=\"https://github.com/battlemidget/vagrant-sbuild\">github</a></p>\n<h2 id=\"features\">Features</h2>\n<ul>\n<li>supports lxc and virtualbox</li>\n<li>apt package caching for quicker builds</li>\n<li>automatically set maxcpus available to sbuild</li>\n<li>supports building packages against newer/custom local packages</li>\n</ul>\n<p>Using it is fairly simple:</p>\n<h2 id=\"setup\">Setup</h2>\n<p>Install virtualbox</p>\n<p><code>$ sudo apt-get install virtualbox</code></p>\n<p>Install <a href=\"http://downloads.vagrantup.com/\">vagrant</a></p>\n<p>Install vagrant-sbuild</p>\n<pre><code class=\"lang-bash\"><span class=\"hljs-variable\">$ </span>git clone <span class=\"hljs-symbol\">git:</span>/<span class=\"hljs-regexp\">/github.com:battlemidget/vagrant</span>-sbuild.git\n<span class=\"hljs-variable\">$ </span>cd vagrant-sbuild\n<span class=\"hljs-variable\">$ </span>git submodule init\n<span class=\"hljs-variable\">$ </span>git submodule update\n</code></pre>\n<p>Install <a href=\"https://github.com/fgrehm/vagrant-lxc\">vagrant-lxc</a></p>\n<p><code>$ vagrant plugin install vagrant-lxc</code></p>\n<p>Set some environment variables</p>\n<p><code>export DEBEMAIL=Your Name &lt; hi2u@mail.com &gt; export DEBSIGN_KEY=123134</code></p>\n<h3 id=\"optional\">Optional</h3>\n<p>Install <a href=\"https://github.com/fgrehm/vagrant-cachier\">vagrant-cachier</a> for improved performance</p>\n<p><code>$ vagrant plugin install vagrant-cachier</code></p>\n<p><strong>Note</strong>: I havent personally tested this as apt-cacher-ng is running\n  for builds, however, for the provisioning itself it may be\n  beneficial if you are doing a lot of provisioning. Make sure you\n  read the <strong>Vagrantfile</strong> and uncomment the section that enables the\n  auto caching feature.</p>\n<h2 id=\"vagrant-boxes\">Vagrant boxes</h2>\n<p>A list of lxc supported vagrant boxes can be found at the\n<a href=\"https://github.com/fgrehm/vagrant-lxc/wiki/Base-boxes\">Vagrant LXC wiki</a>\npage.</p>\n<h2 id=\"usage\">Usage</h2>\n<p><code>$ vagrant up</code></p>\n<h2 id=\"create-sbuild-environments\">Create sbuild environments</h2>\n<p><code>$ vagrant mk-sbuild --series saucy</code></p>\n<h2 id=\"perform-builds\">Perform builds</h2>\n<p><code>$ vagrant sbuild --project saucy-amd64 --dsc scratch/PACKAGE\\*.dsc</code></p>\n<p>If packages are required that are not in the archive you may place\nthem in the <strong>repo/</strong> directory and they will be included in any\nfuture builds.</p>\n<p>Once complete the build packages should be in your <strong>scratch/</strong>\ndirectory and not once did you have to ssh into your vagrant box :D</p>\n<h2 id=\"todo-s\">Todo&#39;s</h2>\n<ul>\n<li>setup vagrant multi-machine for each series</li>\n<li>include a config.yaml file for setting your debian maintainer info and other necessities.</li>\n</ul>\n"
    },
    {
      "body": "<p><a href=\"https://github.com/sosreport/sosreport\">sosreport</a> v3.0 is now in <strong><em>Debian Unstable(Sid)</em></strong> and was synced this morning into <strong><em>Saucy</em></strong> (13.10). I've created some <a href=\"https://bugs.launchpad.net/raring-backports/+bug/1206118\">backport</a> requests to hopefully have sosreport put into Precise, Quantal, and Raring.</p>\n<p>Another goal of mine is to have sosreport included in the <strong>main</strong> archive so I've filed a <a href=\"https://bugs.launchpad.net/ubuntu/+source/sosreport/+bug/1206106\">MIR</a> request for that as well. If this is something that interests you please visit the <a href=\"https://bugs.launchpad.net/ubuntu/+source/sosreport/+bug/1206106\">MIR</a> and set to affects you. I would like to see this in <strong>main</strong> in time for the next LTS release.</p>\n<p>Development of <a href=\"https://github.com/sosreport/sosreport\">sosreport</a> is on-going and we encourage new contributions in any form, but, particularly interested in new plugins. We welcome you to fork the project and submit pull requests as this seems to be the easiest and most productive way to get code accepted into upstream.</p>\n<p>Finally, I'd like to thank those companies and its engineers who've contributed to the growth of sosreport. These companies include but are not limited to Canonical Ltd, EMC Corporation, Rackspace US, Inc., and Red Hat, Inc. You may find a list of all contributors in <strong>/usr/share/doc/sosreport/AUTHORS</strong>.</p>\n",
      "date": "2013-07-29T13:16:07",
      "title": "SOSreport now in Debian unstable(sid) and Ubuntu saucy",
      "tags": [
        "ubuntu",
        "linux",
        "debian",
        "sosreport"
      ],
      "author": "Adam Stokes",
      "path": "sosreport-now-in-debian-unstablesid-and-ubuntu-saucy",
      "compiled": "<p><a href=\"https://github.com/sosreport/sosreport\">sosreport</a> v3.0 is now in <strong><em>Debian Unstable(Sid)</em></strong> and was synced this morning into <strong><em>Saucy</em></strong> (13.10). I&#39;ve created some <a href=\"https://bugs.launchpad.net/raring-backports/+bug/1206118\">backport</a> requests to hopefully have sosreport put into Precise, Quantal, and Raring.</p>\n<p>Another goal of mine is to have sosreport included in the <strong>main</strong> archive so I&#39;ve filed a <a href=\"https://bugs.launchpad.net/ubuntu/+source/sosreport/+bug/1206106\">MIR</a> request for that as well. If this is something that interests you please visit the <a href=\"https://bugs.launchpad.net/ubuntu/+source/sosreport/+bug/1206106\">MIR</a> and set to affects you. I would like to see this in <strong>main</strong> in time for the next LTS release.</p>\n<p>Development of <a href=\"https://github.com/sosreport/sosreport\">sosreport</a> is on-going and we encourage new contributions in any form, but, particularly interested in new plugins. We welcome you to fork the project and submit pull requests as this seems to be the easiest and most productive way to get code accepted into upstream.</p>\n<p>Finally, I&#39;d like to thank those companies and its engineers who&#39;ve contributed to the growth of sosreport. These companies include but are not limited to Canonical Ltd, EMC Corporation, Rackspace US, Inc., and Red Hat, Inc. You may find a list of all contributors in <strong>/usr/share/doc/sosreport/AUTHORS</strong>.</p>\n"
    },
    {
      "body": "<p>I've spent some time working on a <a href=\"https://github.com/battlemidget/vimntu\">stupid simple script</a> that would install latest snapshot of VIM along with <a href=\"https://github.com/carlhuda/janus\">janus</a> and my additional plugins. It's really easy to get started, to install simply run:</p>\n<pre><code>$ curl -L https://github.com/battlemidget/vimntu/raw/master/vimntu | bash\n</code></pre>\n<p>You get all the modifications from <a href=\"https://github.com/carlhuda/janus\">janus</a> in addition to an extensive set of plugins activated through pathogen that gives extensive support to most of the major programming languages.</p>\n",
      "date": "2013-08-20T20:14:34",
      "title": "vimntu; easiest way to get up and running with vim",
      "tags": [
        "perl",
        "vim",
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "vimntu-easiest-way-to-get-up-and-running-with-vim",
      "compiled": "<p>I&#39;ve spent some time working on a <a href=\"https://github.com/battlemidget/vimntu\">stupid simple script</a> that would install latest snapshot of VIM along with <a href=\"https://github.com/carlhuda/janus\">janus</a> and my additional plugins. It&#39;s really easy to get started, to install simply run:</p>\n<pre><code>$ curl -L <a href=\"https://github.com/battlemidget/vimntu/raw/master/vimntu\">https://github.com/battlemidget/vimntu/raw/master/vimntu</a> | bash\n</code></pre>\n<p>You get all the modifications from <a href=\"https://github.com/carlhuda/janus\">janus</a> in addition to an extensive set of plugins activated through pathogen that gives extensive support to most of the major programming languages.</p>\n"
    },
    {
      "body": "<p>We&#39;ve got an aggressive feature list for the next milestone release and welcome any involvement from the community. A few of the big ticket items are the following:</p>\n<h2 id=&#34;toppriorityitems&#34;>Top priority items</h2>\n<ul>\n<li>Python 3.3 <em>and</em> Python 2.7 support - yes we&#39;d like to keep supporting older python versions if possible :)</li>\n<li>Sos object model archive (SOMA) - This feature is for allowing other applications interface with the data collected by sosreport.</li>\n<li>DBUS integration - We&#39;d like to have this feature so that controlling the behavior of sosreport is easily integrated into other systems.</li>\n</ul>\n<p>Additional <a href=&#34;https://github.com/sosreport/sosreport/issues?labels=high&#38;amp;milestone=2&#38;amp;page=1&#38;amp;state=open&#34;>high priority issues</a> are also available.</p>\n<h3 id=&#34;otherimportantitemstonote:&#34;>Other important items to note:</h3>\n<ul>\n<li><em>Plugins</em> - As technologies evolve and new software rises we are always welcoming new plugins to capture the necessary data to aid in debugging those technologies. If you&#39;ve got something in mind its just a simple <a href=&#34;https://github.com/sosreport/sosreport&#34;>pull request</a> away to get it on the right track for inclusion.</li>\n<li>Tests - Our goal is to be at 100% (I think we&#39;re at about 69%) coverage with a wide range of unittests. So if you fancy quality assurance then this is an excellent opportunity for you :D</li>\n</ul>\n<h3 id=&#34;moreinfo&#34;>More info</h3>\n<p>For more information and other issues scheduled to be fixed for the next release visit <a href=&#34;https://github.com/sosreport/sosreport/issues?milestone=2&#38;amp;state=open&#34;>sosreport issues</a></p>\n",
      "date": "2013-08-23T18:17:00",
      "title": "sosreport: on the road to 3.1",
      "tags": [
        "ubuntu",
        "linux",
        "sosreport"
      ],
      "author": "Adam Stokes",
      "path": "sosreport-on-the-road-to-3-1",
      "compiled": "<p>We&#39;ve got an aggressive feature list for the next milestone release and welcome any involvement from the community. A few of the big ticket items are the following:</p>\n<h2 id=&#34;toppriorityitems&#34;>Top priority items</h2>\n<ul>\n<li>Python 3.3 <em>and</em> Python 2.7 support - yes we&#39;d like to keep supporting older python versions if possible :)</li>\n<li>Sos object model archive (SOMA) - This feature is for allowing other applications interface with the data collected by sosreport.</li>\n<li>DBUS integration - We&#39;d like to have this feature so that controlling the behavior of sosreport is easily integrated into other systems.</li>\n</ul>\n<p>Additional <a href=&#34;https://github.com/sosreport/sosreport/issues?labels=high&#38;amp;milestone=2&#38;amp;page=1&#38;amp;state=open&#34;>high priority issues</a> are also available.</p>\n<h3 id=&#34;otherimportantitemstonote:&#34;>Other important items to note:</h3>\n<ul>\n<li><em>Plugins</em> - As technologies evolve and new software rises we are always welcoming new plugins to capture the necessary data to aid in debugging those technologies. If you&#39;ve got something in mind its just a simple <a href=&#34;https://github.com/sosreport/sosreport&#34;>pull request</a> away to get it on the right track for inclusion.</li>\n<li>Tests - Our goal is to be at 100% (I think we&#39;re at about 69%) coverage with a wide range of unittests. So if you fancy quality assurance then this is an excellent opportunity for you :D</li>\n</ul>\n<h3 id=&#34;moreinfo&#34;>More info</h3>\n<p>For more information and other issues scheduled to be fixed for the next release visit <a href=&#34;https://github.com/sosreport/sosreport/issues?milestone=2&#38;amp;state=open&#34;>sosreport issues</a></p>\n"
    },
    {
      "body": "<p>This is for the javascript version of js-beautify and could easily apply to their python version as well. You'll need to have node installed with npm and run the following:</p>\n<pre><code>$ sudo npm install -g js-beautify\n</code></pre>\n<p>Next, open up your emacs init file (<strong>~/.emacs.d/init.el</strong>) and add the following lisp code:</p>\n<pre><code>(defun jstidy ()\n  'Run js-beautify on the current region or buffer.'\n  (interactive)\n  (save-excursion\n    (unless mark-active (mark-defun))\n    (shell-command-on-region (point) (mark) 'js-beautify -f -'; nil t)))\n(global-set-key \"\\C-cg\" 'jstidy)\n</code></pre>\n<p>Once you've re-evaluated or restarted emacs the (<strong>CTRL+c then g</strong>) will be bound to the <em>jstidy</em> function.</p>\n<p>Finally, load up any javascript file and either mark a region or not and press the key commands to execute jstidy and you should see your code re-formatted nicely.</p>\n",
      "date": "2013-09-02T21:55:24",
      "title": "quickly beautify your javascript in emacs",
      "tags": [
        "javascript",
        "lisp",
        "emacs"
      ],
      "author": "Adam Stokes",
      "path": "quickly-beautify-your-javascript-in-emacs",
      "compiled": "<p>This is for the javascript version of js-beautify and could easily apply to their python version as well. You&#39;ll need to have node installed with npm and run the following:</p>\n<pre><code>$ sudo npm install -g js-beautify\n</code></pre>\n<p>Next, open up your emacs init file (<strong>~/.emacs.d/init.el</strong>) and add the following lisp code:</p>\n<pre><code>(defun jstidy ()\n  &#39;Run js-beautify on the current region or buffer.&#39;\n  (interactive)\n  (save-excursion\n    (unless mark-active (mark-defun))\n    (shell-command-on-region (point) (mark) &#39;js-beautify -f -&#39;; nil t)))\n(global-set-key &quot;\\C-cg&quot; &#39;jstidy)\n</code></pre>\n<p>Once you&#39;ve re-evaluated or restarted emacs the (<strong>CTRL+c then g</strong>) will be bound to the <em>jstidy</em> function.</p>\n<p>Finally, load up any javascript file and either mark a region or not and press the key commands to execute jstidy and you should see your code re-formatted nicely.</p>\n"
    },
    {
      "body": "<p>Released a new version of <strong>skryf</strong> a perl cms engine. Some features to highlight are:</p>\n<ul>\n<li>Markdown Editor</li>\n<li>Enhanced wiki plugin</li>\n<li>Extended csrf protection for forms and ajax requests</li>\n<li>Automated menu generator and hooks for new plugins</li>\n<li>Enhanced admin section for maintaining your cms</li>\n</ul>\n",
      "date": "2013-09-04T01:40:11",
      "title": "perl cms - skryf updated to version 0.12",
      "tags": [
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "perl-cms-skryf-updated-to-version-0-12",
      "compiled": "<p><p>Released a new version of <strong>skryf</strong> a perl cms engine. Some features to highlight are:</p></p>\n<ul>\n<li>Markdown Editor</li>\n<li>Enhanced wiki plugin</li>\n<li>Extended csrf protection for forms and ajax requests</li>\n<li>Automated menu generator and hooks for new plugins</li>\n<li>Enhanced admin section for maintaining your cms</li>\n</ul>\n"
    },
    {
      "body": "<p>Started working on a new Mojolicious plugin for integrating the popular javascript mapping library <a href=\"http://leafletjs.com\">leaflet.js</a>. You can find it on <a href=\"https://metacpan.org/release/ADAMJS/Mojolicious-Plugin-Leafletjs-0.001\">metacpan</a> or help with contributions at the <a href=\"https://github.com/battlemidget/Mojolicious-Plugin-Leafletjs\">github project page</a>.</p>\n<p>A quick synopsis of how to use it:</p>\n<pre><code># Mojolicious\n$self-&gt;plugin('Leafletjs');\n\n# Mojolicious::Lite\nplugin 'Leafletjs';\n\n# In your template\n&lt;%= leaflet {\n  name      =&gt; 'map1',\n  latitude =&gt; '35.9239',\n  longitude  =&gt; '-78.4611',\n  zoomLevel =&gt; 18,\n  markers   =&gt; [\n    {   name      =&gt; 'marker1',\n        latitude =&gt; '35.9239',\n        longitude  =&gt; '-78.4611',\n        popup     =&gt; 'A new message tada!',\n    },\n    {   name      =&gt; 'marker2',\n        latitude =&gt; '35.9235',\n        longitude  =&gt; '-78.4610',\n        popup     =&gt; 'A second popup here!',\n    }\n  ],\n}\n%&gt;\n</code></pre>\n<p>An example of a Mojolicious Lite application can be found in <a href=\"https://github.com/battlemidget/Mojolicious-Plugin-Leafletjs/tree/master/eg\">the examples directory on github</a></p>\n",
      "date": "2013-09-05T02:40:52",
      "title": "New mojolicious plugin: leaflet.js",
      "tags": [
        "perl",
        "leaflet",
        "web",
        "javascript",
        "cms",
        "blog",
        "library"
      ],
      "author": "Adam Stokes",
      "path": "new-mojolicious-plugin-leaflet-js",
      "compiled": "<p>Started working on a new Mojolicious plugin for integrating the popular javascript mapping library <a href=\"http://leafletjs.com\">leaflet.js</a>. You can find it on <a href=\"https://metacpan.org/release/ADAMJS/Mojolicious-Plugin-Leafletjs-0.001\">metacpan</a> or help with contributions at the <a href=\"https://github.com/battlemidget/Mojolicious-Plugin-Leafletjs\">github project page</a>.</p>\n<p>A quick synopsis of how to use it:</p>\n<pre><code># Mojolicious\n$self-&gt;plugin(&#39;Leafletjs&#39;);\n\n# Mojolicious::Lite\nplugin &#39;Leafletjs&#39;;\n\n# In your template\n&lt;%= leaflet {\n  name      =&gt; &#39;map1&#39;,\n  latitude =&gt; &#39;35.9239&#39;,\n  longitude  =&gt; &#39;-78.4611&#39;,\n  zoomLevel =&gt; 18,\n  markers   =&gt; [\n    {   name      =&gt; &#39;marker1&#39;,\n        latitude =&gt; &#39;35.9239&#39;,\n        longitude  =&gt; &#39;-78.4611&#39;,\n        popup     =&gt; &#39;A new message tada!&#39;,\n    },\n    {   name      =&gt; &#39;marker2&#39;,\n        latitude =&gt; &#39;35.9235&#39;,\n        longitude  =&gt; &#39;-78.4610&#39;,\n        popup     =&gt; &#39;A second popup here!&#39;,\n    }\n  ],\n}\n%&gt;\n</code></pre>\n<p>An example of a Mojolicious Lite application can be found in <a href=\"https://github.com/battlemidget/Mojolicious-Plugin-Leafletjs/tree/master/eg\">the examples directory on github</a></p>\n"
    },
    {
      "body": "<p>This article covers the steps I took to run a <a href=\"http://maas.ubuntu.com\">MAAS</a> instance within <a href=\"http://vagrantup.com\">vagrant</a>.</p>\n<p>I think of this more like the most direct and reproducable approach I could think of. You could build off of this and automate a lot of the installation tasks with a vagrant provisioner like puppet, chef, saltstack, or ansible. In my case I like to use <a href=\"http://www.ansibleworks.com/\">Ansible</a> which is written by Michael DeHaan who wrote <a href=\"https://fedorahosted.org/func/\">func</a> back in the day. I loved func and ansible feels more at home to me.</p>\n<h1>Installing and configuring MAAS</h1>\n<h2>Software used</h2>\n<ul>\n<li>Ubuntu Precise 12.04 (latest updates)</li>\n<li>vagrant 1.3.x</li>\n<li><a href=\"https://github.com/fgrehm/vagrant-lxc\">vagrant lxc</a></li>\n<li>maas</li>\n<li>lxc</li>\n</ul>\n<h2>Install lxc</h2>\n<pre><code>% sudo apt-get install lxc\n</code></pre>\n<h2>Install Vagrant</h2>\n<p>Download and install vagrant via <a href=\"http://downloads.vagrantup.com/tags/v1.3.3\">vagrant install link</a></p>\n<pre><code>% wget http://files.vagrantup.com/packages/0ac2a87388419b989c3c0d0318cc97df3b0ed27d/vagrant_1.3.4_x86_64.deb\n% sudo dpkg -i vagrant_1.3.4_x86_64.deb\n</code></pre>\n<h2>Install vagrant-lxc</h2>\n<pre><code>% vagrant plugin install vagrant-lxc\n</code></pre>\n<h2>Install a lxc supported vagrant box</h2>\n<pre><code>% vagrant box add precise64 http://bit.ly/vagrant-lxc-precise64-2013-09-28\n</code></pre>\n<h2>Create a Vagrantfile</h2>\n<p>Add the following into your <strong>Vagrantfile</strong></p>\n<pre><code>Vagrant.configure(\"2\") do |config|\n  config.vm.box = \"precise64\"\n  config.vm.provider :lxc do |lxc|\n    lxc.customize 'cgroup.memory.limit_in_bytes', '1024M'\n    lxc.customize 'cgroup.devices.allow', 'b 7:* rwm'\n    lxc.customize 'cgroup.devices.allow', 'c 10:237 rwm'\n  end\nend\n</code></pre>\n<h2>Cache sudo password</h2>\n<p>There is a <a href=\"http://www.sudo.ws/repos/sudo/file/c158df7cd9d2/NEWS#l523\">bug</a> that prevents sudo password from being cached on sudo &lt; 1.8.4. To get around this the vagrant-lxc <a href=\"https://github.com/fgrehm/vagrant-lxc/wiki/Avoiding-%27sudo%27-passwords\">wiki page</a> suggests the following:</p>\n<pre><code># Load up visudo and append the following\n% sudo visudo\nDefaults !tty_tickets\n</code></pre>\n<h2>Run the vagrant box</h2>\n<pre><code>% vagrant up --provider=lxc\n</code></pre>\n<h2>SSH into the vagrant box</h2>\n<pre><code>% vagrant ssh\n</code></pre>\n<h2>Add additional repository</h2>\n<p>A <strong>ubuntu-cloud</strong> archive exists for providing the latest juju, maas, etc bits on precise. Enable this to get the latest MAAS versions.</p>\n<pre><code>vagrant@precise-base:~$ sudo apt-get install -qy ubuntu-cloud-keyring &lt;/dev/null\nvagrant@precise-base:~$ sudo tee /etc/apt/sources.list.d/cloud-tools-precise.list &lt;&lt;EOF\ndeb http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main\ndeb-src http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main\nEOF\n</code></pre>\n<h2>Update the repository and install MAAS</h2>\n<pre><code>vagrant@precise-base:~$ sudo apt-get update \nvagrant@precise-base:~$ sudo apt-get install maas maas-dhcp maas-dns\n</code></pre>\n<h2>Create your MAAS superuser</h2>\n<pre><code>vagrant@precise-base:~$ sudo maas createsuperuser\n</code></pre>\n<p>It's a pain doing this many times over, pulled this tip from <a href=\"http://source.mihelac.org/2009/10/23/django-avoiding-typing-password-for-superuser/\">Bojan Mihelac</a></p>\n<pre><code>echo \"from django.contrib.auth.models import User; User.objects.create_superuser('admin', 'admin@example.com', 'pass')\" | sudo maas shell\n</code></pre>\n<h2>Login to your MAAS UI</h2>\n<p>In your web browser visit the IP (something like http://10.0.3.32/MAAS) of the vagrant box to log into your MAAS instance.</p>\n<h2>Import your boot images</h2>\n<p>Once logged in click on the <strong>cog</strong> icon in the top right hand corner.</p>\n<p><a href=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS.png\" alt=\"maas settings\" width=\"189\" height=\"159\" class=\"alignnone size-full wp-image-286\" /></a></p>\n<p>On the settings page just under <strong>Cluster controllers</strong> click the <strong>import boot images</strong> button.</p>\n<p><a href=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS-1.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS-1.png\" alt=\"maas import boot images\" width=\"670\" height=\"114\" class=\"alignnone size-full wp-image-287\" /></a></p>\n<p>This will take awhile to run so maybe go get some coffee.</p>\n<p>If you want to speed things up a bit edit <code>/etc/maas/import_pxe_files</code> with the following</p>\n<pre><code>vagrant@precise-base:~$ cat /etc/maas/import_pxe_files \n# This file replaces an older one called import_isos.  Include that here for\n# compatibility.\nif [ -f /etc/maas/import_isos ]\nthen\n    cat &gt;&amp;2 &lt;&lt;EOF\n\nIncluding obsolete /etc/maas/import_isos in configuration.  This file has been\nsuperseded by import_pxe_files.  Please see if it can be removed.\n\nEOF\n    . /etc/maas/import_isos\nfi\n\n\nRELEASES=\"precise\"\nARCHES=\"amd64/generic\"\nLOCALE=\"en_US\"\n#IMPORT_EPHEMERALS=1\n</code></pre>\n<h2>Cluster interface configuration</h2>\n<p>Once the boot images are done you are ready to configure one of the network interfaces to be managed by MAAS. Click on the edit icon under <strong>Cluster controllers</strong>. In the <strong>Edit Cluster Controller</strong> page click on the edit icon next to the interface you'd like to configure. In this case I am using <strong>eth0</strong>. <a href=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Controller-precise-base-MAAS.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Controller-precise-base-MAAS.png\" alt=\"Edit cluster interface\" width=\"594\" height=\"192\" class=\"alignnone size-full wp-image-290\" /></a></p>\n<p>On the next page titled <strong>Edit Cluster Interface</strong> we are going to set <strong>eth0</strong> to manage <strong>dhcp</strong> and <strong>dns</strong> along with entering the ip information for our network. Since vagrant is using 10.0.3.32 as its IP we'll set the rest according to that. <a href=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Interface-precise-base-MAAS-1.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Interface-precise-base-MAAS-1.png\" alt=\"Edit Cluster Interface   precise-base MAAS (1)\" width=\"605\" height=\"704\" class=\"alignnone size-full wp-image-336\" /></a></p>\n<h2>Troubleshooting</h2>\n<h3>DBusException error with avahi</h3>\n<pre><code>DBusException: org.freedesktop.DBus.Error.NameHasNoOwner: Could not get owner of name 'org.freedesktop.Avahi': no such name\n</code></pre>\n<h3>Solution</h3>\n<p>Comment out <strong>rlimit-nproc</strong> in <code>/etc/avahi/avahi-daemon.conf</code>, then start the service. <a href=\"http://sourceforge.net/mailarchive/message.php?msg_id=29200350\">See here</a> for more information on this issue and user namespaces in lxc.</p>\n<pre><code>vagrant@precise-base:~$ sudo service avahi-daemon restart\n</code></pre>\n<h3>Failing to mount ephemeral image</h3>\n<pre><code>precise-ephemeral-maas-amd64.img\nmount: Could not find any loop device. Maybe this kernel does not know\n       about the loop device? (If so, recompile or `modprobe loop'.)\nTue, 01 Oct 2013 19:33:58 +0000: failed to mount /tmp/uec2roottar.MmKLTg/precise-ephemeral-maas-amd64.img\nfailed to create root image\nfailed to prepare image for precise/amd64\n</code></pre>\n<h3>Solution</h3>\n<p>Per <a href=\"http://www.mail-archive.com/lxc-users@lists.sourceforge.net/msg03673.html\">this post</a></p>\n<ol>\n<li>Copy <code>/etc/apparmor.d/lxc/lxc-default</code> to <code>/etc/apparmor.d/lxc/lxc-default-with-loops</code></li>\n<li>Edit <code>/etc/apparmor.d/lxc/lxc-default-with-loops</code>\n<ul>\n<li>Rename lxc-container-default to lxc-container-default-with-loops</li>\n<li>Add an entry: <code>\"mount -&gt; /tmp/*/*,\"</code> or matching the source node, fstype,</li>\n</ul>\n</li>\n<li><code>% sudo /etc/init.d/apparmor reload</code></li>\n<li>Edit your container's configuration and set lxc.aa_profile to lxc-container-default-with-loops\n<ul>\n<li><strong>Note</strong>: this would be <code>lxc.customize \"aa_profile\", \"lxc-container-default-with-loops\"</code> in your <strong>Vagrantfile</strong></li>\n</ul>\n</li>\n<li>Restart your container</li>\n</ol>\n<h1>Conclusion</h1>\n<p>That's pretty much it! Whether this is actually useful remains to be seen. Nevertheless, this was a good learning experience for me. :) Oh and if you read this far down I did automate most of this which you can find over at my <a href=\"https://github.com/battlemidget/vagrant-maas\">github vagrant-maas repo</a>.</p>\n<pre><code>% git clone git://github.com:battlemidget/vagrant-maas.git\n% cd vagrant-maas\n% vagrant plugin install vagrant-lxc\n% vagrant box add precise64 http://bit.ly/vagrant-lxc-precise64-2013-09-28\n% vagrant up --provider=lxc --provision-with ansible\n% vagrant provision\n</code></pre>\n",
      "date": "2013-10-02T13:29:00",
      "title": "Run MAAS in Vagrant",
      "tags": [
        "python",
        "juju",
        "maas",
        "vagrant",
        "metal-as-a-service",
        "precise",
        "12.04",
        "cloud-in-a-box"
      ],
      "author": "Adam Stokes",
      "path": "running-maas-vagrant",
      "compiled": "<p><p>This article covers the steps I took to run a <a href=\"http://maas.ubuntu.com\">MAAS</a> instance within <a href=\"http://vagrantup.com\">vagrant</a>.</p></p>\n<p><p>I think of this more like the most direct and reproducable approach I could think of. You could build off of this and automate a lot of the installation tasks with a vagrant provisioner like puppet, chef, saltstack, or ansible. In my case I like to use <a href=\"http://www.ansibleworks.com/\">Ansible</a> which is written by Michael DeHaan who wrote <a href=\"https://fedorahosted.org/func/\">func</a> back in the day. I loved func and ansible feels more at home to me.</p></p>\n<p><h1>Installing and configuring MAAS</h1></p>\n<p><h2>Software used</h2></p>\n<p><ul></p>\n<p><li>Ubuntu Precise 12.04 (latest updates)</li></p>\n<p><li>vagrant 1.3.x</li></p>\n<p><li><a href=\"https://github.com/fgrehm/vagrant-lxc\">vagrant lxc</a></li></p>\n<p><li>maas</li></p>\n<p><li>lxc</li>\n</ul></p>\n<p><h2>Install lxc</h2></p>\n<pre><code>% sudo apt-get install lxc\n</code></pre>\n<h2>Install Vagrant</h2>\n<p>Download and install vagrant via <a href=\"http://downloads.vagrantup.com/tags/v1.3.3\">vagrant install link</a></p>\n<pre><code>% wget http://files.vagrantup.com/packages/0ac2a87388419b989c3c0d0318cc97df3b0ed27d/vagrant_1.3.4_x86_64.deb\n% sudo dpkg -i vagrant_1.3.4_x86_64.deb\n</code></pre>\n<h2>Install vagrant-lxc</h2>\n<pre><code>% vagrant plugin install vagrant-lxc\n</code></pre>\n<h2>Install a lxc supported vagrant box</h2>\n<pre><code>% vagrant box add precise64 http://bit.ly/vagrant-lxc-precise64-2013-09-28\n</code></pre>\n<h2>Create a Vagrantfile</h2>\n<p>Add the following into your <strong>Vagrantfile</strong></p>\n<pre><code>Vagrant.configure(\"2\") do |config|\n  config.vm.box = \"precise64\"\n  config.vm.provider :lxc do |lxc|\n    lxc.customize 'cgroup.memory.limit_in_bytes', '1024M'\n    lxc.customize 'cgroup.devices.allow', 'b 7:* rwm'\n    lxc.customize 'cgroup.devices.allow', 'c 10:237 rwm'\n  end\nend\n</code></pre>\n<h2>Cache sudo password</h2>\n<p>There is a <a href=\"http://www.sudo.ws/repos/sudo/file/c158df7cd9d2/NEWS#l523\">bug</a> that prevents sudo password from being cached on sudo &lt; 1.8.4. To get around this the vagrant-lxc <a href=\"https://github.com/fgrehm/vagrant-lxc/wiki/Avoiding-%27sudo%27-passwords\">wiki page</a> suggests the following:</p>\n<pre><code># Load up visudo and append the following\n% sudo visudo\nDefaults !tty_tickets\n</code></pre>\n<h2>Run the vagrant box</h2>\n<pre><code>% vagrant up --provider=lxc\n</code></pre>\n<h2>SSH into the vagrant box</h2>\n<pre><code>% vagrant ssh\n</code></pre>\n<h2>Add additional repository</h2>\n<p>A <strong>ubuntu-cloud</strong> archive exists for providing the latest juju, maas, etc bits on precise. Enable this to get the latest MAAS versions.</p>\n<pre><code>vagrant@precise-base:~$ sudo apt-get install -qy ubuntu-cloud-keyring &lt;/dev/null\nvagrant@precise-base:~$ sudo tee /etc/apt/sources.list.d/cloud-tools-precise.list &lt;&lt;EOF\ndeb http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main\ndeb-src http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main\nEOF\n</code></pre>\n<h2>Update the repository and install MAAS</h2>\n<pre><code>vagrant@precise-base:~$ sudo apt-get update \nvagrant@precise-base:~$ sudo apt-get install maas maas-dhcp maas-dns\n</code></pre>\n<h2>Create your MAAS superuser</h2>\n<pre><code>vagrant@precise-base:~$ sudo maas createsuperuser\n</code></pre>\n<p>It's a pain doing this many times over, pulled this tip from <a href=\"http://source.mihelac.org/2009/10/23/django-avoiding-typing-password-for-superuser/\">Bojan Mihelac</a></p>\n<pre><code>echo \"from django.contrib.auth.models import User; User.objects.create_superuser('admin', 'admin@example.com', 'pass')\" | sudo maas shell\n</code></pre>\n<h2>Login to your MAAS UI</h2>\n<p>In your web browser visit the IP (something like http://10.0.3.32/MAAS) of the vagrant box to log into your MAAS instance.</p>\n<h2>Import your boot images</h2>\n<p>Once logged in click on the <strong>cog</strong> icon in the top right hand corner.</p>\n<p><a href=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS.png\" alt=\"maas settings\" width=\"189\" height=\"159\" class=\"alignnone size-full wp-image-286\" /></a></p>\n<p>On the settings page just under <strong>Cluster controllers</strong> click the <strong>import boot images</strong> button.</p>\n<p><a href=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS-1.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Settings-precise-base-MAAS-1.png\" alt=\"maas import boot images\" width=\"670\" height=\"114\" class=\"alignnone size-full wp-image-287\" /></a></p>\n<p>This will take awhile to run so maybe go get some coffee.</p>\n<p>If you want to speed things up a bit edit <code>/etc/maas/import_pxe_files</code> with the following</p>\n<pre><code>vagrant@precise-base:~$ cat /etc/maas/import_pxe_files \n# This file replaces an older one called import_isos.  Include that here for\n# compatibility.\nif [ -f /etc/maas/import_isos ]\nthen\n    cat &gt;&amp;2 &lt;&lt;EOF\n\nIncluding obsolete /etc/maas/import_isos in configuration.  This file has been\nsuperseded by import_pxe_files.  Please see if it can be removed.\n\nEOF\n    . /etc/maas/import_isos\nfi\n\n\nRELEASES=\"precise\"\nARCHES=\"amd64/generic\"\nLOCALE=\"en_US\"\n#IMPORT_EPHEMERALS=1\n</code></pre>\n<h2>Cluster interface configuration</h2>\n<p>Once the boot images are done you are ready to configure one of the network interfaces to be managed by MAAS. Click on the edit icon under <strong>Cluster controllers</strong>. In the <strong>Edit Cluster Controller</strong> page click on the edit icon next to the interface you'd like to configure. In this case I am using <strong>eth0</strong>. <a href=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Controller-precise-base-MAAS.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Controller-precise-base-MAAS.png\" alt=\"Edit cluster interface\" width=\"594\" height=\"192\" class=\"alignnone size-full wp-image-290\" /></a></p>\n<p>On the next page titled <strong>Edit Cluster Interface</strong> we are going to set <strong>eth0</strong> to manage <strong>dhcp</strong> and <strong>dns</strong> along with entering the ip information for our network. Since vagrant is using 10.0.3.32 as its IP we'll set the rest according to that. <a href=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Interface-precise-base-MAAS-1.png\"><img src=\"http://astokes.org/wp-content/uploads/2013/10/Edit-Cluster-Interface-precise-base-MAAS-1.png\" alt=\"Edit Cluster Interface   precise-base MAAS (1)\" width=\"605\" height=\"704\" class=\"alignnone size-full wp-image-336\" /></a></p>\n<h2>Troubleshooting</h2>\n<h3>DBusException error with avahi</h3>\n<pre><code>DBusException: org.freedesktop.DBus.Error.NameHasNoOwner: Could not get owner of name 'org.freedesktop.Avahi': no such name\n</code></pre>\n<h3>Solution</h3>\n<p>Comment out <strong>rlimit-nproc</strong> in <code>/etc/avahi/avahi-daemon.conf</code>, then start the service. <a href=\"http://sourceforge.net/mailarchive/message.php?msg_id=29200350\">See here</a> for more information on this issue and user namespaces in lxc.</p>\n<pre><code>vagrant@precise-base:~$ sudo service avahi-daemon restart\n</code></pre>\n<h3>Failing to mount ephemeral image</h3>\n<pre><code>precise-ephemeral-maas-amd64.img\nmount: Could not find any loop device. Maybe this kernel does not know\n       about the loop device? (If so, recompile or `modprobe loop'.)\nTue, 01 Oct 2013 19:33:58 +0000: failed to mount /tmp/uec2roottar.MmKLTg/precise-ephemeral-maas-amd64.img\nfailed to create root image\nfailed to prepare image for precise/amd64\n</code></pre>\n<h3>Solution</h3>\n<p>Per <a href=\"http://www.mail-archive.com/lxc-users@lists.sourceforge.net/msg03673.html\">this post</a></p>\n<ol>\n<li>Copy <code>/etc/apparmor.d/lxc/lxc-default</code> to <code>/etc/apparmor.d/lxc/lxc-default-with-loops</code></li>\n<li>Edit <code>/etc/apparmor.d/lxc/lxc-default-with-loops</code>\n<ul>\n<li>Rename lxc-container-default to lxc-container-default-with-loops</li>\n<li>Add an entry: <code>\"mount -&gt; /tmp/*/*,\"</code> or matching the source node, fstype,</li>\n</ul>\n</li>\n<li><code>% sudo /etc/init.d/apparmor reload</code></li>\n<li>Edit your container's configuration and set lxc.aa_profile to lxc-container-default-with-loops\n<ul>\n<li><strong>Note</strong>: this would be <code>lxc.customize \"aa_profile\", \"lxc-container-default-with-loops\"</code> in your <strong>Vagrantfile</strong></li>\n</ul>\n</li>\n<li>Restart your container</li>\n</ol>\n<h1>Conclusion</h1>\n<p>That's pretty much it! Whether this is actually useful remains to be seen. Nevertheless, this was a good learning experience for me. :) Oh and if you read this far down I did automate most of this which you can find over at my <a href=\"https://github.com/battlemidget/vagrant-maas\">github vagrant-maas repo</a>.</p>\n<pre><code>% git clone git://github.com:battlemidget/vagrant-maas.git\n% cd vagrant-maas\n% vagrant plugin install vagrant-lxc\n% vagrant box add precise64 http://bit.ly/vagrant-lxc-precise64-2013-09-28\n% vagrant up --provider=lxc --provision-with ansible\n% vagrant provision\n</code></pre>\n"
    },
    {
      "body": "Since Debian installer doesn't have the ability to configure [vlans](http://en.wikipedia.org/wiki/Virtual_LAN) we need to make any additional network modifications within the `preseed/late_command` stage. If you aren't familiar with vlan or would like some more details on setting it up take a look at [Ubuntu vlan wiki page](https://wiki.ubuntu.com/vlan). Also I don't have the hardware to test the actual switching so hopefully someone will read this and let me know what I've missed. I checked into [gns3](http://www.gns3.net/) but it is my understanding it would be impossible to emulate the switching that Cisco hardware would.\n\n## Assumptions\n\nYea assumptions are baad, however, this article assumes you have an interface `eth0` that supports vlan tagging (802.1q) and that a hardware switch exists that has been configured for vlans.\n\n## Preseed naming conventions in MAAS\n\nThe order in which [MAAS](http://maas.ubuntu.com) loads a preseed file is seen below:\n\n```jinja2\n{prefix}_{node_architecture}_{node_subarchitecture}_{release}_{node_name}\n{prefix}_{node_architecture}_{node_subarchitecture}_{release}\n{prefix}_{node_architecture}_{node_subarchitecture}\n{prefix}_{node_architecture}\n{prefix}\n'generic'\n```\n\n> ### Note:\n> If you wish to keep your distro provided preseeds in-tact and use an\n> alternative you could always name a new preseed with something like\n> `amd64_generic_precise` and when deploying your nodes with the\n> precise image it would pick up that preseed instead of\n> `generic`. More information at\n> **[How preseeds work](http://maas.ubuntu.com/docs/development/preseeds.html)**\n\n## Modifying the preseeds for vlan support\n\nThe preseeds are located within `/etc/maas/preseeds`. For now the only\npreseed files we are concerned with is `preseed_master` and `generic`.\n\nOpening up `preseed_master` we see a typical preseed configuration and scrolling to the bottom you'll see:\n\n```\n# Post scripts.\n{{self.post_scripts}}\n```\n\nThis method is exposed as part of the [Tempita](http://pythonpaste.org/tempita/) template engine which we'll see defined in our `generic` template next.\n\nOpening `generic` template we'll see something like the below:\n\n```yaml\n{{inherit \"preseed_master\"}}\n\n{{def proxy}}\nd-i     mirror/country string manual\nd-i     mirror/http/hostname string {{ports_archive_hostname}}\nd-i     mirror/http/directory string {{ports_archive_directory}}\n{{if http_proxy }}\nd-i     mirror/http/proxy string {{http_proxy}}\n{{else}}\nd-i     mirror/http/proxy string http://{{server_host}}:8000/\n{{endif}}\n{{enddef}}\n\n{{def client_packages}}\nd-i     pkgsel/include string cloud-init openssh-server python-software-properties vim avahi-daemon server^\n{{enddef}}\n\n{{def preseed}}\n{{preseed_data}}\n{{enddef}}\n\n{{def post_scripts}}\n# Executes late command and disables PXE.\nd-i     preseed/late_command string true && \\\n    in-target sh -c 'f=$1; shift; echo $0 > $f && chmod 0440 $f $*' 'ubuntu ALL=(ALL) NOPASSWD: ALL' /etc/sudoers.d/maas && \\\n    in-target wget --no-proxy \"{{node_disable_pxe_url|escape.shell}}\" --post-data \"{{node_disable_pxe_data|escape.shell}}\" -O /dev/null && \\\n    true\n{{enddef}}\n```\n\nMost of this should be self explanatory as this basically outlines the\ntypical usage of most template engines. We `inherit 'preseed_master'`\nwhich calls `self` and we provide our method definitions with `{{def\n<method>}}`. Scroll down your `generic` preseed file and locate `{{def\npost_scripts}}`.\n\nThis definition is what's called from our `preseed_master`\nconfiguration and where we'll add our vlan options. We'll make a call\nout to a `vlansetup` file hosted on the same server as maas, usually\nfound in `/var/www/`.\n\n```yaml\n{{def post_scripts}}\n# Executes late command and disables PXE.\nd-i     preseed/late_command string true && \\\n    in-target sh -c 'f=$1; shift; echo $0 > $f && chmod 0440 $f $*' 'ubuntu ALL=(ALL) NOPASSWD: ALL' /etc/sudoers.d/maas && \\\n    in-target wget --no-proxy \"{{node_disable_pxe_url|escape.shell}}\" --post-data \"{{node_disable_pxe_data|escape.shell}}\" -O /dev/null && \\\n    wget -O /tmp/vlansetup http://192.168.122.206/vlansetup && \\\n    chmod +x /tmp/vlansetup && \\\n    sh -x /tmp/vlansetup && \\\n    rm -f /tmp/vlansetup && \\\n    true\n{{enddef}}\n```\n\nOur `vlansetup` file would look something like\n\n```bash\n#!/bin/sh\n/bin/apt-install vlan\necho \"8021q\" >> /target/etc/modules\ncat >>/target/etc/network/interfaces<<EOF\nauto vlan5\nauto vlan100\niface vlan5 inet static\n  address 10.0.0.18\n  netmask 255.255.255.0\n  vlan-raw-device eth0\niface vlan100 inet static\n  address 192.168.66.118\n  netmask 255.255.255.0\n  vlan-raw-device eth0\nEOF\n```\n\nAfter the node is deployed you should see something like the following in your syslog output.\n\n```\nSet name-type for VLAN subsystem. Should be visible in /proc/net/vlan/config\nAdded VLAN with VID == 5 to IF -:eth0:-\nSet name-type for VLAN subsystem. Should be visible in /proc/net/vlan/config\nAdded VLAN with VID == 100 to IF -:eth0:-\n```\n\nAnd `/proc/net/vlan/config` should look like\n\n```\nubuntu@node1:~$ sudo cat /proc/net/vlan/config \nVLAN Dev name    | VLAN ID\nName-Type: VLAN_NAME_TYPE_PLUS_VID_NO_PAD\nvlan5          | 5  | eth0\nvlan100        | 100  | eth0\n```\n\nLast but not least `ifconfig` reports\n\n```\neth0      Link encap:Ethernet  HWaddr 52:54:00:2a:37:ac  \n          inet addr:192.168.122.144  Bcast:192.168.122.255  Mask:255.255.255.0\n          inet6 addr: fe80::5054:ff:fe2a:37ac/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:148 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:227 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:1000 \n          RX bytes:20214 (20.2 KB)  TX bytes:34006 (34.0 KB)\n\nlo        Link encap:Local Loopback  \n          inet addr:127.0.0.1  Mask:255.0.0.0\n          inet6 addr: ::1/128 Scope:Host\n          UP LOOPBACK RUNNING  MTU:16436  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nvlan5     Link encap:Ethernet  HWaddr 52:54:00:2a:37:ac  \n          inet addr:10.0.0.18  Bcast:10.0.0.255  Mask:255.255.255.0\n          inet6 addr: fe80::5054:ff:fe2a:37ac/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:40 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:6600 (6.6 KB)\n\nvlan100   Link encap:Ethernet  HWaddr 52:54:00:2a:37:ac  \n          inet addr:192.168.66.118  Bcast:192.168.66.255  Mask:255.255.255.0\n          inet6 addr: fe80::5054:ff:fe2a:37ac/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:38 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:0 (0.0 B)  TX bytes:6324 (6.3 KB)\n```\n\n## Thoughts\n\nOf course this could be seen as a hindrance if you have an environment\nmore complex than just assigning vlan tags to `eth0`. Automating the\nassignment of vlan's is probably best done within the installer,\nhowever, that feature doesn't exist. Some things that could be done to\nlessen the administrative burden would be making use of puppet on the\nMAAS server and pre-populating the `/etc/maas/preseeds/generic` file.\n\n## Cool tips\n\nIf you are running your MAAS instance and nodes within\nKVM/VirtualBox/etc you could easily pull the IP from the virtual\nmachine if you know the MAC address using something like `arp\n-an`. Then either setup puppet to keep your preseeds updated or\nutilize something like [libguestfs](http://libguestfs.org/) to make\nchanges directly within the VM.\n\n## Troubleshooting\n\nInstalling this on a desktop image with NetworkManager running (first\nask yourself why)? Then\n[see this post](http://askubuntu.com/questions/199254/802-1q-vlan-interface-configuration-on-ubuntu-12-04-desktop)\nfor a solution to configuring NetworkManager and vlan's.\n",
      "date": "2013-10-07T22:55:26",
      "title": "Configuring VLANs in MAAS node deployment",
      "tags": [
        "ubuntu",
        "maas",
        "preseed",
        "di",
        "debian installer",
        "bare metal",
        "fastpath"
      ],
      "author": "Adam Stokes",
      "path": "automatically-configuring-vlans-maas",
      "compiled": "<p>Since Debian installer doesn&#39;t have the ability to configure <a href=\"http://en.wikipedia.org/wiki/Virtual_LAN\">vlans</a> we need to make any additional network modifications within the <code>preseed/late_command</code> stage. If you aren&#39;t familiar with vlan or would like some more details on setting it up take a look at <a href=\"https://wiki.ubuntu.com/vlan\">Ubuntu vlan wiki page</a>. Also I don&#39;t have the hardware to test the actual switching so hopefully someone will read this and let me know what I&#39;ve missed. I checked into <a href=\"http://www.gns3.net/\">gns3</a> but it is my understanding it would be impossible to emulate the switching that Cisco hardware would.</p>\n<h2 id=\"assumptions\">Assumptions</h2>\n<p>Yea assumptions are baad, however, this article assumes you have an interface <code>eth0</code> that supports vlan tagging (802.1q) and that a hardware switch exists that has been configured for vlans.</p>\n<h2 id=\"preseed-naming-conventions-in-maas\">Preseed naming conventions in MAAS</h2>\n<p>The order in which <a href=\"http://maas.ubuntu.com\">MAAS</a> loads a preseed file is seen below:</p>\n<pre><code class=\"lang-jinja2\"><span class=\"hljs-list\">{prefix}</span>_<span class=\"hljs-list\">{node_architecture}</span>_<span class=\"hljs-list\">{node_subarchitecture}</span>_<span class=\"hljs-list\">{release}</span>_<span class=\"hljs-list\">{node_name}</span>\n<span class=\"hljs-list\">{prefix}</span>_<span class=\"hljs-list\">{node_architecture}</span>_<span class=\"hljs-list\">{node_subarchitecture}</span>_<span class=\"hljs-list\">{release}</span>\n<span class=\"hljs-list\">{prefix}</span>_<span class=\"hljs-list\">{node_architecture}</span>_<span class=\"hljs-list\">{node_subarchitecture}</span>\n<span class=\"hljs-list\">{prefix}</span>_<span class=\"hljs-list\">{node_architecture}</span>\n<span class=\"hljs-list\">{prefix}</span>\n<span class=\"hljs-string\">'generic'</span>\n</code></pre>\n<blockquote>\n<h3 id=\"note-\">Note:</h3>\n<p>If you wish to keep your distro provided preseeds in-tact and use an\nalternative you could always name a new preseed with something like\n<code>amd64_generic_precise</code> and when deploying your nodes with the\nprecise image it would pick up that preseed instead of\n<code>generic</code>. More information at\n<strong><a href=\"http://maas.ubuntu.com/docs/development/preseeds.html\">How preseeds work</a></strong></p>\n</blockquote>\n<h2 id=\"modifying-the-preseeds-for-vlan-support\">Modifying the preseeds for vlan support</h2>\n<p>The preseeds are located within <code>/etc/maas/preseeds</code>. For now the only\npreseed files we are concerned with is <code>preseed_master</code> and <code>generic</code>.</p>\n<p>Opening up <code>preseed_master</code> we see a typical preseed configuration and scrolling to the bottom you&#39;ll see:</p>\n<pre><code><span class=\"xml\"># Post scripts.\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">self.post</span>_<span class=\"hljs-variable\">scripts</span>}}</span><span class=\"xml\"></span>\n</code></pre><p>This method is exposed as part of the <a href=\"http://pythonpaste.org/tempita/\">Tempita</a> template engine which we&#39;ll see defined in our <code>generic</code> template next.</p>\n<p>Opening <code>generic</code> template we&#39;ll see something like the below:</p>\n<pre><code class=\"lang-yaml\"><span class=\"xml\"></span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">inherit</span> <span class=\"hljs-string\">\"preseed_master\"</span>}}</span><span class=\"xml\">\n\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">def</span> <span class=\"hljs-variable\">proxy</span>}}</span><span class=\"xml\">\nd-i     mirror/country string manual\nd-i     mirror/http/hostname string </span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">ports</span>_<span class=\"hljs-variable\">archive</span>_<span class=\"hljs-variable\">hostname</span>}}</span><span class=\"xml\">\nd-i     mirror/http/directory string </span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">ports</span>_<span class=\"hljs-variable\">archive</span>_<span class=\"hljs-variable\">directory</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\"><span class=\"hljs-keyword\">if</span></span> <span class=\"hljs-variable\">http</span>_<span class=\"hljs-variable\">proxy</span> }}</span><span class=\"xml\">\nd-i     mirror/http/proxy string </span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">http</span>_<span class=\"hljs-variable\">proxy</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\"><span class=\"hljs-keyword\">else</span></span>}}</span><span class=\"xml\">\nd-i     mirror/http/proxy string http://</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">server</span>_<span class=\"hljs-variable\">host</span>}}</span><span class=\"xml\">:8000/\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">endif</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">enddef</span>}}</span><span class=\"xml\">\n\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">def</span> <span class=\"hljs-variable\">client</span>_<span class=\"hljs-variable\">packages</span>}}</span><span class=\"xml\">\nd-i     pkgsel/include string cloud-init openssh-server python-software-properties vim avahi-daemon server^\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">enddef</span>}}</span><span class=\"xml\">\n\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">def</span> <span class=\"hljs-variable\">preseed</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">preseed</span>_<span class=\"hljs-variable\">data</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">enddef</span>}}</span><span class=\"xml\">\n\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">def</span> <span class=\"hljs-variable\">post</span>_<span class=\"hljs-variable\">scripts</span>}}</span><span class=\"xml\">\n# Executes late command and disables PXE.\nd-i     preseed/late_command string true &amp;&amp; \\\n    in-target sh -c 'f=$1; shift; echo $0 &gt; $f &amp;&amp; chmod 0440 $f $*' 'ubuntu ALL=(ALL) NOPASSWD: ALL' /etc/sudoers.d/maas &amp;&amp; \\\n    in-target wget --no-proxy \"</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">node</span>_<span class=\"hljs-variable\">disable</span>_<span class=\"hljs-variable\">pxe</span>_<span class=\"hljs-variable\">url</span>|<span class=\"hljs-variable\">escape.shell</span>}}</span><span class=\"xml\">\" --post-data \"</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">node</span>_<span class=\"hljs-variable\">disable</span>_<span class=\"hljs-variable\">pxe</span>_<span class=\"hljs-variable\">data</span>|<span class=\"hljs-variable\">escape.shell</span>}}</span><span class=\"xml\">\" -O /dev/null &amp;&amp; \\\n    true\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">enddef</span>}}</span><span class=\"xml\"></span>\n</code></pre>\n<p>Most of this should be self explanatory as this basically outlines the\ntypical usage of most template engines. We <code>inherit &#39;preseed_master&#39;</code>\nwhich calls <code>self</code> and we provide our method definitions with `{{def</p>\n<p><method>}}<code>. Scroll down your</code>generic<code>preseed file and locate</code>{{def\npost_scripts}}`.</p>\n<p>This definition is what&#39;s called from our <code>preseed_master</code>\nconfiguration and where we&#39;ll add our vlan options. We&#39;ll make a call\nout to a <code>vlansetup</code> file hosted on the same server as maas, usually\nfound in <code>/var/www/</code>.</p>\n<pre><code class=\"lang-yaml\">{{def post_scripts}}\n<span class=\"hljs-comment\"># Executes late command and disables PXE.</span>\nd-i     preseed/late_command string <span class=\"hljs-literal\">true</span> &amp;&amp; <span class=\"hljs-string\">\\</span>\n    <span class=\"hljs-keyword\">in</span>-target sh -c <span class=\"hljs-string\">'f=$1; shift; echo $0 &gt; $f &amp;&amp; chmod 0440 $f $*'</span> <span class=\"hljs-string\">'ubuntu ALL=(ALL) NOPASSWD: ALL'</span> /etc/sudoers.d/maas &amp;&amp; <span class=\"hljs-string\">\\</span>\n    <span class=\"hljs-keyword\">in</span>-target wget --<span class=\"hljs-literal\">no</span>-proxy <span class=\"hljs-string\">\"{{node_disable_pxe_url|escape.shell}}\"</span> --post-data <span class=\"hljs-string\">\"{{node_disable_pxe_data|escape.shell}}\"</span> -O /dev/<span class=\"hljs-literal\">null</span> &amp;&amp; <span class=\"hljs-string\">\\</span>\n    wget -O <span class=\"hljs-pi\">/tmp/vlansetup http:/</span>/<span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">122.206</span>/vlansetup &amp;&amp; <span class=\"hljs-string\">\\</span>\n    chmod +x /tmp/vlansetup &amp;&amp; <span class=\"hljs-string\">\\</span>\n    sh -x /tmp/vlansetup &amp;&amp; <span class=\"hljs-string\">\\</span>\n    rm -f /tmp/vlansetup &amp;&amp; <span class=\"hljs-string\">\\</span>\n    <span class=\"hljs-literal\">true</span>\n{{enddef}}\n</code></pre>\n<p>Our <code>vlansetup</code> file would look something like</p>\n<pre><code class=\"lang-bash\"><span class=\"hljs-shebang\">#!/bin/sh</span>\n/bin/apt-install vlan\n<span class=\"hljs-built_in\">echo</span> <span class=\"hljs-string\">\"8021q\"</span> &gt;&gt; /target/etc/modules\ncat &gt;&gt;/target/etc/network/interfaces&lt;&lt;EOF\nauto vlan5\nauto vlan100\niface vlan5 inet static\n  address <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.18</span>\n  netmask <span class=\"hljs-number\">255.255</span>.<span class=\"hljs-number\">255.0</span>\n  vlan-raw-device eth0\niface vlan100 inet static\n  address <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.118</span>\n  netmask <span class=\"hljs-number\">255.255</span>.<span class=\"hljs-number\">255.0</span>\n  vlan-raw-device eth0\nEOF\n</code></pre>\n<p>After the node is deployed you should see something like the following in your syslog output.</p>\n<pre><code><span class=\"hljs-type\">Set</span> name-<span class=\"hljs-keyword\">type</span> <span class=\"hljs-keyword\">for</span> <span class=\"hljs-type\">VLAN</span> subsystem. <span class=\"hljs-type\">Should</span> be visible <span class=\"hljs-keyword\">in</span> /<span class=\"hljs-keyword\">proc</span>/net/vlan/config\n<span class=\"hljs-type\">Added</span> <span class=\"hljs-type\">VLAN</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-type\">VID</span> == <span class=\"hljs-number\">5</span> to <span class=\"hljs-type\">IF</span> -:eth0:-\n<span class=\"hljs-type\">Set</span> name-<span class=\"hljs-keyword\">type</span> <span class=\"hljs-keyword\">for</span> <span class=\"hljs-type\">VLAN</span> subsystem. <span class=\"hljs-type\">Should</span> be visible <span class=\"hljs-keyword\">in</span> /<span class=\"hljs-keyword\">proc</span>/net/vlan/config\n<span class=\"hljs-type\">Added</span> <span class=\"hljs-type\">VLAN</span> <span class=\"hljs-keyword\">with</span> <span class=\"hljs-type\">VID</span> == <span class=\"hljs-number\">100</span> to <span class=\"hljs-type\">IF</span> -:eth0:-\n</code></pre><p>And <code>/proc/net/vlan/config</code> should look like</p>\n<pre><code>ubuntu@node1:~$ sudo cat /<span class=\"hljs-keyword\">proc</span>/net/vlan/config \n<span class=\"hljs-type\">VLAN</span> <span class=\"hljs-type\">Dev</span> name    | <span class=\"hljs-type\">VLAN</span> <span class=\"hljs-type\">ID</span>\n<span class=\"hljs-type\">Name</span>-<span class=\"hljs-type\">Type</span>: <span class=\"hljs-type\">VLAN_NAME_TYPE_PLUS_VID_NO_PAD</span>\nvlan5          | <span class=\"hljs-number\">5</span>  | eth0\nvlan100        | <span class=\"hljs-number\">100</span>  | eth0\n</code></pre><p>Last but not least <code>ifconfig</code> reports</p>\n<pre><code>eth0      Link <span class=\"hljs-string\">encap:</span>Ethernet  HWaddr <span class=\"hljs-number\">52</span>:<span class=\"hljs-number\">54</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">2</span><span class=\"hljs-string\">a:</span><span class=\"hljs-number\">37</span>:ac  \n          inet <span class=\"hljs-string\">addr:</span><span class=\"hljs-number\">192.168</span>.122.144  <span class=\"hljs-string\">Bcast:</span><span class=\"hljs-number\">192.168</span>.122.255  <span class=\"hljs-string\">Mask:</span><span class=\"hljs-number\">255.255</span>.255.0\n          inet6 <span class=\"hljs-string\">addr:</span> <span class=\"hljs-string\">fe80:</span>:<span class=\"hljs-number\">5054</span>:<span class=\"hljs-string\">ff:</span><span class=\"hljs-string\">fe2a:</span><span class=\"hljs-number\">37</span>ac/<span class=\"hljs-number\">64</span> <span class=\"hljs-string\">Scope:</span>Link\n          UP BROADCAST RUNNING MULTICAST  <span class=\"hljs-string\">MTU:</span><span class=\"hljs-number\">1500</span>  <span class=\"hljs-string\">Metric:</span><span class=\"hljs-number\">1</span>\n          RX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">148</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">frame:</span><span class=\"hljs-number\">0</span>\n          TX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">227</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">carrier:</span><span class=\"hljs-number\">0</span>\n<span class=\"hljs-label\">          collisions:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">txqueuelen:</span><span class=\"hljs-number\">1000</span> \n          RX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">20214</span> (<span class=\"hljs-number\">20.2</span> KB)  TX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">34006</span> (<span class=\"hljs-number\">34.0</span> KB)\n\nlo        Link <span class=\"hljs-string\">encap:</span>Local Loopback  \n          inet <span class=\"hljs-string\">addr:</span><span class=\"hljs-number\">127.0</span>.0.1  <span class=\"hljs-string\">Mask:</span><span class=\"hljs-number\">255.0</span>.0.0\n          inet6 <span class=\"hljs-string\">addr:</span> ::<span class=\"hljs-number\">1</span>/<span class=\"hljs-number\">128</span> <span class=\"hljs-string\">Scope:</span>Host\n          UP LOOPBACK RUNNING  <span class=\"hljs-string\">MTU:</span><span class=\"hljs-number\">16436</span>  <span class=\"hljs-string\">Metric:</span><span class=\"hljs-number\">1</span>\n          RX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">frame:</span><span class=\"hljs-number\">0</span>\n          TX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">carrier:</span><span class=\"hljs-number\">0</span>\n<span class=\"hljs-label\">          collisions:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">txqueuelen:</span><span class=\"hljs-number\">0</span> \n          RX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">0.0</span> B)  TX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">0.0</span> B)\n\nvlan5     Link <span class=\"hljs-string\">encap:</span>Ethernet  HWaddr <span class=\"hljs-number\">52</span>:<span class=\"hljs-number\">54</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">2</span><span class=\"hljs-string\">a:</span><span class=\"hljs-number\">37</span>:ac  \n          inet <span class=\"hljs-string\">addr:</span><span class=\"hljs-number\">10.0</span>.0.18  <span class=\"hljs-string\">Bcast:</span><span class=\"hljs-number\">10.0</span>.0.255  <span class=\"hljs-string\">Mask:</span><span class=\"hljs-number\">255.255</span>.255.0\n          inet6 <span class=\"hljs-string\">addr:</span> <span class=\"hljs-string\">fe80:</span>:<span class=\"hljs-number\">5054</span>:<span class=\"hljs-string\">ff:</span><span class=\"hljs-string\">fe2a:</span><span class=\"hljs-number\">37</span>ac/<span class=\"hljs-number\">64</span> <span class=\"hljs-string\">Scope:</span>Link\n          UP BROADCAST RUNNING MULTICAST  <span class=\"hljs-string\">MTU:</span><span class=\"hljs-number\">1500</span>  <span class=\"hljs-string\">Metric:</span><span class=\"hljs-number\">1</span>\n          RX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">frame:</span><span class=\"hljs-number\">0</span>\n          TX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">40</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">carrier:</span><span class=\"hljs-number\">0</span>\n<span class=\"hljs-label\">          collisions:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">txqueuelen:</span><span class=\"hljs-number\">0</span> \n          RX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">0.0</span> B)  TX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">6600</span> (<span class=\"hljs-number\">6.6</span> KB)\n\nvlan100   Link <span class=\"hljs-string\">encap:</span>Ethernet  HWaddr <span class=\"hljs-number\">52</span>:<span class=\"hljs-number\">54</span>:<span class=\"hljs-number\">00</span>:<span class=\"hljs-number\">2</span><span class=\"hljs-string\">a:</span><span class=\"hljs-number\">37</span>:ac  \n          inet <span class=\"hljs-string\">addr:</span><span class=\"hljs-number\">192.168</span>.66.118  <span class=\"hljs-string\">Bcast:</span><span class=\"hljs-number\">192.168</span>.66.255  <span class=\"hljs-string\">Mask:</span><span class=\"hljs-number\">255.255</span>.255.0\n          inet6 <span class=\"hljs-string\">addr:</span> <span class=\"hljs-string\">fe80:</span>:<span class=\"hljs-number\">5054</span>:<span class=\"hljs-string\">ff:</span><span class=\"hljs-string\">fe2a:</span><span class=\"hljs-number\">37</span>ac/<span class=\"hljs-number\">64</span> <span class=\"hljs-string\">Scope:</span>Link\n          UP BROADCAST RUNNING MULTICAST  <span class=\"hljs-string\">MTU:</span><span class=\"hljs-number\">1500</span>  <span class=\"hljs-string\">Metric:</span><span class=\"hljs-number\">1</span>\n          RX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">frame:</span><span class=\"hljs-number\">0</span>\n          TX <span class=\"hljs-string\">packets:</span><span class=\"hljs-number\">38</span> <span class=\"hljs-string\">errors:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">dropped:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">overruns:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">carrier:</span><span class=\"hljs-number\">0</span>\n<span class=\"hljs-label\">          collisions:</span><span class=\"hljs-number\">0</span> <span class=\"hljs-string\">txqueuelen:</span><span class=\"hljs-number\">0</span> \n          RX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">0</span> (<span class=\"hljs-number\">0.0</span> B)  TX <span class=\"hljs-string\">bytes:</span><span class=\"hljs-number\">6324</span> (<span class=\"hljs-number\">6.3</span> KB)\n</code></pre><h2 id=\"thoughts\">Thoughts</h2>\n<p>Of course this could be seen as a hindrance if you have an environment\nmore complex than just assigning vlan tags to <code>eth0</code>. Automating the\nassignment of vlan&#39;s is probably best done within the installer,\nhowever, that feature doesn&#39;t exist. Some things that could be done to\nlessen the administrative burden would be making use of puppet on the\nMAAS server and pre-populating the <code>/etc/maas/preseeds/generic</code> file.</p>\n<h2 id=\"cool-tips\">Cool tips</h2>\n<p>If you are running your MAAS instance and nodes within\nKVM/VirtualBox/etc you could easily pull the IP from the virtual\nmachine if you know the MAC address using something like <code>arp\n-an</code>. Then either setup puppet to keep your preseeds updated or\nutilize something like <a href=\"http://libguestfs.org/\">libguestfs</a> to make\nchanges directly within the VM.</p>\n<h2 id=\"troubleshooting\">Troubleshooting</h2>\n<p>Installing this on a desktop image with NetworkManager running (first\nask yourself why)? Then\n<a href=\"http://askubuntu.com/questions/199254/802-1q-vlan-interface-configuration-on-ubuntu-12-04-desktop\">see this post</a>\nfor a solution to configuring NetworkManager and vlan&#39;s.</p>\n"
    },
    {
      "body": "\nMAAS 1.4 supports installing images via\n[curtin](http://launchpad.net/curtin) (fastpath).\n\nTo enable fastpath for a node we need to\n[tag](http://maas.ubuntu.com/docs/tags.html) it with\n`use-fastpath-installer` that is understood by MAAS and fastpath. As\nfar as I can tell this has to be accomplished via `maas-cli`.\n\n## Set your MAAS profile\n\nIf you've gone through the\n[basic getting started steps](http://maas.ubuntu.com/docs/install.html)\nwith MAAS your profile is most likely `maas`. Assign `MAASNAME` to\nyour `maas` profile.\n\n```\nubuntu@maas:~$ MAASNAME=maas\n```\n\n## Login to your MAAS instance via maas-cli\n\nIn order to login to your maas instance you'll need to grab your\n**maas-key**. This can be done by visiting the user preferences page\n(http://maas.ip/MAAS/account/prefs) or clicking the `preferences` link\nunder your account name (Fig 1).\n\n![Fig 1. User preferences](/images/2013/10/figure_8a.png)\n\nYour **maas-key** should be located under the _MAAS keys_ section (Fig 2)\n\n![Fig 2. MAAS keys](/images/2013/10/figure_9a.png)\n\nOnce you have that key copied,\n[login](http://maas.ubuntu.com/docs/maascli.html#api-key) to your MAAS\ninstance from the command line.\n\n```\nubuntu@maas:~$ maas-cli login maas http://192.168.122.206/MAAS/api/1.0 CNTvmLmstUadGLk4wp:nxcJ9LZnCmksRe2jFS:xAYeYj4yJdJ4ARsfGBxWYSgqzsMtJbcF\n\nYou are now logged in to the MAAS server at\nhttp://192.168.122.206/MAAS/api/1.0/ with the profile name 'maas'.\n\nFor help with the available commands, try:\n\n    maas-cli maas --help\n\nubuntu@maas:~$\n```\n\n## Apply the tag to a single node\n\nOnce logged in we can start tagging nodes. In order to figure out which node you'd like to tag run the following command:\n\n```\nubuntu@maas:~$ maas-cli maas nodes list\n    [\n        {\n            \"status\": 4,\n            \"macaddress_set\": [\n                {\n                    \"resource_uri\": \"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/macs/52:54:00:2a:37:ac/\",\n                    \"mac_address\": \"52:54:00:2a:37:ac\"\n                }\n            ],\n            \"hostname\": \"node1.master\",\n            \"power_type\": \"virsh\",\n            \"routers\": [],\n            \"netboot\": true,\n            \"cpu_count\": 1,\n            \"storage\": 0,\n            \"system_id\": \"node-1a62d358-2f8e-11e3-b5c3-525400a1c422\",\n            \"architecture\": \"amd64/generic\",\n            \"memory\": 512,\n            \"owner\": null,\n            \"tag_names\": [\n                \"virtual\"\n            ],\n            \"ip_addresses\": [\n                \"192.168.122.101\"\n            ],\n            \"resource_uri\": \"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/\"\n        }\n    ]\n```\n\nIf you look at `system_id` this will be what you'll use when tagging a single node. Go ahead and store that node in a variable\n\n```\nubuntu@maas:~$ node=node-1a62d358-2f8e-11e3-b5c3-525400a1c422\n```\n\nAt this point the `use-fastpath-installer` tag doesn't exist so we need to create it first\n\n```\nubuntu@maas:~$ maas-cli $MAASNAME tags new name='use-fastpath-installer' comment='fp'\n    {\n        \"comment\": \"fp\",\n        \"definition\": \"\",\n        \"resource_uri\": \"/MAAS/api/1.0/tags/use-fastpath-installer/\",\n        \"name\": \"use-fastpath-installer\",\n        \"kernel_opts\": \"\"\n    }\n```\n\nNow we can apply the tag to the node\n\n```\nubuntu@maas:~$ maas-cli $MAASNAME tag update-nodes use-fastpath-installer add=$node\n    {\n        \"removed\": 0,\n        \"added\": 1\n    }\n```\n\nOr you can run the following command and bypass creating the tag and applying it manually to a node with the following\n\n```\nubuntu@maas:~$ maas-cli $MAASNAME tags new name='use-fastpath-installer' comment='fp' \"definition=true()\"\n```\n\nThis will create the `use-fastpath-installer` tag and apply to all available nodes.\n\n## Verify your node(s) are tagged\n\nYou can view that the tagging worked by either running the following command:\n\n```\nubuntu@maas:~$ maas-cli $MAASNAME tag nodes use-fastpath-installer\n    [\n        {\n            \"status\": 4,\n            \"macaddress_set\": [\n                {\n                    \"resource_uri\": \"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/macs/52:54:00:2a:37:ac/\",\n                    \"mac_address\": \"52:54:00:2a:37:ac\"\n                }\n            ],\n            \"hostname\": \"node1.master\",\n            \"power_type\": \"virsh\",\n            \"routers\": [],\n            \"netboot\": true,\n            \"cpu_count\": 1,\n            \"storage\": 0,\n            \"system_id\": \"node-1a62d358-2f8e-11e3-b5c3-525400a1c422\",\n            \"architecture\": \"amd64/generic\",\n            \"memory\": 512,\n            \"owner\": null,\n            \"tag_names\": [\n                \"virtual\",\n                \"use-fastpath-installer\"\n            ],\n            \"ip_addresses\": [\n                \"192.168.122.101\"\n            ],\n            \"resource_uri\": \"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/\"\n        }\n    ]\n```\n\nOr through the **web-ui** and viewing your node properties (Fig. 3)\n\n![Fig 3. Node properties](/images/2013/10/figure_10a.png)\n\n## Deploy your node with fastpath installer\n\nNow that the node is tagged simply re-deploy the node and fastpath\nshould take over automatically. Should note that you really won't see\na difference other than speed increase of the installation, but, let's\nbe honest that's really what we care about right? :)\n\n## Tips\n\nI ran this test on **Precise** in order to do that you'll need the\n_cloud-tools_ pocket in the **cloud archive**:\n\n```\nubuntu@hostmachine:~$ sudo apt-get install -qy ubuntu-cloud-keyring </dev/null\nubuntu@hostmachine:~$ sudo tee /etc/apt/sources.list.d/cloud-tools-precise.list <<EOF\ndeb http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main\ndeb-src http://ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main\nEOF\n```\n",
      "date": "2013-10-08T17:04:00",
      "title": "Using fastpath installer in MAAS",
      "tags": [
        "maas",
        "fastpath",
        "curtin",
        "kvm"
      ],
      "author": "Adam Stokes",
      "path": "using-fastpath-installer-maas",
      "compiled": "<p>MAAS 1.4 supports installing images via\n<a href=\"http://launchpad.net/curtin\">curtin</a> (fastpath).</p>\n<p>To enable fastpath for a node we need to\n<a href=\"http://maas.ubuntu.com/docs/tags.html\">tag</a> it with\n<code>use-fastpath-installer</code> that is understood by MAAS and fastpath. As\nfar as I can tell this has to be accomplished via <code>maas-cli</code>.</p>\n<h2 id=\"set-your-maas-profile\">Set your MAAS profile</h2>\n<p>If you&#39;ve gone through the\n<a href=\"http://maas.ubuntu.com/docs/install.html\">basic getting started steps</a>\nwith MAAS your profile is most likely <code>maas</code>. Assign <code>MAASNAME</code> to\nyour <code>maas</code> profile.</p>\n<pre><code>ubuntu<span class=\"hljs-variable\">@maas</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span><span class=\"hljs-constant\">MAASNAME=</span>maas\n</code></pre><h2 id=\"login-to-your-maas-instance-via-maas-cli\">Login to your MAAS instance via maas-cli</h2>\n<p>In order to login to your maas instance you&#39;ll need to grab your\n<strong>maas-key</strong>. This can be done by visiting the user preferences page\n(<a href=\"http://maas.ip/MAAS/account/prefs\">http://maas.ip/MAAS/account/prefs</a>) or clicking the <code>preferences</code> link\nunder your account name (Fig 1).</p>\n<p><img src=\"/images/2013/10/figure_8a.png\" alt=\"Fig 1. User preferences\"></p>\n<p>Your <strong>maas-key</strong> should be located under the <em>MAAS keys</em> section (Fig 2)</p>\n<p><img src=\"/images/2013/10/figure_9a.png\" alt=\"Fig 2. MAAS keys\"></p>\n<p>Once you have that key copied,\n<a href=\"http://maas.ubuntu.com/docs/maascli.html#api-key\">login</a> to your MAAS\ninstance from the command line.</p>\n<pre><code>ubuntu@maas:~$ maas-cli login maas <span class=\"hljs-keyword\">http</span>://<span class=\"hljs-number\">192.168</span>.122.206/MAAS/api/<span class=\"hljs-number\">1.0</span> CNTvmLmstUadGLk4wp:nxcJ9LZnCmksRe2jFS:xAYeYj4yJdJ4ARsfGBxWYSgqzsMtJbcF\n\nYou are now logged <span class=\"hljs-operator\">in</span> <span class=\"hljs-built_in\">to</span> <span class=\"hljs-operator\">the</span> MAAS server <span class=\"hljs-keyword\">at</span>\n<span class=\"hljs-keyword\">http</span>://<span class=\"hljs-number\">192.168</span>.122.206/MAAS/api/<span class=\"hljs-number\">1.0</span>/ <span class=\"hljs-operator\">with</span> <span class=\"hljs-operator\">the</span> profile name <span class=\"hljs-string\">'maas'</span>.\n\nFor help <span class=\"hljs-operator\">with</span> <span class=\"hljs-operator\">the</span> available commands, <span class=\"hljs-keyword\">try</span>:\n\n    maas-cli maas <span class=\"hljs-comment\">--help</span>\n\nubuntu@maas:~$\n</code></pre><h2 id=\"apply-the-tag-to-a-single-node\">Apply the tag to a single node</h2>\n<p>Once logged in we can start tagging nodes. In order to figure out which node you&#39;d like to tag run the following command:</p>\n<pre><code><span class=\"hljs-atom\">ubuntu</span>@<span class=\"hljs-atom\">maas</span>:~$ <span class=\"hljs-atom\">maas</span>-<span class=\"hljs-atom\">cli</span> <span class=\"hljs-atom\">maas</span> <span class=\"hljs-atom\">nodes</span> <span class=\"hljs-atom\">list</span>\n    [\n        {\n            <span class=\"hljs-string\">\"status\"</span>: <span class=\"hljs-number\">4</span>,\n            <span class=\"hljs-string\">\"macaddress_set\"</span>: [\n                {\n                    <span class=\"hljs-string\">\"resource_uri\"</span>: <span class=\"hljs-string\">\"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/macs/52:54:00:2a:37:ac/\"</span>,\n                    <span class=\"hljs-string\">\"mac_address\"</span>: <span class=\"hljs-string\">\"52:54:00:2a:37:ac\"</span>\n                }\n            ],\n            <span class=\"hljs-string\">\"hostname\"</span>: <span class=\"hljs-string\">\"node1.master\"</span>,\n            <span class=\"hljs-string\">\"power_type\"</span>: <span class=\"hljs-string\">\"virsh\"</span>,\n            <span class=\"hljs-string\">\"routers\"</span>: [],\n            <span class=\"hljs-string\">\"netboot\"</span>: <span class=\"hljs-atom\">true</span>,\n            <span class=\"hljs-string\">\"cpu_count\"</span>: <span class=\"hljs-number\">1</span>,\n            <span class=\"hljs-string\">\"storage\"</span>: <span class=\"hljs-number\">0</span>,\n            <span class=\"hljs-string\">\"system_id\"</span>: <span class=\"hljs-string\">\"node-1a62d358-2f8e-11e3-b5c3-525400a1c422\"</span>,\n            <span class=\"hljs-string\">\"architecture\"</span>: <span class=\"hljs-string\">\"amd64/generic\"</span>,\n            <span class=\"hljs-string\">\"memory\"</span>: <span class=\"hljs-number\">512</span>,\n            <span class=\"hljs-string\">\"owner\"</span>: <span class=\"hljs-atom\">null</span>,\n            <span class=\"hljs-string\">\"tag_names\"</span>: [\n                <span class=\"hljs-string\">\"virtual\"</span>\n            ],\n            <span class=\"hljs-string\">\"ip_addresses\"</span>: [\n                <span class=\"hljs-string\">\"192.168.122.101\"</span>\n            ],\n            <span class=\"hljs-string\">\"resource_uri\"</span>: <span class=\"hljs-string\">\"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/\"</span>\n        }\n    ]\n</code></pre><p>If you look at <code>system_id</code> this will be what you&#39;ll use when tagging a single node. Go ahead and store that node in a variable</p>\n<pre><code>ubuntu<span class=\"hljs-variable\">@maas</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>node=node-<span class=\"hljs-number\">1</span>a62d358-<span class=\"hljs-number\">2</span>f8e-<span class=\"hljs-number\">11</span>e3-b5c3-<span class=\"hljs-number\">525400</span>a1c422\n</code></pre><p>At this point the <code>use-fastpath-installer</code> tag doesn&#39;t exist so we need to create it first</p>\n<pre><code>ubuntu<span class=\"hljs-variable\">@maas</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>maas-cli <span class=\"hljs-variable\">$MAASNAME</span> tags new name=<span class=\"hljs-string\">'use-fastpath-installer'</span> comment=<span class=\"hljs-string\">'fp'</span>\n    {\n        <span class=\"hljs-string\">\"comment\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"fp\"</span>,\n        <span class=\"hljs-string\">\"definition\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"\"</span>,\n        <span class=\"hljs-string\">\"resource_uri\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"/MAAS/api/1.0/tags/use-fastpath-installer/\"</span>,\n        <span class=\"hljs-string\">\"name\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"use-fastpath-installer\"</span>,\n        <span class=\"hljs-string\">\"kernel_opts\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"\"</span>\n    }\n</code></pre><p>Now we can apply the tag to the node</p>\n<pre><code>ubuntu<span class=\"hljs-variable\">@maas</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>maas-cli <span class=\"hljs-variable\">$MAASNAME</span> tag update-nodes <span class=\"hljs-keyword\">use</span>-fastpath-installer add=<span class=\"hljs-variable\">$node</span>\n    {\n        <span class=\"hljs-string\">\"removed\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-number\">0</span>,\n        <span class=\"hljs-string\">\"added\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-number\">1</span>\n    }\n</code></pre><p>Or you can run the following command and bypass creating the tag and applying it manually to a node with the following</p>\n<pre><code>ubuntu<span class=\"hljs-variable\">@maas</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>maas-cli <span class=\"hljs-variable\">$MAASNAME</span> tags new name=<span class=\"hljs-string\">'use-fastpath-installer'</span> comment=<span class=\"hljs-string\">'fp'</span> <span class=\"hljs-string\">\"definition=true()\"</span>\n</code></pre><p>This will create the <code>use-fastpath-installer</code> tag and apply to all available nodes.</p>\n<h2 id=\"verify-your-node-s-are-tagged\">Verify your node(s) are tagged</h2>\n<p>You can view that the tagging worked by either running the following command:</p>\n<pre><code>ubuntu<span class=\"hljs-variable\">@maas</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>maas-cli <span class=\"hljs-variable\">$MAASNAME</span> tag nodes <span class=\"hljs-keyword\">use</span>-fastpath-installer\n    [\n        {\n            <span class=\"hljs-string\">\"status\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-number\">4</span>,\n            <span class=\"hljs-string\">\"macaddress_set\"</span><span class=\"hljs-symbol\">:</span> [\n                {\n                    <span class=\"hljs-string\">\"resource_uri\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/macs/52:54:00:2a:37:ac/\"</span>,\n                    <span class=\"hljs-string\">\"mac_address\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"52:54:00:2a:37:ac\"</span>\n                }\n            ],\n            <span class=\"hljs-string\">\"hostname\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"node1.master\"</span>,\n            <span class=\"hljs-string\">\"power_type\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"virsh\"</span>,\n            <span class=\"hljs-string\">\"routers\"</span><span class=\"hljs-symbol\">:</span> [],\n            <span class=\"hljs-string\">\"netboot\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-keyword\">true</span>,\n            <span class=\"hljs-string\">\"cpu_count\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-number\">1</span>,\n            <span class=\"hljs-string\">\"storage\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-number\">0</span>,\n            <span class=\"hljs-string\">\"system_id\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"node-1a62d358-2f8e-11e3-b5c3-525400a1c422\"</span>,\n            <span class=\"hljs-string\">\"architecture\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"amd64/generic\"</span>,\n            <span class=\"hljs-string\">\"memory\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-number\">512</span>,\n            <span class=\"hljs-string\">\"owner\"</span><span class=\"hljs-symbol\">:</span> null,\n            <span class=\"hljs-string\">\"tag_names\"</span><span class=\"hljs-symbol\">:</span> [\n                <span class=\"hljs-string\">\"virtual\"</span>,\n                <span class=\"hljs-string\">\"use-fastpath-installer\"</span>\n            ],\n            <span class=\"hljs-string\">\"ip_addresses\"</span><span class=\"hljs-symbol\">:</span> [\n                <span class=\"hljs-string\">\"192.168.122.101\"</span>\n            ],\n            <span class=\"hljs-string\">\"resource_uri\"</span><span class=\"hljs-symbol\">:</span> <span class=\"hljs-string\">\"/MAAS/api/1.0/nodes/node-1a62d358-2f8e-11e3-b5c3-525400a1c422/\"</span>\n        }\n    ]\n</code></pre><p>Or through the <strong>web-ui</strong> and viewing your node properties (Fig. 3)</p>\n<p><img src=\"/images/2013/10/figure_10a.png\" alt=\"Fig 3. Node properties\"></p>\n<h2 id=\"deploy-your-node-with-fastpath-installer\">Deploy your node with fastpath installer</h2>\n<p>Now that the node is tagged simply re-deploy the node and fastpath\nshould take over automatically. Should note that you really won&#39;t see\na difference other than speed increase of the installation, but, let&#39;s\nbe honest that&#39;s really what we care about right? :)</p>\n<h2 id=\"tips\">Tips</h2>\n<p>I ran this test on <strong>Precise</strong> in order to do that you&#39;ll need the\n<em>cloud-tools</em> pocket in the <strong>cloud archive</strong>:</p>\n<pre><code>ubuntu<span class=\"hljs-annotation\">@hostmachine</span>:~$ sudo apt-get install -qy ubuntu-cloud-keyring &lt;<span class=\"hljs-regexp\">/dev/</span><span class=\"hljs-literal\">null</span>\nubuntu<span class=\"hljs-annotation\">@hostmachine</span>:~$ sudo tee <span class=\"hljs-regexp\">/etc/</span>apt<span class=\"hljs-regexp\">/sources.list.d/</span>cloud-tools-precise.list &lt;&lt;EOF\ndeb <span class=\"hljs-string\">http:</span><span class=\"hljs-comment\">//ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main</span>\ndeb-src <span class=\"hljs-string\">http:</span><span class=\"hljs-comment\">//ubuntu-cloud.archive.canonical.com/ubuntu precise-updates/cloud-tools main</span>\nEOF\n</code></pre>"
    },
    {
      "body": "Working off my previous entry about\n**[using fastpath installer in MAAS](http://astokes.org/using-fastpath-installer-maas/)**\nI decided to dig a little deeper into customizing those installations\na bit. One thing to note is\n[fastpath(curtin/curt installer)](http://launchpad.net/curtin)\ninstallations do not follow the same guidelines that are used in\npreseed files for Debian installer. Some overview documentation of\n[fastpath can be located here](http://bazaar.launchpad.net/~curtin-dev/curtin/trunk/view/head:/doc/topics/overview.rst)\nand thanks to [Scott Moser](http://ubuntu-smoser.blogspot.com/) we\nwere able to come up with the following example scenario.\n\n## Example scenario\n\n**Setting up vlans during a fastpath installation.**\n\nOn the **[MAAS](http://maas.ubuntu.com)** server edit\n`/etc/maas/preseeds/curtin_userdata` and write the following\n(substituting your vlan configuration):\n\n```yaml\n# vlan config\nbucket:\n  &myinterfaces |\n   # This file describes the network interfaces available on your system\n   # and how to activate them. For more information, see interfaces(5).\n\n   # The loopback network interface\n   auto lo\n   iface lo inet loopback\n\n   # The primary network interface\n   auto eth0\n   iface eth0 inet dhcp\n   auto vlan5\n   auto vlan100\n   iface vlan5 inet static\n     address 10.0.0.18\n     netmask 255.255.255.0\n     vlan-raw-device eth0\n   iface vlan100 inet static\n     address 192.168.66.118\n     netmask 255.255.255.0\n     vlan-raw-device eth0\n\n#cloud-config\ndebconf_selections:\n maas: |\n  {{for line in str(curtin_preseed).splitlines()}}\n  {{line}}\n  {{endfor}}\nearly_commands:\n  update: apt-get update\n  vlan: apt-get install vlan -q -y\n\nlate_commands:\n  maas: [wget, '--no-proxy', '{{node_disable_pxe_url|escape.shell}}', '--post-data', '{{node_disable_pxe_data|escape.shell}}', '-O', '/dev/null']\n  load_8021q: ['sh', '-c', 'echo 8021q >> $TARGET_MOUNT_POINT/etc/modules']\n\nnetwork_commands:\n  vlans: ['sh', '-c', 'printf \"$1\" > \"$OUTPUT_INTERFACES\"', '--', *myinterfaces]\n\npower_state:\n  mode: reboot\n\n{{if node.architecture in {'i386/generic', 'amd64/generic'} }}\napt_mirror: http://{{main_archive_hostname}}/{{main_archive_directory}}\n{{else}}\napt_mirror: http://{{ports_archive_hostname}}/{{ports_archive_directory}}\n{{endif}}\n\n{{if http_proxy }}\napt_proxy: {{http_proxy}}\n{{else}}\napt_proxy: http://{{server_host}}:8000/\n{{endif}}\n```\n\nOnce your node is deployed simply ssh into the instance and verify the\n`8021q` module is loaded and that `ifconfig` reports your added vlans.\n\nOur `lsmod` output shows the proper module loaded\n\n```\nubuntu@node1:~$ lsmod|grep 8021q\n8021q                  24084  0 \ngarp                   14602  1 8021q\n```\n\n`/etc/network/interfaces` shows the correct vlan information\n\n```\nauto lo\niface lo inet loopback\nauto eth0\niface eth0 inet dhcp\nauto vlan5\nauto vlan100\niface vlan5 inet static\n  address 10.0.0.18\n  netmask 255.255.255.0\n  vlan-raw-device eth0\niface vlan100 inet static\n  address 192.168.66.118\n  netmask 255.255.255.0\n  vlan-raw-device eth0\n```\n\n## Notes\n\n***curtin_userdata*** is a YAML file so any thing that applies to the YAML\n1.2 specification should work here. For example, you'll notice\n***&myinterfaces*** and __*myinterfaces__, these are node anchors more\ncommonly called references for repeating YAML items. See\n[this wikipedia page](http://en.wikipedia.org/wiki/YAML#References)\nfor more information and the\n[YAML spec](http://www.yaml.org/spec/1.2/spec.html).\n",
      "date": "2013-10-09T18:49:00",
      "title": "Customizing fastpath (curtin) installations in MAAS",
      "tags": "python, fastpath, maas, curtin",
      "author": "Adam Stokes",
      "path": "customizing-fastpath-curtin-installations",
      "compiled": "<p>Working off my previous entry about\n<strong><a href=\"http://astokes.org/using-fastpath-installer-maas/\">using fastpath installer in MAAS</a></strong>\nI decided to dig a little deeper into customizing those installations\na bit. One thing to note is\n<a href=\"http://launchpad.net/curtin\">fastpath(curtin/curt installer)</a>\ninstallations do not follow the same guidelines that are used in\npreseed files for Debian installer. Some overview documentation of\n<a href=\"http://bazaar.launchpad.net/~curtin-dev/curtin/trunk/view/head:/doc/topics/overview.rst\">fastpath can be located here</a>\nand thanks to <a href=\"http://ubuntu-smoser.blogspot.com/\">Scott Moser</a> we\nwere able to come up with the following example scenario.</p>\n<h2 id=\"example-scenario\">Example scenario</h2>\n<p><strong>Setting up vlans during a fastpath installation.</strong></p>\n<p>On the <strong><a href=\"http://maas.ubuntu.com\">MAAS</a></strong> server edit\n<code>/etc/maas/preseeds/curtin_userdata</code> and write the following\n(substituting your vlan configuration):</p>\n<pre><code class=\"lang-yaml\"><span class=\"xml\"># vlan config\nbucket:\n  &amp;myinterfaces |\n   # This file describes the network interfaces available on your system\n   # and how to activate them. For more information, see interfaces(5).\n\n   # The loopback network interface\n   auto lo\n   iface lo inet loopback\n\n   # The primary network interface\n   auto eth0\n   iface eth0 inet dhcp\n   auto vlan5\n   auto vlan100\n   iface vlan5 inet static\n     address 10.0.0.18\n     netmask 255.255.255.0\n     vlan-raw-device eth0\n   iface vlan100 inet static\n     address 192.168.66.118\n     netmask 255.255.255.0\n     vlan-raw-device eth0\n\n#cloud-config\ndebconf_selections:\n maas: |\n  </span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">for</span> <span class=\"hljs-variable\">line</span> <span class=\"hljs-variable\"><span class=\"hljs-keyword\">in</span></span> <span class=\"hljs-variable\">str</span>(<span class=\"hljs-variable\">curtin</span>_<span class=\"hljs-variable\">preseed</span>)<span class=\"hljs-variable\">.splitlines</span>()}}</span><span class=\"xml\">\n  </span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">line</span>}}</span><span class=\"xml\">\n  </span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">endfor</span>}}</span><span class=\"xml\">\nearly_commands:\n  update: apt-get update\n  vlan: apt-get install vlan -q -y\n\nlate_commands:\n  maas: [wget, '--no-proxy', '</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">node</span>_<span class=\"hljs-variable\">disable</span>_<span class=\"hljs-variable\">pxe</span>_<span class=\"hljs-variable\">url</span>|<span class=\"hljs-variable\">escape.shell</span>}}</span><span class=\"xml\">', '--post-data', '</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">node</span>_<span class=\"hljs-variable\">disable</span>_<span class=\"hljs-variable\">pxe</span>_<span class=\"hljs-variable\">data</span>|<span class=\"hljs-variable\">escape.shell</span>}}</span><span class=\"xml\">', '-O', '/dev/null']\n  load_8021q: ['sh', '-c', 'echo 8021q &gt;&gt; $TARGET_MOUNT_POINT/etc/modules']\n\nnetwork_commands:\n  vlans: ['sh', '-c', 'printf \"$1\" &gt; \"$OUTPUT_INTERFACES\"', '--', *myinterfaces]\n\npower_state:\n  mode: reboot\n\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\"><span class=\"hljs-keyword\">if</span></span> <span class=\"hljs-variable\">node.architecture</span> <span class=\"hljs-variable\"><span class=\"hljs-keyword\">in</span></span> {'<span class=\"hljs-variable\">i</span>386<span class=\"hljs-end-block\">/generic</span>', '<span class=\"hljs-variable\">amd</span>64<span class=\"hljs-end-block\">/generic</span>'} }}</span><span class=\"xml\">\napt_mirror: http://</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">main</span>_<span class=\"hljs-variable\">archive</span>_<span class=\"hljs-variable\">hostname</span>}}</span><span class=\"xml\">/</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">main</span>_<span class=\"hljs-variable\">archive</span>_<span class=\"hljs-variable\">directory</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\"><span class=\"hljs-keyword\">else</span></span>}}</span><span class=\"xml\">\napt_mirror: http://</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">ports</span>_<span class=\"hljs-variable\">archive</span>_<span class=\"hljs-variable\">hostname</span>}}</span><span class=\"xml\">/</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">ports</span>_<span class=\"hljs-variable\">archive</span>_<span class=\"hljs-variable\">directory</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">endif</span>}}</span><span class=\"xml\">\n\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\"><span class=\"hljs-keyword\">if</span></span> <span class=\"hljs-variable\">http</span>_<span class=\"hljs-variable\">proxy</span> }}</span><span class=\"xml\">\napt_proxy: </span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">http</span>_<span class=\"hljs-variable\">proxy</span>}}</span><span class=\"xml\">\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\"><span class=\"hljs-keyword\">else</span></span>}}</span><span class=\"xml\">\napt_proxy: http://</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">server</span>_<span class=\"hljs-variable\">host</span>}}</span><span class=\"xml\">:8000/\n</span><span class=\"hljs-expression\">{{<span class=\"hljs-variable\">endif</span>}}</span><span class=\"xml\"></span>\n</code></pre>\n<p>Once your node is deployed simply ssh into the instance and verify the\n<code>8021q</code> module is loaded and that <code>ifconfig</code> reports your added vlans.</p>\n<p>Our <code>lsmod</code> output shows the proper module loaded</p>\n<pre><code>ubuntu<span class=\"hljs-variable\">@node1</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>lsmod|grep <span class=\"hljs-number\">8021</span>q\n<span class=\"hljs-number\">8021</span>q                  <span class=\"hljs-number\">24084</span>  <span class=\"hljs-number\">0</span> \ngarp                   <span class=\"hljs-number\">14602</span>  <span class=\"hljs-number\">1</span> <span class=\"hljs-number\">8021</span>q\n</code></pre><p><code>/etc/network/interfaces</code> shows the correct vlan information</p>\n<pre><code><span class=\"hljs-attribute\">auto</span> lo\niface lo inet loopback\n<span class=\"hljs-attribute\">auto</span> eth0\niface eth0 inet dhcp\n<span class=\"hljs-attribute\">auto</span> vlan5\n<span class=\"hljs-attribute\">auto</span> vlan100\niface vlan5 inet static\n  <span class=\"hljs-tag\">address</span> <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">0.18</span>\n  netmask <span class=\"hljs-number\">255.255</span>.<span class=\"hljs-number\">255.0</span>\n  vlan-raw-device eth0\niface vlan100 inet static\n  <span class=\"hljs-tag\">address</span> <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">66.118</span>\n  netmask <span class=\"hljs-number\">255.255</span>.<span class=\"hljs-number\">255.0</span>\n  vlan-raw-device eth0\n</code></pre><h2 id=\"notes\">Notes</h2>\n<p><strong><em>curtin_userdata</em></strong> is a YAML file so any thing that applies to the YAML\n1.2 specification should work here. For example, you&#39;ll notice\n<strong><em>&amp;myinterfaces</em></strong> and <strong>*myinterfaces</strong>, these are node anchors more\ncommonly called references for repeating YAML items. See\n<a href=\"http://en.wikipedia.org/wiki/YAML#References\">this wikipedia page</a>\nfor more information and the\n<a href=\"http://www.yaml.org/spec/1.2/spec.html\">YAML spec</a>.</p>\n"
    },
    {
      "body": "<p>A small review of what's happening as we enter into our 3rd month of development for the next major release of sosreport 3.1 (<em>approximate due date of February 2014</em>).</p>\n<p><strong>Here is a rundown of what we need help on:</strong></p>\n<ul>\n<li>Documentation</li>\n<li>Openstack guru's to review our existing plugins and provide feedback and/or code submissions.\n<ul>\n<li>Our priority is to make sure we are capturing everything needed to successfully troubleshoot issues occurring within all of openstack's moving parts.</li>\n<li>Validating all captured configs to make sure we've scrubbed out any secrets/credentials.</li>\n<li>Any new additions since Havana.</li>\n</ul>\n</li>\n<li>MAAS/Juju guru's to review existing plugins and provide feedback and/or code.</li>\n<li>Security auditing\n<ul>\n<li>Mainly need extra set of eyes to make sure none of the plugins capture secret/confidential information along with scrubbing out those bits if unavoidable.</li>\n</ul>\n</li>\n</ul>\n<p>We also have a <a href=\"https://github.com/sosreport/sosreport/issues?milestone=2&amp;state=open\">list of bugs needing attention/resolution</a> that would also benefit from community contributions.</p>\n<p>Also be aware that <strong><em>support for Python 2.6 will be dropped</em></strong> in the next release as well.</p>\n",
      "date": "2013-10-18T21:00:00",
      "title": "sosreport: mid-milestone update",
      "tags": [
        "ubuntu",
        "python",
        "sosreport"
      ],
      "author": "Adam Stokes",
      "path": "sosreport-mid-milestone-update",
      "compiled": "<p>A small review of what&#39;s happening as we enter into our 3rd month of development for the next major release of sosreport 3.1 (<em>approximate due date of February 2014</em>).</p>\n<p><strong>Here is a rundown of what we need help on:</strong></p>\n<ul>\n<li>Documentation</li>\n<li>Openstack guru&#39;s to review our existing plugins and provide feedback and/or code submissions.\n<ul>\n<li>Our priority is to make sure we are capturing everything needed to successfully troubleshoot issues occurring within all of openstack&#39;s moving parts.</li>\n<li>Validating all captured configs to make sure we&#39;ve scrubbed out any secrets/credentials.</li>\n<li>Any new additions since Havana.</li>\n</ul>\n</li>\n<li>MAAS/Juju guru&#39;s to review existing plugins and provide feedback and/or code.</li>\n<li>Security auditing\n<ul>\n<li>Mainly need extra set of eyes to make sure none of the plugins capture secret/confidential information along with scrubbing out those bits if unavoidable.</li>\n</ul>\n</li>\n</ul>\n<p>We also have a <a href=\"https://github.com/sosreport/sosreport/issues?milestone=2&amp;state=open\">list of bugs needing attention/resolution</a> that would also benefit from community contributions.</p>\n<p>Also be aware that <strong><em>support for Python 2.6 will be dropped</em></strong> in the next release as well.</p>\n"
    },
    {
      "body": "<p>I've got a couple of new perl packages written for interacting with Salesforce.com, it's features include:</p>\n<ul>\n<li>OAuth 2 authentication with support for scopes including refresh_token and api. Easily add more for what you need in your application.</li>\n<li>Client that will query sobjects via JSON api so no more SOAP!</li>\n</ul>\n<p>Net::Salesforce is in pretty good condition to be used daily and Net::Salesforce::Client is usable but needs more models added to interact with Salesforce API. So far I've got models written for Accounts and Cases with more coming soon.</p>\n<p>As always contributions welcomed! You can find the code hosted on github at the following:</p>\n<ul>\n<li><a href=\"https://github.com/battlemidget/Net-Salesforce\">Net::Salesforce</a></li>\n<li><a href=\"https://github.com/battlemidget/Net-Salesforce-Client\">Net::Salesforce::Client</a></li>\n</ul>\n",
      "date": "2014-01-08T12:53:34",
      "title": "Salesforce.com meet Net::Salesforce",
      "tags": [
        "salesforce"
      ],
      "author": "Adam Stokes",
      "path": "salesforce-com-meet-netsalesforce",
      "compiled": "<p><p>I&#39;ve got a couple of new perl packages written for interacting with Salesforce.com, it&#39;s features include:</p></p>\n<ul>\n<li>OAuth 2 authentication with support for scopes including refresh_token and api. Easily add more for what you need in your application.</li>\n<li>Client that will query sobjects via JSON api so no more SOAP!</li>\n</ul>\n<p>Net::Salesforce is in pretty good condition to be used daily and Net::Salesforce::Client is usable but needs more models added to interact with Salesforce API. So far I&#39;ve got models written for Accounts and Cases with more coming soon.</p>\n<p>As always contributions welcomed! You can find the code hosted on github at the following:</p>\n<ul>\n<li><a href=\"https://github.com/battlemidget/Net-Salesforce\">Net::Salesforce</a></li>\n<li><a href=\"https://github.com/battlemidget/Net-Salesforce-Client\">Net::Salesforce::Client</a></li>\n</ul>\n"
    },
    {
      "body": "<p>Issues resolved in this release:</p>\n<p><a href=\"https://github.com/sosreport/sosreport/issues?milestone=2&amp;state=closed\">Closed items</a></p>\n<p>Enhancements:</p>\n<ul>\n<li>Full Python 3.x support</li>\n<li>Further modularized openstack plugins</li>\n<li>Switched the build to use pybuild</li>\n<li>Reports are generated by default</li>\n<li>Further sanitizing of all openstack credentials</li>\n<li>As of Ubuntu Trusty (14.04) sosreport will be included in the server iso's.</li>\n</ul>\n<p>Our next point release 3.1.1 could use contributors help to resolve a few low hanging fruit issues and is a great way to get familiar with Python.</p>\n<p><a href=\"https://github.com/sosreport/sosreport/issues?labels=&amp;milestone=4&amp;page=1&amp;state=open\">Next issues to be resolved for 3.1.1</a></p>\n",
      "date": "2014-01-31T12:32:00",
      "title": "SOSreport 3.1 released",
      "tags": "sosreport, ubuntu",
      "author": "Adam Stokes",
      "path": "sosreport-3-1-released",
      "compiled": "<p>Issues resolved in this release:</p>\n<p><a href=\"https://github.com/sosreport/sosreport/issues?milestone=2&amp;state=closed\">Closed items</a></p>\n<p>Enhancements:</p>\n<ul>\n<li>Full Python 3.x support</li>\n<li>Further modularized openstack plugins</li>\n<li>Switched the build to use pybuild</li>\n<li>Reports are generated by default</li>\n<li>Further sanitizing of all openstack credentials</li>\n<li>As of Ubuntu Trusty (14.04) sosreport will be included in the server iso&#39;s.</li>\n</ul>\n<p>Our next point release 3.1.1 could use contributors help to resolve a few low hanging fruit issues and is a great way to get familiar with Python.</p>\n<p><a href=\"https://github.com/sosreport/sosreport/issues?labels=&amp;milestone=4&amp;page=1&amp;state=open\">Next issues to be resolved for 3.1.1</a></p>\n"
    },
    {
      "body": "In an attempt to better learn the Juju internals I started working on\nsome Perl bindings and as a result a lot of time spent in the Go\ncodebase. The library utilizes an event-based approach making use of\ntechnologies such as [AnyEvent](https://metacpan.org/pod/AnyEvent) and\n[AnyEvent::WebSocket::Client](https://metacpan.org/pod/AnyEvent::WebSocket::Client). I\nam still going through the golang code to make the library api\ncomplete and the code is considered alpha quality so not recommended\nin production by any means. The library is located on\n[GitHub](https://github.com/battlemidget/perl-juju), as always\ncontributions welcomed. :P\n\n## A quick walkthrough\n\nInstalling is easy with `cpanm`, simply point the client at the github\nrepo and the dependencies will be handled for you:\n\n### Installing\n\n`$ cpanm git@github.com:battlemidget/perl-juju.git`\n\n### Example\n\nThis code snippet shows you how to pull the juju environment data\n\n```perl\n#!/usr/bin/env perl\n\nuse strict;\nuse warnings;\nuse v5.18.0;\nuse Juju::Environment;\nuse Mojo::JSON qw(j);\nuse Data::Dumper;\n\n$Data::Dumper::Indent = 1;\n\nmy $client = Juju::Environment->new(\n    endpoint => 'wss://10.0.3.1:17070/',\n    password => '211fdd69b8942c10cef6cfb8a4748fa4'\n);\n$client->login;\nmy $_info = $client->info;\nprint Dumper($_info);\n\n$client->close;\n\n__END__\n\nOutput of code:\n\n$VAR1 = {\n  'Name' => 'local',\n  'DefaultSeries' => 'precise',\n  'UUID' => '23929e29-5b3d-42d7-8984-5e18319aeacb',\n  'ProviderType' => 'local'\n};\n```\n\nI should probably put a disclaimer that this isn't endorsed by\nCanonical and please dont report any issues with this library to the\nJuju team. For now this is nothing more than a hobby project and maybe\na helpful starting point for others to write bindings in their\npreferred language.\n",
      "date": "2014-02-16T22:55:00",
      "title": "Perl bindings for Juju",
      "tags": "perl, juju, ubuntu",
      "author": "Adam Stokes",
      "path": "perl-bindings-for-juju",
      "compiled": "<p>In an attempt to better learn the Juju internals I started working on\nsome Perl bindings and as a result a lot of time spent in the Go\ncodebase. The library utilizes an event-based approach making use of\ntechnologies such as <a href=\"https://metacpan.org/pod/AnyEvent\">AnyEvent</a> and\n<a href=\"https://metacpan.org/pod/AnyEvent::WebSocket::Client\">AnyEvent::WebSocket::Client</a>. I\nam still going through the golang code to make the library api\ncomplete and the code is considered alpha quality so not recommended\nin production by any means. The library is located on\n<a href=\"https://github.com/battlemidget/perl-juju\">GitHub</a>, as always\ncontributions welcomed. :P</p>\n<h2 id=\"a-quick-walkthrough\">A quick walkthrough</h2>\n<p>Installing is easy with <code>cpanm</code>, simply point the client at the github\nrepo and the dependencies will be handled for you:</p>\n<h3 id=\"installing\">Installing</h3>\n<p><code>$ cpanm git@github.com:battlemidget/perl-juju.git</code></p>\n<h3 id=\"example\">Example</h3>\n<p>This code snippet shows you how to pull the juju environment data</p>\n<pre><code class=\"lang-perl\"><span class=\"hljs-comment\">#!/usr/bin/env perl</span>\n\n<span class=\"hljs-keyword\">use</span> <span class=\"hljs-title\">strict</span>;\n<span class=\"hljs-keyword\">use</span> <span class=\"hljs-title\">warnings</span>;\n<span class=\"hljs-keyword\">use</span> <span class=\"hljs-title\">v5</span>.18.0;\n<span class=\"hljs-keyword\">use</span> <span class=\"hljs-title\">Juju</span>::<span class=\"hljs-title\">Environment</span>;\n<span class=\"hljs-keyword\">use</span> <span class=\"hljs-title\">Mojo</span>::<span class=\"hljs-title\">JSON</span> <span class=\"hljs-title\">qw</span>(<span class=\"hljs-title\">j</span>);\n<span class=\"hljs-keyword\">use</span> <span class=\"hljs-title\">Data</span>::<span class=\"hljs-title\">Dumper</span>;\n\n<span class=\"hljs-variable\">$Data</span>::Dumper::Indent = <span class=\"hljs-number\">1</span>;\n\nmy <span class=\"hljs-variable\">$client</span> = Juju::Environment-&gt;new(\n    endpoint =&gt; <span class=\"hljs-string\">'wss://10.0.3.1:17070/'</span>,\n    password =&gt; <span class=\"hljs-string\">'211fdd69b8942c10cef6cfb8a4748fa4'</span>\n);\n<span class=\"hljs-variable\">$client</span>-&gt;login;\nmy <span class=\"hljs-variable\">$_info</span> = <span class=\"hljs-variable\">$client</span>-&gt;info;\n<span class=\"hljs-keyword\">print</span> Dumper(<span class=\"hljs-variable\">$_info</span>);\n\n<span class=\"hljs-variable\">$client</span>-&gt;close;\n\n__END__\n\nOutput of code:\n\n<span class=\"hljs-variable\">$VAR1</span> = {\n  <span class=\"hljs-string\">'Name'</span> =&gt; <span class=\"hljs-string\">'local'</span>,\n  <span class=\"hljs-string\">'DefaultSeries'</span> =&gt; <span class=\"hljs-string\">'precise'</span>,\n  <span class=\"hljs-string\">'UUID'</span> =&gt; <span class=\"hljs-string\">'23929e29-5b3d-42d7-8984-5e18319aeacb'</span>,\n  <span class=\"hljs-string\">'ProviderType'</span> =&gt; <span class=\"hljs-string\">'local'</span>\n};\n</code></pre>\n<p>I should probably put a disclaimer that this isn&#39;t endorsed by\nCanonical and please dont report any issues with this library to the\nJuju team. For now this is nothing more than a hobby project and maybe\na helpful starting point for others to write bindings in their\npreferred language.</p>\n"
    },
    {
      "body": "<p>While messing around with juju 1.18.x I managed to stumble across a setup that allows me to deploy both LXC and KVM containers in a single environment.</p>\n<h2>Pre-reqs</h2>\n<ul>\n<li>Juju v1.18 or higher</li>\n<li>libvirt-bin</li>\n<li>lxc</li>\n<li>Ubuntu Trusty or higher (only one I tested this on)</li>\n</ul>\n<h2>The juju environments.yaml</h2>\n<p>Very simple configuration for this</p>\n<pre><code>default: local\n\nenvironments:\n  local:\n    type: local\n    lxc-use-clone: true\n    container: kvm\n</code></pre>\n<p><strong>Note</strong> <em>lxc-use-clone</em> was introduced in juju 1.18.3 and 1.19.2. This will greatly reduce the wait time it takes to deploy systems into containers no matter the provider used (as long as it supports lxc)</p>\n<h2>Networking modification</h2>\n<p>In order for the machines to talk to one another we need to make sure that the KVM machine that's housing the lxc containers are utilizing the same network that the KVM uses. So if we didn't modify the network and attempted to deploy you would have <strong>machine 1</strong> with an ip of like <strong>10&#46;0.3.1</strong> and when you deploy a service to an lxc container within that KVM it would assign an address of <strong>10&#46;0.4.x</strong> or whatever the lxcbr0 is using for its network.</p>\n<p>To fix this you'll want to make sure that the KVM machine is using a host only network where lxcbr0 is bridged to the <strong>eth0</strong> device. The output below shows a simple way to make this work:</p>\n<p>In your <strong>/etc/network/interfaces.d/lxcbr0.cfg</strong> file put the following:</p>\n<pre><code>auto eth0\niface eth0 inet manual\n\nauto lxcbr0\niface lxcbr0 inet dhcp\n    bridge_ports eth0\n</code></pre>\n<p>From there you can remove the existing <strong>eth0.cfg</strong> file and reboot your kvm instance. Once rebooted you can <code>juju deploy mysql --to lxc:1</code> and it'll have the correct ip associated with it so that all kvm/lxc containers can communicate with one another.</p>\n<h2>Bootstrap and Deploy</h2>\n<pre><code>$ juju bootstrap\n$ juju set-constraints mem=2G\n$ juju add-machine\n$ juju deploy openstack-dashboard --to lxc:1\n$ juju deploy mysql --to lxc:1\n$ juju deploy keystone --to lxc:1\n$ juju add-machine\n$ juju deploy nova-compute\n</code></pre>\n<p>What this does is deploy a few openstack components to kvm and LXC where the KVM instances are your separate machines and lxc being containers within the KVM machine.</p>\n<h2>Output from a Openstack cloud deployed on a single machine using both lxc and kvm</h2>\n<pre><code>environment: local\nmachines:\n  \"0\":\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: localhost\n    instance-id: localhost\n    series: trusty\n  \"1\":\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: 10.0.3.64\n    instance-id: poe-local-machine-1\n    series: trusty\n    containers:\n      1/lxc/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.177\n        instance-id: juju-machine-1-lxc-0\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/1:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.230\n        instance-id: juju-machine-1-lxc-1\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/2:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.67\n        instance-id: juju-machine-1-lxc-2\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/3:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.178\n        instance-id: juju-machine-1-lxc-3\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/4:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.84\n        instance-id: juju-machine-1-lxc-4\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/5:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.14\n        instance-id: juju-machine-1-lxc-5\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/6:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.66\n        instance-id: juju-machine-1-lxc-6\n        series: trusty\n        hardware: arch=amd64\n    hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\n  \"2\":\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: 10.0.3.219\n    instance-id: poe-local-machine-2\n    series: trusty\n    hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\n  \"3\":\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: 10.0.3.237\n    instance-id: poe-local-machine-3\n    series: trusty\n    hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\nservices:\n  glance:\n    charm: cs:trusty/glance-0\n    exposed: false\n    relations:\n      cluster:\n      - glance\n      identity-service:\n      - keystone\n      image-service:\n      - nova-cloud-controller\n      - nova-compute\n      shared-db:\n      - mysql\n    units:\n      glance/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/2\n        open-ports:\n        - 9292/tcp\n        public-address: 10.0.3.67\n  juju-gui:\n    charm: cs:trusty/juju-gui-2\n    exposed: false\n    units:\n      juju-gui/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/4\n        open-ports:\n        - 80/tcp\n        - 443/tcp\n        public-address: 10.0.3.84\n  keystone:\n    charm: cs:trusty/keystone-2\n    exposed: false\n    relations:\n      cluster:\n      - keystone\n      identity-service:\n      - glance\n      - nova-cloud-controller\n      - openstack-dashboard\n      shared-db:\n      - mysql\n    units:\n      keystone/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/5\n        public-address: 10.0.3.14\n  mysql:\n    charm: cs:trusty/mysql-0\n    exposed: false\n    relations:\n      cluster:\n      - mysql\n      shared-db:\n      - glance\n      - keystone\n      - nova-cloud-controller\n      - nova-compute\n    units:\n      mysql/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: \"3\"\n        public-address: 10.0.3.237\n  nova-cloud-controller:\n    charm: cs:trusty/nova-cloud-controller-36\n    exposed: false\n    relations:\n      amqp:\n      - rabbitmq-server\n      cloud-compute:\n      - nova-compute\n      cluster:\n      - nova-cloud-controller\n      identity-service:\n      - keystone\n      image-service:\n      - glance\n      shared-db:\n      - mysql\n    units:\n      nova-cloud-controller/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/1\n        open-ports:\n        - 3333/tcp\n        - 8773/tcp\n        - 8774/tcp\n        public-address: 10.0.3.230\n  nova-compute:\n    charm: cs:trusty/nova-compute-0\n    exposed: false\n    relations:\n      amqp:\n      - rabbitmq-server\n      cloud-compute:\n      - nova-cloud-controller\n      compute-peer:\n      - nova-compute\n      image-service:\n      - glance\n      shared-db:\n      - mysql\n    units:\n      nova-compute/1:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: \"2\"\n        public-address: 10.0.3.219\n  openstack-dashboard:\n    charm: cs:trusty/openstack-dashboard-0\n    exposed: false\n    relations:\n      cluster:\n      - openstack-dashboard\n      identity-service:\n      - keystone\n    units:\n      openstack-dashboard/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/3\n        open-ports:\n        - 80/tcp\n        - 443/tcp\n        public-address: 10.0.3.178\n  rabbitmq-server:\n    charm: cs:trusty/rabbitmq-server-1\n    exposed: false\n    relations:\n      amqp:\n      - nova-cloud-controller\n      - nova-compute\n      cluster:\n      - rabbitmq-server\n    units:\n      rabbitmq-server/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/6\n        open-ports:\n        - 5672/tcp\n        public-address: 10.0.3.66\n</code></pre>\n<h2>Disclaimer</h2>\n<ul>\n<li>At this time it is not currently recommended to do it this way.</li>\n<li>I say do it anyway and see what you can deploy.</li>\n</ul>\n",
      "date": "2014-03-20T10:09:00",
      "title": "juju: deploy to lxc AND kvm in the local provider",
      "tags": "juju, ubuntu",
      "author": "Adam Stokes",
      "path": "juju-deploy-to-lxc-and-kvm-in-the-local-provider",
      "compiled": "<p><p>While messing around with juju 1.18.x I managed to stumble across a setup that allows me to deploy both LXC and KVM containers in a single environment.</p></p>\n<p><h2>Pre-reqs</h2></p>\n<ul>\n<li>Juju v1.18 or higher</li>\n<li>libvirt-bin</li>\n<li>lxc</li>\n<li>Ubuntu Trusty or higher (only one I tested this on)</li>\n</ul>\n<h2>The juju environments.yaml</h2>\n<p>Very simple configuration for this</p>\n<pre><code>default: local\n\nenvironments:\n  local:\n    type: local\n    lxc-use-clone: true\n    container: kvm\n</code></pre>\n<p><strong>Note</strong> <em>lxc-use-clone</em> was introduced in juju 1.18.3 and 1.19.2. This will greatly reduce the wait time it takes to deploy systems into containers no matter the provider used (as long as it supports lxc)</p>\n<h2>Networking modification</h2>\n<p>In order for the machines to talk to one another we need to make sure that the KVM machine that&#39;s housing the lxc containers are utilizing the same network that the KVM uses. So if we didn&#39;t modify the network and attempted to deploy you would have <strong>machine 1</strong> with an ip of like <strong>10&#46;0.3.1</strong> and when you deploy a service to an lxc container within that KVM it would assign an address of <strong>10&#46;0.4.x</strong> or whatever the lxcbr0 is using for its network.</p>\n<p>To fix this you&#39;ll want to make sure that the KVM machine is using a host only network where lxcbr0 is bridged to the <strong>eth0</strong> device. The output below shows a simple way to make this work:</p>\n<p>In your <strong>/etc/network/interfaces.d/lxcbr0.cfg</strong> file put the following:</p>\n<pre><code>auto eth0\niface eth0 inet manual\n\nauto lxcbr0\niface lxcbr0 inet dhcp\n    bridge_ports eth0\n</code></pre>\n<p>From there you can remove the existing <strong>eth0.cfg</strong> file and reboot your kvm instance. Once rebooted you can <code>juju deploy mysql --to lxc:1</code> and it&#39;ll have the correct ip associated with it so that all kvm/lxc containers can communicate with one another.</p>\n<h2>Bootstrap and Deploy</h2>\n<pre><code>$ juju bootstrap\n$ juju set-constraints mem=2G\n$ juju add-machine\n$ juju deploy openstack-dashboard --to lxc:1\n$ juju deploy mysql --to lxc:1\n$ juju deploy keystone --to lxc:1\n$ juju add-machine\n$ juju deploy nova-compute\n</code></pre>\n<p>What this does is deploy a few openstack components to kvm and LXC where the KVM instances are your separate machines and lxc being containers within the KVM machine.</p>\n<h2>Output from a Openstack cloud deployed on a single machine using both lxc and kvm</h2>\n<pre><code>environment: local\nmachines:\n  &quot;0&quot;:\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: localhost\n    instance-id: localhost\n    series: trusty\n  &quot;1&quot;:\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: 10.0.3.64\n    instance-id: poe-local-machine-1\n    series: trusty\n    containers:\n      1/lxc/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.177\n        instance-id: juju-machine-1-lxc-0\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/1:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.230\n        instance-id: juju-machine-1-lxc-1\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/2:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.67\n        instance-id: juju-machine-1-lxc-2\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/3:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.178\n        instance-id: juju-machine-1-lxc-3\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/4:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.84\n        instance-id: juju-machine-1-lxc-4\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/5:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.14\n        instance-id: juju-machine-1-lxc-5\n        series: trusty\n        hardware: arch=amd64\n      1/lxc/6:\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.66\n        instance-id: juju-machine-1-lxc-6\n        series: trusty\n        hardware: arch=amd64\n    hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\n  &quot;2&quot;:\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: 10.0.3.219\n    instance-id: poe-local-machine-2\n    series: trusty\n    hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\n  &quot;3&quot;:\n    agent-state: started\n    agent-version: 1.18.1.1\n    dns-name: 10.0.3.237\n    instance-id: poe-local-machine-3\n    series: trusty\n    hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\nservices:\n  glance:\n    charm: cs:trusty/glance-0\n    exposed: false\n    relations:\n      cluster:\n      - glance\n      identity-service:\n      - keystone\n      image-service:\n      - nova-cloud-controller\n      - nova-compute\n      shared-db:\n      - mysql\n    units:\n      glance/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/2\n        open-ports:\n        - 9292/tcp\n        public-address: 10.0.3.67\n  juju-gui:\n    charm: cs:trusty/juju-gui-2\n    exposed: false\n    units:\n      juju-gui/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/4\n        open-ports:\n        - 80/tcp\n        - 443/tcp\n        public-address: 10.0.3.84\n  keystone:\n    charm: cs:trusty/keystone-2\n    exposed: false\n    relations:\n      cluster:\n      - keystone\n      identity-service:\n      - glance\n      - nova-cloud-controller\n      - openstack-dashboard\n      shared-db:\n      - mysql\n    units:\n      keystone/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/5\n        public-address: 10.0.3.14\n  mysql:\n    charm: cs:trusty/mysql-0\n    exposed: false\n    relations:\n      cluster:\n      - mysql\n      shared-db:\n      - glance\n      - keystone\n      - nova-cloud-controller\n      - nova-compute\n    units:\n      mysql/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: &quot;3&quot;\n        public-address: 10.0.3.237\n  nova-cloud-controller:\n    charm: cs:trusty/nova-cloud-controller-36\n    exposed: false\n    relations:\n      amqp:\n      - rabbitmq-server\n      cloud-compute:\n      - nova-compute\n      cluster:\n      - nova-cloud-controller\n      identity-service:\n      - keystone\n      image-service:\n      - glance\n      shared-db:\n      - mysql\n    units:\n      nova-cloud-controller/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/1\n        open-ports:\n        - 3333/tcp\n        - 8773/tcp\n        - 8774/tcp\n        public-address: 10.0.3.230\n  nova-compute:\n    charm: cs:trusty/nova-compute-0\n    exposed: false\n    relations:\n      amqp:\n      - rabbitmq-server\n      cloud-compute:\n      - nova-cloud-controller\n      compute-peer:\n      - nova-compute\n      image-service:\n      - glance\n      shared-db:\n      - mysql\n    units:\n      nova-compute/1:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: &quot;2&quot;\n        public-address: 10.0.3.219\n  openstack-dashboard:\n    charm: cs:trusty/openstack-dashboard-0\n    exposed: false\n    relations:\n      cluster:\n      - openstack-dashboard\n      identity-service:\n      - keystone\n    units:\n      openstack-dashboard/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/3\n        open-ports:\n        - 80/tcp\n        - 443/tcp\n        public-address: 10.0.3.178\n  rabbitmq-server:\n    charm: cs:trusty/rabbitmq-server-1\n    exposed: false\n    relations:\n      amqp:\n      - nova-cloud-controller\n      - nova-compute\n      cluster:\n      - rabbitmq-server\n    units:\n      rabbitmq-server/0:\n        agent-state: started\n        agent-version: 1.18.1.1\n        machine: 1/lxc/6\n        open-ports:\n        - 5672/tcp\n        public-address: 10.0.3.66\n</code></pre>\n<h2>Disclaimer</h2>\n<ul>\n<li>At this time it is not currently recommended to do it this way.</li>\n<li>I say do it anyway and see what you can deploy.</li>\n</ul>\n"
    },
    {
      "body": "[Juju sos](https://github.com/battlemidget/juju-sos) is my entryway into Go code and the juju internals. This plugin will execute and pull [sosreports](https://github.com/sosreport/sos) from all machines known to juju or a specific machine of your choice and copy them locally on your machine.\n\nAn example of what this plugin does, first, some output of `juju status` to give you an idea of the machines I have:\n\n    ┌[poe@cloudymeatballs] [/dev/pts/1] \n    └[~]> juju status\n    environment: local\n    machines:\n      \"0\":\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: localhost\n        instance-id: localhost\n        series: trusty\n      \"1\":\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.27\n        instance-id: poe-local-machine-1\n        series: trusty\n        hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\n      \"2\":\n        agent-state: started\n        agent-version: 1.18.1.1\n        dns-name: 10.0.3.19\n        instance-id: poe-local-machine-2\n        series: trusty\n        hardware: arch=amd64 cpu-cores=1 mem=2048M root-disk=8192M\n    services:\n      keystone:\n        charm: cs:trusty/keystone-2\n        exposed: false\n        relations:\n          cluster:\n          - keystone\n          identity-service:\n          - openstack-dashboard\n        units:\n          keystone/0:\n            agent-state: started\n            agent-version: 1.18.1.1\n            machine: \"2\"\n            public-address: 10.0.3.19\n      openstack-dashboard:\n        charm: cs:trusty/openstack-dashboard-0\n        exposed: false\n        relations:\n          cluster:\n          - openstack-dashboard\n          identity-service:\n          - keystone\n        units:\n          openstack-dashboard/0:\n            agent-state: started\n            agent-version: 1.18.1.1\n            machine: \"1\"\n            open-ports:\n            - 80/tcp\n            - 443/tcp\n            public-address: 10.0.3.27\n\nBasically what we are looking at is 2 machines that are running various services on them in my case **Openstack Horizon** and **Keystone**. Now suppose I have some issues with my juju machines and openstack and I need a quick way to gather a bunch of data on those machines and send them to someone who can help. With my [juju-sos plugin](https://github.com/battlemidget/juju-sos), I can quickly gather sosreports on each of the machines I care about in as little typing as possible.\n\nHere is the output from `juju sos` querying all machines known to juju:\n\n```bash\n┌[poe@cloudymeatballs] [/dev/pts/1] \n└[~]> juju sos -d ~/scratch\n2014-04-23 05:30:47 INFO juju.provider.local environprovider.go:40 opening environment \"local\"\n2014-04-23 05:30:47 INFO juju.state open.go:81 opening state, mongo addresses: [\"10.0.3.1:37017\"]; entity \"\"\n2014-04-23 05:30:47 INFO juju.state open.go:133 dialled mongo successfully\n2014-04-23 05:30:47 INFO juju.sos.cmd cmd.go:53 Querying all machines\n2014-04-23 05:30:47 INFO juju.sos.cmd cmd.go:59 Adding machine(1)\n2014-04-23 05:30:47 INFO juju.sos.cmd cmd.go:59 Adding machine(2)\n2014-04-23 05:30:47 INFO juju.sos.cmd cmd.go:88 Capturing sosreport for machine 1\n2014-04-23 05:30:55 INFO juju.sos main.go:119 Copying archive to \"/home/poe/scratch\"\n2014-04-23 05:30:56 INFO juju.sos.cmd cmd.go:88 Capturing sosreport for machine 2\n2014-04-23 05:31:08 INFO juju.sos main.go:119 Copying archive to \"/home/poe/scratch\"\n\n┌[poe@cloudymeatballs] [/dev/pts/1] \n└[~]> ls $HOME/scratch\nsosreport-ubuntu-20140423040507.tar.xz  sosreport-ubuntu-20140423052125.tar.xz  sosreport-ubuntu-20140423052545.tar.xz\nsosreport-ubuntu-20140423050401.tar.xz  sosreport-ubuntu-20140423052223.tar.xz  sosreport-ubuntu-20140423052600.tar.xz\nsosreport-ubuntu-20140423050727.tar.xz  sosreport-ubuntu-20140423052330.tar.xz  sosreport-ubuntu-20140423052610.tar.xz\nsosreport-ubuntu-20140423051436.tar.xz  sosreport-ubuntu-20140423052348.tar.xz  sosreport-ubuntu-20140423053052.tar.xz\nsosreport-ubuntu-20140423051635.tar.xz  sosreport-ubuntu-20140423052450.tar.xz  sosreport-ubuntu-20140423053101.tar.xz\nsosreport-ubuntu-20140423052006.tar.xz  sosreport-ubuntu-20140423052532.tar.xz\n```\n\nAnother example of `juju sos` just capturing a sosreport from one machine:\n\n```bash\n┌[poe@cloudymeatballs] [/dev/pts/1] \n└[~]> juju sos -d ~/scratch -m 2\n2014-04-23 05:41:59 INFO juju.provider.local environprovider.go:40 opening environment \"local\"\n2014-04-23 05:42:00 INFO juju.state open.go:81 opening state, mongo addresses: [\"10.0.3.1:37017\"]; entity \"\"\n2014-04-23 05:42:00 INFO juju.state open.go:133 dialled mongo successfully\n2014-04-23 05:42:00 INFO juju.sos.cmd cmd.go:70 Querying one machine(2)\n2014-04-23 05:42:00 INFO juju.sos.cmd cmd.go:88 Capturing sosreport for machine 2\n2014-04-23 05:42:08 INFO juju.sos main.go:99 Copying archive to \"/home/poe/scratch\"\n```\n\nFancy, fancy :)\n\nOf course this is a _work in progress_ and I have a few ideas of what else to add here, some of those being:\n\n*   Rename the sosreports to match the dns-name of the juju machine\n*   Filter sosreport captures based on services\n*   Optionally pass arguments to sosreport command in order to filter out specific plugins I want to run, ie\n\n    `$ juju sos -d ~/sosreport -- -b -o juju,maas,nova-compute`\n\nAs usual contributions are welcomed and some installation instructions are located in the [readme](https://github.com/battlemidget/juju-sos/blob/master/README.md)\n",
      "date": "2014-04-23T01:52:00",
      "title": "new juju plugin: juju-sos",
      "tags": "ubuntu, juju",
      "author": "Adam Stokes",
      "path": "new-juju-plugin-juju-sos",
      "compiled": "<p><a href=\"https://github.com/battlemidget/juju-sos\">Juju sos</a> is my entryway into Go code and the juju internals. This plugin will execute and pull <a href=\"https://github.com/sosreport/sos\">sosreports</a> from all machines known to juju or a specific machine of your choice and copy them locally on your machine.</p>\n<p>An example of what this plugin does, first, some output of <code>juju status</code> to give you an idea of the machines I have:</p>\n<pre><code>┌[poe<span class=\"hljs-annotation\">@cloudymeatballs</span>] [<span class=\"hljs-regexp\">/dev/</span>pts/<span class=\"hljs-number\">1</span>] \n└[~]&gt; juju status\n<span class=\"hljs-string\">environment:</span> local\n<span class=\"hljs-string\">machines:</span>\n  <span class=\"hljs-string\">\"0\"</span>:\n    agent-<span class=\"hljs-string\">state:</span> started\n    agent-<span class=\"hljs-string\">version:</span> <span class=\"hljs-number\">1.18</span>.1.1\n    dns-<span class=\"hljs-string\">name:</span> localhost\n    instance-<span class=\"hljs-string\">id:</span> localhost\n<span class=\"hljs-label\">    series:</span> trusty\n  <span class=\"hljs-string\">\"1\"</span>:\n    agent-<span class=\"hljs-string\">state:</span> started\n    agent-<span class=\"hljs-string\">version:</span> <span class=\"hljs-number\">1.18</span>.1.1\n    dns-<span class=\"hljs-string\">name:</span> <span class=\"hljs-number\">10.0</span>.3.27\n    instance-<span class=\"hljs-string\">id:</span> poe-local-machine-<span class=\"hljs-number\">1</span>\n<span class=\"hljs-label\">    series:</span> trusty\n<span class=\"hljs-label\">    hardware:</span> arch=amd64 cpu-cores=<span class=\"hljs-number\">1</span> mem=<span class=\"hljs-number\">2048</span>M root-disk=<span class=\"hljs-number\">8192</span>M\n  <span class=\"hljs-string\">\"2\"</span>:\n    agent-<span class=\"hljs-string\">state:</span> started\n    agent-<span class=\"hljs-string\">version:</span> <span class=\"hljs-number\">1.18</span>.1.1\n    dns-<span class=\"hljs-string\">name:</span> <span class=\"hljs-number\">10.0</span>.3.19\n    instance-<span class=\"hljs-string\">id:</span> poe-local-machine-<span class=\"hljs-number\">2</span>\n<span class=\"hljs-label\">    series:</span> trusty\n<span class=\"hljs-label\">    hardware:</span> arch=amd64 cpu-cores=<span class=\"hljs-number\">1</span> mem=<span class=\"hljs-number\">2048</span>M root-disk=<span class=\"hljs-number\">8192</span>M\n<span class=\"hljs-string\">services:</span>\n<span class=\"hljs-label\">  keystone:</span>\n<span class=\"hljs-label\">    charm:</span> <span class=\"hljs-string\">cs:</span>trusty/keystone-<span class=\"hljs-number\">2</span>\n<span class=\"hljs-label\">    exposed:</span> <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-label\">    relations:</span>\n<span class=\"hljs-label\">      cluster:</span>\n      - keystone\n      identity-<span class=\"hljs-string\">service:</span>\n      - openstack-dashboard\n<span class=\"hljs-label\">    units:</span>\n      keystone/<span class=\"hljs-number\">0</span>:\n        agent-<span class=\"hljs-string\">state:</span> started\n        agent-<span class=\"hljs-string\">version:</span> <span class=\"hljs-number\">1.18</span>.1.1\n<span class=\"hljs-label\">        machine:</span> <span class=\"hljs-string\">\"2\"</span>\n        <span class=\"hljs-keyword\">public</span>-<span class=\"hljs-string\">address:</span> <span class=\"hljs-number\">10.0</span>.3.19\n  openstack-<span class=\"hljs-string\">dashboard:</span>\n<span class=\"hljs-label\">    charm:</span> <span class=\"hljs-string\">cs:</span>trusty/openstack-dashboard-<span class=\"hljs-number\">0</span>\n<span class=\"hljs-label\">    exposed:</span> <span class=\"hljs-literal\">false</span>\n<span class=\"hljs-label\">    relations:</span>\n<span class=\"hljs-label\">      cluster:</span>\n      - openstack-dashboard\n      identity-<span class=\"hljs-string\">service:</span>\n      - keystone\n<span class=\"hljs-label\">    units:</span>\n      openstack-dashboard/<span class=\"hljs-number\">0</span>:\n        agent-<span class=\"hljs-string\">state:</span> started\n        agent-<span class=\"hljs-string\">version:</span> <span class=\"hljs-number\">1.18</span>.1.1\n<span class=\"hljs-label\">        machine:</span> <span class=\"hljs-string\">\"1\"</span>\n        open-<span class=\"hljs-string\">ports:</span>\n        - <span class=\"hljs-number\">80</span>/tcp\n        - <span class=\"hljs-number\">443</span>/tcp\n        <span class=\"hljs-keyword\">public</span>-<span class=\"hljs-string\">address:</span> <span class=\"hljs-number\">10.0</span>.3.27\n</code></pre><p>Basically what we are looking at is 2 machines that are running various services on them in my case <strong>Openstack Horizon</strong> and <strong>Keystone</strong>. Now suppose I have some issues with my juju machines and openstack and I need a quick way to gather a bunch of data on those machines and send them to someone who can help. With my <a href=\"https://github.com/battlemidget/juju-sos\">juju-sos plugin</a>, I can quickly gather sosreports on each of the machines I care about in as little typing as possible.</p>\n<p>Here is the output from <code>juju sos</code> querying all machines known to juju:</p>\n<pre><code class=\"lang-bash\">┌[poe@cloudymeatballs] [/dev/pts/<span class=\"hljs-number\">1</span>] \n└[~]&gt; juju sos -d ~/scratch\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">47</span> INFO juju.provider.local environprovider.go:<span class=\"hljs-number\">40</span> opening environment <span class=\"hljs-string\">\"local\"</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">47</span> INFO juju.<span class=\"hljs-keyword\">state</span> open.go:<span class=\"hljs-number\">81</span> opening <span class=\"hljs-keyword\">state</span>, mongo addresses: [<span class=\"hljs-string\">\"10.0.3.1:37017\"</span>]; entity <span class=\"hljs-string\">\"\"</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">47</span> INFO juju.<span class=\"hljs-keyword\">state</span> open.go:<span class=\"hljs-number\">133</span> dialled mongo successfully\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">47</span> INFO juju.sos.cmd cmd.go:<span class=\"hljs-number\">53</span> Querying <span class=\"hljs-literal\">all</span> machines\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">47</span> INFO juju.sos.cmd cmd.go:<span class=\"hljs-number\">59</span> Adding machine(<span class=\"hljs-number\">1</span>)\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">47</span> INFO juju.sos.cmd cmd.go:<span class=\"hljs-number\">59</span> Adding machine(<span class=\"hljs-number\">2</span>)\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">47</span> INFO juju.sos.cmd cmd.go:<span class=\"hljs-number\">88</span> Capturing sosreport <span class=\"hljs-keyword\">for</span> machine <span class=\"hljs-number\">1</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">55</span> INFO juju.sos main.go:<span class=\"hljs-number\">119</span> Copying archive <span class=\"hljs-keyword\">to</span> <span class=\"hljs-string\">\"/home/poe/scratch\"</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">30</span>:<span class=\"hljs-number\">56</span> INFO juju.sos.cmd cmd.go:<span class=\"hljs-number\">88</span> Capturing sosreport <span class=\"hljs-keyword\">for</span> machine <span class=\"hljs-number\">2</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">31</span>:<span class=\"hljs-number\">08</span> INFO juju.sos main.go:<span class=\"hljs-number\">119</span> Copying archive <span class=\"hljs-keyword\">to</span> <span class=\"hljs-string\">\"/home/poe/scratch\"</span>\n\n┌[poe@cloudymeatballs] [/dev/pts/<span class=\"hljs-number\">1</span>] \n└[~]&gt; ls <span class=\"hljs-variable\">$HOME</span>/scratch\nsosreport-ubuntu-<span class=\"hljs-number\">20140423040507</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052125</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052545</span>.tar.xz\nsosreport-ubuntu-<span class=\"hljs-number\">20140423050401</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052223</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052600</span>.tar.xz\nsosreport-ubuntu-<span class=\"hljs-number\">20140423050727</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052330</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052610</span>.tar.xz\nsosreport-ubuntu-<span class=\"hljs-number\">20140423051436</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052348</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423053052</span>.tar.xz\nsosreport-ubuntu-<span class=\"hljs-number\">20140423051635</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052450</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423053101</span>.tar.xz\nsosreport-ubuntu-<span class=\"hljs-number\">20140423052006</span>.tar.xz  sosreport-ubuntu-<span class=\"hljs-number\">20140423052532</span>.tar.xz\n</code></pre>\n<p>Another example of <code>juju sos</code> just capturing a sosreport from one machine:</p>\n<pre><code class=\"lang-bash\">┌[poe@cloudymeatballs] [/dev/pts/<span class=\"hljs-number\">1</span>] \n└[~]&gt; juju sos -d ~/scratch -m <span class=\"hljs-number\">2</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">41</span>:<span class=\"hljs-number\">59</span> INFO juju.provider.local environprovider.go:<span class=\"hljs-number\">40</span> opening environment <span class=\"hljs-string\">\"local\"</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">42</span>:<span class=\"hljs-number\">00</span> INFO juju.<span class=\"hljs-keyword\">state</span> open.go:<span class=\"hljs-number\">81</span> opening <span class=\"hljs-keyword\">state</span>, mongo addresses: [<span class=\"hljs-string\">\"10.0.3.1:37017\"</span>]; entity <span class=\"hljs-string\">\"\"</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">42</span>:<span class=\"hljs-number\">00</span> INFO juju.<span class=\"hljs-keyword\">state</span> open.go:<span class=\"hljs-number\">133</span> dialled mongo successfully\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">42</span>:<span class=\"hljs-number\">00</span> INFO juju.sos.cmd cmd.go:<span class=\"hljs-number\">70</span> Querying one machine(<span class=\"hljs-number\">2</span>)\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">42</span>:<span class=\"hljs-number\">00</span> INFO juju.sos.cmd cmd.go:<span class=\"hljs-number\">88</span> Capturing sosreport <span class=\"hljs-keyword\">for</span> machine <span class=\"hljs-number\">2</span>\n<span class=\"hljs-number\">2014</span>-<span class=\"hljs-number\">04</span>-<span class=\"hljs-number\">23</span> <span class=\"hljs-number\">05</span>:<span class=\"hljs-number\">42</span>:<span class=\"hljs-number\">08</span> INFO juju.sos main.go:<span class=\"hljs-number\">99</span> Copying archive <span class=\"hljs-keyword\">to</span> <span class=\"hljs-string\">\"/home/poe/scratch\"</span>\n</code></pre>\n<p>Fancy, fancy :)</p>\n<p>Of course this is a <em>work in progress</em> and I have a few ideas of what else to add here, some of those being:</p>\n<ul>\n<li>Rename the sosreports to match the dns-name of the juju machine</li>\n<li>Filter sosreport captures based on services</li>\n<li><p>Optionally pass arguments to sosreport command in order to filter out specific plugins I want to run, ie</p>\n<p><code>$ juju sos -d ~/sosreport -- -b -o juju,maas,nova-compute</code></p>\n</li>\n</ul>\n<p>As usual contributions are welcomed and some installation instructions are located in the <a href=\"https://github.com/battlemidget/juju-sos/blob/master/README.md\">readme</a></p>\n"
    },
    {
      "body": "As the title suggests this little gem is an OpenStack installer tailored specifically to get you from zero to hero in just a short amount of time.\n\nThere are a few options available today for deploying an OpenStack cloud. For instance, [juju-deployer](http://pythonhosted.org/juju-deployer/) with an OpenStack specific bundle or that other thing called [devstack](http://devstack.org/). While these technologies work we wanted to take our existing technologies and go a step further. A lot of people may not have 10 systems laying around to utilize juju-deployer or you may be wanting to demonstrate to the powers that be that implementing Ubuntu, Juju, MAAS, and OpenStack within your company is a great idea. Of course you could bring one of those shiny orange boxes or a handful of Intel NUCS into the conference room _or_ ..\n\n.. install the Ubuntu OpenStack Installer and get a cloud to play with on a single machine. Getting started is ez-pz.\n\n## Requirements\n\n*   Decent machine, tested on a machine with 8 cores, 12G ram, and 100G HDD.\n*   Ubuntu Trusty 14.04\n*   Juju 1.20.x (includes support for lxc fast cloning for multiple providers)\n*   About 30 minutes of your time.\n\n## First\n\nAdd the **ppa** and install the software.\n\n```bash\n    $ sudo apt-add-repository ppa:cloud-installer/testing\n    $ sudo apt-get update\n    $ sudo apt-get install openstack\n```\n\n## Second\n\nRun it.\n\n`$ sudo openstack-install`\n\nYou'll first be asked for an OpenStack password, this can be anything of your choosing and will be the password used throughout the rest of the install and also the password used for logging into various services (Horizon, Juju GUI, Landscape)\n\n## Third\n\nYou're presented with 3 options, a **Single**, **Multi**, and **Landscape OpenStack Autopilot**. Select **Single**.\n\n## Post\n\nThe installer will go through its little routine of installing necessary packages and setting up configuration. Once this is complete you'll be dropped into a _status screen_ which will then begin the magical journey of getting you setup with a fully functioning OpenStack cloud.\n\n# Is that all?\n\nYep, to elaborate a bit I'll explain what's happening:\n\nThe entire stack is running off a single machine in a single **LXC** container. Having the deployment within a container allows for an undestructive way to test out a new OpenStack deployment as cleaning up is a matter of removing the container or uninstalling the _openstack_ package. Juju is heavily utilized for its ability to deploy services, setup relations, and configure those services. Similar to what juju-deployer does. What juju-deployer doesn't do is automatically sync boot images via simplestreams or automatically configure neutron to have all deployed instances within nova-compute available on the same network as the host machine all while using a single network card. We even throw in **juju-gui** for good measure :D.\n\nThe experience we are trying to achieve is that any one person can sit down at a machine and have a complete end to end working Openstack environment. All while keeping your gray hair at a minimum and your budget intact. Heres a screenshot of our nifty console ui:\n\n## Verify\n\nVerifying your cloud is easy, just go through the process of deploying an instance via Horizon (Openstack Dashboard), associating a floating IP (already created for you just need to select one) and ssh into the newly created instance to deploy your software stack. Depending on bandwidth some images may not be immediately available and may require you to wait a little longer.\n\n## What about those other install options?\n\nWell, as I stated before we have a lot of cool technologies out there like MAAS. That is what the **Multi Install** is for. The cool thing about this is you install it the same way you would a **Single Install**. Fast-forward past the package installing and to the status screen you'll be presented with a dialog stating to PXE boot a machine to act as the controller. Our installer tries to do everything for you but some things are left up to you. In this case you'd commission a machine in the MAAS environment and get it into a ready state. From there the Installer will pick up that machine and continue on its merry way as it did during the single installation.\n\nOne thing to note is you'll want to have a few machines whether it be bare metal or virtual registered in MAAS to make use of all the installer has to offer. I was able to get a full cloud deployed on 3 machines, 1 bare metal (the host machine running maas), 2 virtual machines registered in MAAS. Keep in mind there were no additional network devices added as the installer can configure neutron on a single NIC :)\n\n## Where to go from here?\n\nIf you need swift storage for your glance images hit **(F6)** in the status screen and select **Swift storage**. This will deploy the necessary bits for swift-storage to be integrated into your Openstack cloud. Swift storage requires at least 3 nodes (in the single install this would be 3 VMs) so make sure you've got the hardware for this. Otherwise, for developing/toying around with Openstack leaving the defaults works just as good.\n\nThis is just an intro into the installer more documentation can be found @ [ReadTheDocs](http://ubuntu-cloud-installer.readthedocs.org/en/latest/index.html). The project is hosted @ [GitHub](https://github.com/Ubuntu-Solutions-Engineering/cloud-installer) and we definitely encourage you to star it, fork it, file issues, and contribute back to make this a truly enjoyable experience. If you need help please come talk to us on IRC @ freenode.net/#ubuntu-solutions.\n",
      "date": "2014-06-26T20:40:00",
      "title": "Ubuntu Openstack Installer",
      "tags": "openstack, ubuntu",
      "author": "Adam Stokes",
      "path": "ubuntu-openstack-installer",
      "compiled": "<p>As the title suggests this little gem is an OpenStack installer tailored specifically to get you from zero to hero in just a short amount of time.</p>\n<p>There are a few options available today for deploying an OpenStack cloud. For instance, <a href=\"http://pythonhosted.org/juju-deployer/\">juju-deployer</a> with an OpenStack specific bundle or that other thing called <a href=\"http://devstack.org/\">devstack</a>. While these technologies work we wanted to take our existing technologies and go a step further. A lot of people may not have 10 systems laying around to utilize juju-deployer or you may be wanting to demonstrate to the powers that be that implementing Ubuntu, Juju, MAAS, and OpenStack within your company is a great idea. Of course you could bring one of those shiny orange boxes or a handful of Intel NUCS into the conference room <em>or</em> ..</p>\n<p>.. install the Ubuntu OpenStack Installer and get a cloud to play with on a single machine. Getting started is ez-pz.</p>\n<h2 id=\"requirements\">Requirements</h2>\n<ul>\n<li>Decent machine, tested on a machine with 8 cores, 12G ram, and 100G HDD.</li>\n<li>Ubuntu Trusty 14.04</li>\n<li>Juju 1.20.x (includes support for lxc fast cloning for multiple providers)</li>\n<li>About 30 minutes of your time.</li>\n</ul>\n<h2 id=\"first\">First</h2>\n<p>Add the <strong>ppa</strong> and install the software.</p>\n<pre><code class=\"lang-bash\">    $ sudo apt-<span class=\"hljs-built_in\">add</span>-repository <span class=\"hljs-keyword\">pp</span><span class=\"hljs-variable\">a:cloud</span>-installer/testing\n    $ sudo apt-<span class=\"hljs-built_in\">get</span> <span class=\"hljs-keyword\">update</span>\n    $ sudo apt-<span class=\"hljs-built_in\">get</span> install openstack\n</code></pre>\n<h2 id=\"second\">Second</h2>\n<p>Run it.</p>\n<p><code>$ sudo openstack-install</code></p>\n<p>You&#39;ll first be asked for an OpenStack password, this can be anything of your choosing and will be the password used throughout the rest of the install and also the password used for logging into various services (Horizon, Juju GUI, Landscape)</p>\n<h2 id=\"third\">Third</h2>\n<p>You&#39;re presented with 3 options, a <strong>Single</strong>, <strong>Multi</strong>, and <strong>Landscape OpenStack Autopilot</strong>. Select <strong>Single</strong>.</p>\n<h2 id=\"post\">Post</h2>\n<p>The installer will go through its little routine of installing necessary packages and setting up configuration. Once this is complete you&#39;ll be dropped into a <em>status screen</em> which will then begin the magical journey of getting you setup with a fully functioning OpenStack cloud.</p>\n<h1 id=\"is-that-all-\">Is that all?</h1>\n<p>Yep, to elaborate a bit I&#39;ll explain what&#39;s happening:</p>\n<p>The entire stack is running off a single machine in a single <strong>LXC</strong> container. Having the deployment within a container allows for an undestructive way to test out a new OpenStack deployment as cleaning up is a matter of removing the container or uninstalling the <em>openstack</em> package. Juju is heavily utilized for its ability to deploy services, setup relations, and configure those services. Similar to what juju-deployer does. What juju-deployer doesn&#39;t do is automatically sync boot images via simplestreams or automatically configure neutron to have all deployed instances within nova-compute available on the same network as the host machine all while using a single network card. We even throw in <strong>juju-gui</strong> for good measure :D.</p>\n<p>The experience we are trying to achieve is that any one person can sit down at a machine and have a complete end to end working Openstack environment. All while keeping your gray hair at a minimum and your budget intact. Heres a screenshot of our nifty console ui:</p>\n<h2 id=\"verify\">Verify</h2>\n<p>Verifying your cloud is easy, just go through the process of deploying an instance via Horizon (Openstack Dashboard), associating a floating IP (already created for you just need to select one) and ssh into the newly created instance to deploy your software stack. Depending on bandwidth some images may not be immediately available and may require you to wait a little longer.</p>\n<h2 id=\"what-about-those-other-install-options-\">What about those other install options?</h2>\n<p>Well, as I stated before we have a lot of cool technologies out there like MAAS. That is what the <strong>Multi Install</strong> is for. The cool thing about this is you install it the same way you would a <strong>Single Install</strong>. Fast-forward past the package installing and to the status screen you&#39;ll be presented with a dialog stating to PXE boot a machine to act as the controller. Our installer tries to do everything for you but some things are left up to you. In this case you&#39;d commission a machine in the MAAS environment and get it into a ready state. From there the Installer will pick up that machine and continue on its merry way as it did during the single installation.</p>\n<p>One thing to note is you&#39;ll want to have a few machines whether it be bare metal or virtual registered in MAAS to make use of all the installer has to offer. I was able to get a full cloud deployed on 3 machines, 1 bare metal (the host machine running maas), 2 virtual machines registered in MAAS. Keep in mind there were no additional network devices added as the installer can configure neutron on a single NIC :)</p>\n<h2 id=\"where-to-go-from-here-\">Where to go from here?</h2>\n<p>If you need swift storage for your glance images hit <strong>(F6)</strong> in the status screen and select <strong>Swift storage</strong>. This will deploy the necessary bits for swift-storage to be integrated into your Openstack cloud. Swift storage requires at least 3 nodes (in the single install this would be 3 VMs) so make sure you&#39;ve got the hardware for this. Otherwise, for developing/toying around with Openstack leaving the defaults works just as good.</p>\n<p>This is just an intro into the installer more documentation can be found @ <a href=\"http://ubuntu-cloud-installer.readthedocs.org/en/latest/index.html\">ReadTheDocs</a>. The project is hosted @ <a href=\"https://github.com/Ubuntu-Solutions-Engineering/cloud-installer\">GitHub</a> and we definitely encourage you to star it, fork it, file issues, and contribute back to make this a truly enjoyable experience. If you need help please come talk to us on IRC @ freenode.net/#ubuntu-solutions.</p>\n"
    },
    {
      "body": "## Current approach\n\nJuju's existing providers(except manual) do not allow you to containerize the bootstrap node. However, in the manual provider this is possible using something like this in your **environments.yaml** file and setting the **boostrap-host** appropriately:\n\n```yaml\n    ## https://juju.ubuntu.com/docs/config-manual.html\n    manual:\n        type: manual\n        # bootstrap-host holds the host name of the machine where the\n        # bootstrap machine agent will be started.org\n        bootstrap-host: somehost.example.com\n        # bootstrap-user specifies the user to authenticate as when\n        # connecting to the bootstrap machine. If defaults to\n        # the current user.\n        # bootstrap-user: joebloggs\n        # storage-listen-ip specifies the IP address that the\n        # bootstrap machine's Juju storage server will listen\n        # on. By default, storage will be served on all\n        # network interfaces.\n        # storage-listen-ip:\n        # storage-port specifes the TCP port that the\n        # bootstrap machine's Juju storage server will listen\n        # on. It defaults to 8040\n        # storage-port: 8040\n```\n\nCool, that will allow me to bootstrap juju on something other than my host machine. But, that machine needs to be configured appropriately for a non-interactive deployment (setting ssh keys, passwordless sudo, etc).\n\n## A different approach\n\nIn my particular case we wanted our Openstack Installer to be fully containerized from juju bootstrap to deploying of compute nodes. In order to achieve this we need to configure an existing container to be our bootstrap agent **and** still allow for our mixture of kvm/lxc environments for use within the Openstack deployment.\n\n### Walkthrough\n\nCreate a container named **joojoo** that will be used as our Juju bootstrap agent:\n\n```bash\nubuntu@fluffy:~$ sudo lxc-create -t ubuntu -n joojoo\n```\n\nUpdate the container's **lxcbr0** to be on its own network:\n\n```bash\nubuntu@fluffy:~$ cat >>-EOF | sudo tee /var/lib/lxc/joojoo/rootfs/etc/default/lxc-net\n    USE_LXC_BRIDGE=\"true\"\n    LXC_BRIDGE=\"lxcbr0\"\n    LXC_ADDR=\"10.0.4.1\"\n    LXC_NETMASK=\"255.255.255.0\"\n    LXC_NETWORK=\"10.0.4.0/24\"\n    LXC_DHCP_RANGE=\"10.0.4.2,10.0.4.254\"\n    LXC_DHCP_MAX=\"253\"\n    EOF\n```\n\nCreate the necessary character files for kvm support within lxc via `mknod`, also persist them through reboots.\n\n```bash\nubuntu@fluffy:~$ cat >>-EOF | sudo tee /var/lib/lxc/joojoo/rootfs/etc/rc.local\n    #!/bin/sh\n    mkdir -p /dev/net || true\n    mknod /dev/kvm c 10 232\n    mknod /dev/net/tun c 10 200\n    exit 0\n    EOF\n```\n\nStart the container\n\n```bash\nubuntu@fluffy:~$ sudo lxc-start -n joojoo -d\n```\n\nPre-install libvirt and uvtools\n\n```bash\nubuntu@fluffy:~$ sudo lxc-attach -n joojoo -- apt-get update\nubuntu@fluffy:~$ sudo lxc-attach -n joojoo -- apt-get install -qyf \\\n   libvirt-bin uvtool uvtool-libvirt software-properties-common\n```\nMake sure our **ubuntu** user has the correct `libvirtd` group associated\n\n```bash\nubuntu@fluffy:~$ sudo lxc-attach -n joojoo -- usermod -a -G libvirtd ubuntu\n```\n\n### Now that you have a containerized environment ready for Juju, lets test!\n\nThe LXC container should now be ready for a juju deployment. Lets use our Openstack Cloud Installer to test this setup. I want to make sure everything deploys into its appropriate containers/kvm instances and that I can still access the Horizon dashboard to deploy a compute instance.\n\nFirst, ssh into your container, you can get the IP with the `lxc-ls -f` command:\n\n```bash\nubuntu@fluffy:~$ sudo lxc-ls -f joojoo\n    NAME    STATE    IPV4       IPV6  AUTOSTART\n    -------------------------------------------\n    joojoo  RUNNING  10.0.3.3   -     NO\n\nubuntu@fluffy:~$ ssh ubuntu@10.0.3.3\n```\n\nWithin the container add our PPA and perform the installation:\n\n```bash\nubuntu@joojoo:~$ sudo apt-add-repository ppa:cloud-installer/experimental\nubuntu@joojoo:~$ sudo apt-add-repository ppa:juju/stable\nubuntu@joojoo:~$ sudo apt update && sudo apt install cloud-installer\nubuntu@joojoo:~$ sudo openstack-install\n```\n\n**Note** I'm using our experimental PPA for Openstack Cloud Installer which will be our next major release and will automate the previous steps for putting juju within a container.\n\nThis test I'm using the **Single Install** method, so select that and enter a Openstack password of your choice. Now sit back and wait for the installation to finish.\n\n### Recap\n\nFirst we created a LXC container to be used as our **entry point** for juju to bootstrap itself too. This required some configuration changes to how the container will handle bridged connections along with making sure the character devices required by KVM are available.\n\nNext we installed some pre-requisites for libvirt and uvtools.\n\nFrom there we login to the newly created container, install, and run the Openstack Cloud Installer. This will install juju-core and lxc as dependencies along with automatically configuring lxc-net with our predefined `lxc-net` template, seen in the latest `lxc-ls` output (showing eth0, lxcbr0, and virbr0):\n\n```bash\nubuntu@fluffy:~$ sudo lxc-ls -f\n    NAME    STATE    IPV4                               IPV6  AUTOSTART  \n    -------------------------------------------------------------------\n    joojoo  RUNNING  10.0.3.3, 10.0.4.1, 192.168.122.1  -     NO\n```\n\nOnce the installer is finished we verify that our LXC container was able to facilitate the deployment of services in both LXC (nested) and KVM (also nested within LXC).\n\nIt's a long list so here is the [pastebin](http://paste.ubuntu.com/8021230/). What you'll notice is that all machines/services are now bound to the 10.0.4.x network which is what was defined in the `lxc-net` configuration above. We have KVM's running within our host container which also houses containers for the Openstack deployment.\n\nJust to give a more visual representation of the setup:\n\n```\nBaremetal Machine\n- LXC Container\n  - Runs juju bootstrap agent\n    - KVM (machine 1)\n      - Houses a bunch of LXC's for the openstack services\n    - KVM (machine 2)\n      - Houses nova-compute\n    - KVM (machine 3)\n      - Houses quantum-gateway\n```\n\n### Why is this a good thing?\n\n```bash\nubuntu@fluffy:~$ sudo lxc-stop -n joojoo\nubuntu@fluffy:~$ sudo lxc-destroy -n joojoo\n```\n\nAnd it's like it never happened ...\n\n## Acknowledgements\n\nThanks to a colleague, [Robert Ayres](http://voices.canonical.com/robert.ayres/), who provided the necessary information for getting KVM to run within an LXC container.\n",
      "date": "2014-08-11T19:05:00",
      "title": "Containerize juju's local provider",
      "tags": "ubuntu, openstack",
      "author": "Adam Stokes",
      "path": "containerize-jujus-local-provider",
      "compiled": "<h2 id=\"current-approach\">Current approach</h2>\n<p>Juju&#39;s existing providers(except manual) do not allow you to containerize the bootstrap node. However, in the manual provider this is possible using something like this in your <strong>environments.yaml</strong> file and setting the <strong>boostrap-host</strong> appropriately:</p>\n<pre><code class=\"lang-yaml\">    <span class=\"hljs-comment\">## https://juju.ubuntu.com/docs/config-manual.html</span>\n    manual:\n        <span class=\"hljs-built_in\">type</span>: manual\n        <span class=\"hljs-comment\"># bootstrap-host holds the host name of the machine where the</span>\n        <span class=\"hljs-comment\"># bootstrap machine agent will be started.org</span>\n        bootstrap-<span class=\"hljs-keyword\">host</span>: somehost.example.com\n        <span class=\"hljs-comment\"># bootstrap-user specifies the user to authenticate as when</span>\n        <span class=\"hljs-comment\"># connecting to the bootstrap machine. If defaults to</span>\n        <span class=\"hljs-comment\"># the current user.</span>\n        <span class=\"hljs-comment\"># bootstrap-user: joebloggs</span>\n        <span class=\"hljs-comment\"># storage-listen-ip specifies the IP address that the</span>\n        <span class=\"hljs-comment\"># bootstrap machine's Juju storage server will listen</span>\n        <span class=\"hljs-comment\"># on. By default, storage will be served on all</span>\n        <span class=\"hljs-comment\"># network interfaces.</span>\n        <span class=\"hljs-comment\"># storage-listen-ip:</span>\n        <span class=\"hljs-comment\"># storage-port specifes the TCP port that the</span>\n        <span class=\"hljs-comment\"># bootstrap machine's Juju storage server will listen</span>\n        <span class=\"hljs-comment\"># on. It defaults to 8040</span>\n        <span class=\"hljs-comment\"># storage-port: 8040</span>\n</code></pre>\n<p>Cool, that will allow me to bootstrap juju on something other than my host machine. But, that machine needs to be configured appropriately for a non-interactive deployment (setting ssh keys, passwordless sudo, etc).</p>\n<h2 id=\"a-different-approach\">A different approach</h2>\n<p>In my particular case we wanted our Openstack Installer to be fully containerized from juju bootstrap to deploying of compute nodes. In order to achieve this we need to configure an existing container to be our bootstrap agent <strong>and</strong> still allow for our mixture of kvm/lxc environments for use within the Openstack deployment.</p>\n<h3 id=\"walkthrough\">Walkthrough</h3>\n<p>Create a container named <strong>joojoo</strong> that will be used as our Juju bootstrap agent:</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-create -t ubuntu -n joojoo\n</code></pre>\n<p>Update the container&#39;s <strong>lxcbr0</strong> to be on its own network:</p>\n<pre><code class=\"lang-bash\">ubuntu@fluffy:~$ cat &gt;&gt;-EOF | sudo tee /var/lib/lxc/joojoo/rootfs/etc/default/lxc-net\n    <span class=\"hljs-variable\">USE_LXC_BRIDGE=</span><span class=\"hljs-string\">\"true\"</span>\n    <span class=\"hljs-variable\">LXC_BRIDGE=</span><span class=\"hljs-string\">\"lxcbr0\"</span>\n    <span class=\"hljs-variable\">LXC_ADDR=</span><span class=\"hljs-string\">\"10.0.4.1\"</span>\n    <span class=\"hljs-variable\">LXC_NETMASK=</span><span class=\"hljs-string\">\"255.255.255.0\"</span>\n    <span class=\"hljs-variable\">LXC_NETWORK=</span><span class=\"hljs-string\">\"10.0.4.0/24\"</span>\n    <span class=\"hljs-variable\">LXC_DHCP_RANGE=</span><span class=\"hljs-string\">\"10.0.4.2,10.0.4.254\"</span>\n    <span class=\"hljs-variable\">LXC_DHCP_MAX=</span><span class=\"hljs-string\">\"253\"</span>\n    EOF\n</code></pre>\n<p>Create the necessary character files for kvm support within lxc via <code>mknod</code>, also persist them through reboots.</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-annotation\">@fluffy</span>:~$ cat &gt;&gt;-EOF | sudo tee <span class=\"hljs-regexp\">/var/</span>lib<span class=\"hljs-regexp\">/lxc/</span>joojoo<span class=\"hljs-regexp\">/rootfs/</span>etc/rc.local\n    #!<span class=\"hljs-regexp\">/bin/</span>sh\n    mkdir -p <span class=\"hljs-regexp\">/dev/</span>net || <span class=\"hljs-literal\">true</span>\n    mknod <span class=\"hljs-regexp\">/dev/</span>kvm c <span class=\"hljs-number\">10</span> <span class=\"hljs-number\">232</span>\n    mknod <span class=\"hljs-regexp\">/dev/</span>net/tun c <span class=\"hljs-number\">10</span> <span class=\"hljs-number\">200</span>\n    exit <span class=\"hljs-number\">0</span>\n    EOF\n</code></pre>\n<p>Start the container</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-start -n joojoo -d\n</code></pre>\n<p>Pre-install libvirt and uvtools</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-attach -n joojoo -- apt-get update\nubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-attach -n joojoo -- apt-get install -qyf \\\n   libvirt-bin uvtool uvtool-libvirt software-properties-common\n</code></pre>\n<p>Make sure our <strong>ubuntu</strong> user has the correct <code>libvirtd</code> group associated</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-attach -n joojoo -- usermod -a -<span class=\"hljs-constant\">G </span>libvirtd ubuntu\n</code></pre>\n<h3 id=\"now-that-you-have-a-containerized-environment-ready-for-juju-lets-test-\">Now that you have a containerized environment ready for Juju, lets test!</h3>\n<p>The LXC container should now be ready for a juju deployment. Lets use our Openstack Cloud Installer to test this setup. I want to make sure everything deploys into its appropriate containers/kvm instances and that I can still access the Horizon dashboard to deploy a compute instance.</p>\n<p>First, ssh into your container, you can get the IP with the <code>lxc-ls -f</code> command:</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-ls -f joojoo\n    <span class=\"hljs-constant\">NAME </span>   <span class=\"hljs-constant\">STATE </span>   <span class=\"hljs-constant\">IPV4 </span>      <span class=\"hljs-constant\">IPV6 </span> <span class=\"hljs-constant\">AUTOSTART</span>\n    -------------------------------------------\n    joojoo  <span class=\"hljs-constant\">RUNNING </span> <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">3.3</span>   -     <span class=\"hljs-constant\">NO</span>\n\nubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>ssh ubuntu<span class=\"hljs-variable\">@10</span>.<span class=\"hljs-number\">0</span>.<span class=\"hljs-number\">3.3</span>\n</code></pre>\n<p>Within the container add our PPA and perform the installation:</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@joojoo</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo apt-add-repository <span class=\"hljs-symbol\">ppa:</span>cloud-installer/experimental\nubuntu<span class=\"hljs-variable\">@joojoo</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo apt-add-repository <span class=\"hljs-symbol\">ppa:</span>juju/stable\nubuntu<span class=\"hljs-variable\">@joojoo</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo apt update &amp;&amp; sudo apt install cloud-installer\nubuntu<span class=\"hljs-variable\">@joojoo</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo openstack-install\n</code></pre>\n<p><strong>Note</strong> I&#39;m using our experimental PPA for Openstack Cloud Installer which will be our next major release and will automate the previous steps for putting juju within a container.</p>\n<p>This test I&#39;m using the <strong>Single Install</strong> method, so select that and enter a Openstack password of your choice. Now sit back and wait for the installation to finish.</p>\n<h3 id=\"recap\">Recap</h3>\n<p>First we created a LXC container to be used as our <strong>entry point</strong> for juju to bootstrap itself too. This required some configuration changes to how the container will handle bridged connections along with making sure the character devices required by KVM are available.</p>\n<p>Next we installed some pre-requisites for libvirt and uvtools.</p>\n<p>From there we login to the newly created container, install, and run the Openstack Cloud Installer. This will install juju-core and lxc as dependencies along with automatically configuring lxc-net with our predefined <code>lxc-net</code> template, seen in the latest <code>lxc-ls</code> output (showing eth0, lxcbr0, and virbr0):</p>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-ls -f\n    <span class=\"hljs-constant\">NAME </span>   <span class=\"hljs-constant\">STATE </span>   <span class=\"hljs-constant\">IPV4 </span>                              <span class=\"hljs-constant\">IPV6 </span> <span class=\"hljs-constant\">AUTOSTART </span> \n    -------------------------------------------------------------------\n    joojoo  <span class=\"hljs-constant\">RUNNING </span> <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">3.3</span>, <span class=\"hljs-number\">10.0</span>.<span class=\"hljs-number\">4.1</span>, <span class=\"hljs-number\">192.168</span>.<span class=\"hljs-number\">122.1</span>  -     <span class=\"hljs-constant\">NO</span>\n</code></pre>\n<p>Once the installer is finished we verify that our LXC container was able to facilitate the deployment of services in both LXC (nested) and KVM (also nested within LXC).</p>\n<p>It&#39;s a long list so here is the <a href=\"http://paste.ubuntu.com/8021230/\">pastebin</a>. What you&#39;ll notice is that all machines/services are now bound to the 10.0.4.x network which is what was defined in the <code>lxc-net</code> configuration above. We have KVM&#39;s running within our host container which also houses containers for the Openstack deployment.</p>\n<p>Just to give a more visual representation of the setup:</p>\n<pre><code>Baremetal Machine\n-<span class=\"ruby\"> <span class=\"hljs-constant\">LXC</span> <span class=\"hljs-constant\">Container</span>\n</span>  -<span class=\"ruby\"> <span class=\"hljs-constant\">Runs</span> juju bootstrap agent\n</span>    -<span class=\"ruby\"> <span class=\"hljs-constant\">KVM</span> (machine <span class=\"hljs-number\">1</span>)\n</span>      -<span class=\"ruby\"> <span class=\"hljs-constant\">Houses</span> a bunch of <span class=\"hljs-constant\">LXC</span><span class=\"hljs-string\">'s for the openstack services\n</span></span>    -<span class=\"ruby\"> <span class=\"hljs-constant\">KVM</span> (machine <span class=\"hljs-number\">2</span>)\n</span>      -<span class=\"ruby\"> <span class=\"hljs-constant\">Houses</span> nova-compute\n</span>    -<span class=\"ruby\"> <span class=\"hljs-constant\">KVM</span> (machine <span class=\"hljs-number\">3</span>)\n</span>      -<span class=\"ruby\"> <span class=\"hljs-constant\">Houses</span> quantum-gateway</span>\n</code></pre><h3 id=\"why-is-this-a-good-thing-\">Why is this a good thing?</h3>\n<pre><code class=\"lang-bash\">ubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-stop -n joojoo\nubuntu<span class=\"hljs-variable\">@fluffy</span><span class=\"hljs-symbol\">:~</span><span class=\"hljs-variable\">$ </span>sudo lxc-destroy -n joojoo\n</code></pre>\n<p>And it&#39;s like it never happened ...</p>\n<h2 id=\"acknowledgements\">Acknowledgements</h2>\n<p>Thanks to a colleague, <a href=\"http://voices.canonical.com/robert.ayres/\">Robert Ayres</a>, who provided the necessary information for getting KVM to run within an LXC container.</p>\n"
    },
    {
      "body": "The sos team is pleased to announce the release of sos-3.2. This release includes a large number of enhancements and fixes, including:\n\n* Profiles for plugin selection\n* Improved log size limiting\n* File archiving enhancements and robustness improvements\n* Global plugin options:\n  * `--verify`, `--log-size`, `--all-logs`\n* Better plugin descriptions\n* Improved journalctl log capture\n* PEP8 compliant code base\n* oVirt support improvements\n* New and updated plugins: hpasm, ctdb, dbus, oVirt engine hosted, MongoDB, ActiveMQ, OpenShift 2.0, MegaCLI, FCoEm, NUMA, Team network driver, Juju, MAAS, Openstack\n\nReferences:\n\n*   [Release Page](https://github.com/sosreport/sos/releases)\n*   [GitHub](https://github.com/sosreport/sos)\n*   [API Documentation](http://sos.readthedocs.org/en/latest/)\n",
      "date": "2014-09-30T13:55:00",
      "title": "sosreport (SoS) version 3.2 released",
      "tags": "ubuntu",
      "author": "Adam Stokes",
      "path": "sos-version-3-2-released",
      "compiled": "<p>The sos team is pleased to announce the release of sos-3.2. This release includes a large number of enhancements and fixes, including:</p>\n<ul>\n<li>Profiles for plugin selection</li>\n<li>Improved log size limiting</li>\n<li>File archiving enhancements and robustness improvements</li>\n<li>Global plugin options:<ul>\n<li><code>--verify</code>, <code>--log-size</code>, <code>--all-logs</code></li>\n</ul>\n</li>\n<li>Better plugin descriptions</li>\n<li>Improved journalctl log capture</li>\n<li>PEP8 compliant code base</li>\n<li>oVirt support improvements</li>\n<li>New and updated plugins: hpasm, ctdb, dbus, oVirt engine hosted, MongoDB, ActiveMQ, OpenShift 2.0, MegaCLI, FCoEm, NUMA, Team network driver, Juju, MAAS, Openstack</li>\n</ul>\n<p>References:</p>\n<ul>\n<li><a href=\"https://github.com/sosreport/sos/releases\">Release Page</a></li>\n<li><a href=\"https://github.com/sosreport/sos\">GitHub</a></li>\n<li><a href=\"http://sos.readthedocs.org/en/latest/\">API Documentation</a></li>\n</ul>\n"
    },
    {
      "body": "I recently released a Perl API client for LeanKit which covers the majority of exposed endpoints from the service.\n\nThis library can be installed from CPAN and supports Perl versions 5.14+:\n\n```\n$ cpanm Net::LeanKit\n```\n\n### An example use of the library:\n\n```perl\nuse strict;\nuse warnings;\nuse Net::LeanKit;\n\nmy $lk = Net::LeanKit->new(email => 'email@mail.com',\n                           password => 'password',\n                           account => 'mycompany');\n\nprint(\"Listing known boards\\n\");\nforeach my $board (@{$lk->getBoards}) {\n  printf(\"Board Name: %s has an id of %s\\n\", $board->{Title}, $board->{Id});\n}\n\nmy $boardByName = $lk->getBoardByName('Getting Started');\nprint(\"Board Lanes\\n\");\nforeach my $lane (@{$boardByName->{Lanes}}) {\n  printf(\"Lane id (%s) with title (%s)\\n\", $lane->{Id}, $lane->{Title});\n}\n```\n\nThis library is designed to match the same functionality as the <a href=\"https://github.com/LeanKit/leankit-node-client\">official nodejs client</a>.\n\nDocumentation on the available api can be found at <a href=\"https://metacpan.org/pod/Net::LeanKit\">the release page</a>. Also feel free to visit the <a href=\"https://github.com/battlemidget/p5-leankit\">github page</a> and to see other available bindings head over to <a href=\"https://support.leankit.com/entries/28686507-Other-LeanKit-API-Wrappers-and-Examples\">LeanKit's API wrappers</a> page.\n",
      "date": "2014-10-07T15:38:00",
      "title": "Perl bindings for LeanKit.com",
      "tags": [
        "api",
        "json",
        "rest"
      ],
      "author": "Adam Stokes",
      "path": "perl-bindings-for-leankit-com",
      "compiled": "<p>I recently released a Perl API client for LeanKit which covers the majority of exposed endpoints from the service.</p>\n<p>This library can be installed from CPAN and supports Perl versions 5.14+:</p>\n<pre><code><span class=\"hljs-variable\">$ </span>cpanm <span class=\"hljs-constant\">Net:</span><span class=\"hljs-symbol\">:LeanKit</span>\n</code></pre><h3 id=\"an-example-use-of-the-library-\">An example use of the library:</h3>\n<pre><code class=\"lang-perl\"><span class=\"hljs-keyword\">use</span> strict;\n<span class=\"hljs-keyword\">use</span> warnings;\n<span class=\"hljs-keyword\">use</span> Net::LeanKit;\n\n<span class=\"hljs-keyword\">my</span> <span class=\"hljs-variable\">$lk</span> = Net::LeanKit-&gt;new(<span class=\"hljs-string\">email =&gt;</span> <span class=\"hljs-string\">'email@mail.com'</span>,\n                           <span class=\"hljs-string\">password =&gt;</span> <span class=\"hljs-string\">'password'</span>,\n                           <span class=\"hljs-string\">account =&gt;</span> <span class=\"hljs-string\">'mycompany'</span>);\n\n<span class=\"hljs-keyword\">print</span>(<span class=\"hljs-string\">\"Listing known boards\\n\"</span>);\n<span class=\"hljs-keyword\">foreach</span> <span class=\"hljs-keyword\">my</span> <span class=\"hljs-variable\">$board</span> (@{<span class=\"hljs-variable\">$lk</span>-&gt;getBoards}) {\n  <span class=\"hljs-keyword\">printf</span>(<span class=\"hljs-string\">\"Board Name: <span class=\"hljs-variable\">%s</span> has an id of <span class=\"hljs-variable\">%s</span>\\n\"</span>, <span class=\"hljs-variable\">$board</span>-&gt;{Title}, <span class=\"hljs-variable\">$board</span>-&gt;{Id});\n}\n\n<span class=\"hljs-keyword\">my</span> <span class=\"hljs-variable\">$boardByName</span> = <span class=\"hljs-variable\">$lk</span>-&gt;getBoardByName(<span class=\"hljs-string\">'Getting Started'</span>);\n<span class=\"hljs-keyword\">print</span>(<span class=\"hljs-string\">\"Board Lanes\\n\"</span>);\n<span class=\"hljs-keyword\">foreach</span> <span class=\"hljs-keyword\">my</span> <span class=\"hljs-variable\">$lane</span> (@{<span class=\"hljs-variable\">$boardByName</span>-&gt;{Lanes}}) {\n  <span class=\"hljs-keyword\">printf</span>(<span class=\"hljs-string\">\"Lane id (<span class=\"hljs-variable\">%s</span>) with title (<span class=\"hljs-variable\">%s</span>)\\n\"</span>, <span class=\"hljs-variable\">$lane</span>-&gt;{Id}, <span class=\"hljs-variable\">$lane</span>-&gt;{Title});\n}\n</code></pre>\n<p>This library is designed to match the same functionality as the <a href=\"https://github.com/LeanKit/leankit-node-client\">official nodejs client</a>.</p>\n<p>Documentation on the available api can be found at <a href=\"https://metacpan.org/pod/Net::LeanKit\">the release page</a>. Also feel free to visit the <a href=\"https://github.com/battlemidget/p5-leankit\">github page</a> and to see other available bindings head over to <a href=\"https://support.leankit.com/entries/28686507-Other-LeanKit-API-Wrappers-and-Examples\">LeanKit&#39;s API wrappers</a> page.</p>\n"
    },
    {
      "body": "\n# Overview\n\nSometimes our default constraints for a Single Installation isn't enough. With our latest release it is possible to now configure the service placements with custom constraints.\n\nBelow is a fully working config example that you can modify to suit your hardware:\n\n## Example\n\n```yaml\ninstall_type: Single\nplacements:\n  controller:\n    assignments:\n      LXC:\n      - nova-cloud-controller\n      - glance\n      - glance-simplestreams-sync\n      - openstack-dashboard\n      - juju-gui\n      - keystone\n      - mysql\n      - neutron-api\n      - neutron-openvswitch\n      - rabbitmq-server\n      - swift-proxy\n    constraints:\n      cpu-cores: 2\n      mem: 6144\n      root-disk: 20480\n  nova-compute-machine-0:\n    assignments:\n      BareMetal:\n      - nova-compute\n    constraints:\n      mem: 4096\n      root-disk: 40960\n  quantum-gateway-machine-0:\n    assignments:\n      BareMetal:\n      - quantum-gateway\n    constraints:\n      mem: 2048\n      root-disk: 20480\n  swift-storage-machine-0:\n    assignments:\n      BareMetal:\n      - swift-storage\n    constraints: &id001 {}\n  swift-storage-machine-1:\n    assignments:\n      BareMetal:\n      - swift-storage\n    constraints: *id001\n  swift-storage-machine-2:\n    assignments:\n      BareMetal:\n      - swift-storage\n    constraints: *id001\n```\n\nLooking under the constraints for the **controller** you can expand on\nthe disk storage, memory, and cpus that will be allocated to that\nservice during deployment.\n\n### To make use of this config run:\n\n```bash\n$ sudo openstack-install -c config.yaml\n```\nIt'll walk you through setting a password and selecting the Single\ninstall mode. Once the installer is to the point of deployment it'll\nautomatically pickup your placements configuration and deploy based on\nthose updated constraints.\n\nHead over to\n[Single installer guide](http://ubuntu-cloud-installer.readthedocs.org/en/testing/single-installer.guide.html)\nfor more information. Also if you find bugs or have a feature request\nplease check out our\n[GitHub project](https://github.com/Ubuntu-Solutions-Engineering/openstack-installer)!\n",
      "date": "2015-02-18T10:42:00",
      "title": "Customizing the Single Install constraints",
      "tags": "ubuntu, openstack, juju",
      "author": "Adam Stokes",
      "path": "openstack-installer-customizing-the-single-install-constraints",
      "compiled": "<h1 id=\"overview\">Overview</h1>\n<p>Sometimes our default constraints for a Single Installation isn&#39;t enough. With our latest release it is possible to now configure the service placements with custom constraints.</p>\n<p>Below is a fully working config example that you can modify to suit your hardware:</p>\n<h2 id=\"example\">Example</h2>\n<pre><code class=\"lang-yaml\">install_type: Single\nplacements:\n  controller:\n    assignments:\n      LXC:\n      -<span class=\"ruby\"> nova-cloud-controller\n</span>      -<span class=\"ruby\"> glance\n</span>      -<span class=\"ruby\"> glance-simplestreams-sync\n</span>      -<span class=\"ruby\"> openstack-dashboard\n</span>      -<span class=\"ruby\"> juju-gui\n</span>      -<span class=\"ruby\"> keystone\n</span>      -<span class=\"ruby\"> mysql\n</span>      -<span class=\"ruby\"> neutron-api\n</span>      -<span class=\"ruby\"> neutron-openvswitch\n</span>      -<span class=\"ruby\"> rabbitmq-server\n</span>      -<span class=\"ruby\"> swift-proxy\n</span>    constraints:\n      cpu-cores: 2\n      mem: 6144\n      root-disk: 20480\n  nova-compute-machine-0:\n    assignments:\n      BareMetal:\n      -<span class=\"ruby\"> nova-compute\n</span>    constraints:\n      mem: 4096\n      root-disk: 40960\n  quantum-gateway-machine-0:\n    assignments:\n      BareMetal:\n      -<span class=\"ruby\"> quantum-gateway\n</span>    constraints:\n      mem: 2048\n      root-disk: 20480\n  swift-storage-machine-0:\n    assignments:\n      BareMetal:\n      -<span class=\"ruby\"> swift-storage\n</span>    constraints: &amp;id001 {}\n  swift-storage-machine-1:\n    assignments:\n      BareMetal:\n      -<span class=\"ruby\"> swift-storage\n</span>    constraints: *id001\n  swift-storage-machine-2:\n    assignments:\n      BareMetal:\n      -<span class=\"ruby\"> swift-storage\n</span>    constraints: *id001\n</code></pre>\n<p>Looking under the constraints for the <strong>controller</strong> you can expand on\nthe disk storage, memory, and cpus that will be allocated to that\nservice during deployment.</p>\n<h3 id=\"to-make-use-of-this-config-run-\">To make use of this config run:</h3>\n<pre><code class=\"lang-bash\">$ sudo openstack-<span class=\"hljs-keyword\">install</span> -c config.yaml\n</code></pre>\n<p>It&#39;ll walk you through setting a password and selecting the Single\ninstall mode. Once the installer is to the point of deployment it&#39;ll\nautomatically pickup your placements configuration and deploy based on\nthose updated constraints.</p>\n<p>Head over to\n<a href=\"http://ubuntu-cloud-installer.readthedocs.org/en/testing/single-installer.guide.html\">Single installer guide</a>\nfor more information. Also if you find bugs or have a feature request\nplease check out our\n<a href=\"https://github.com/Ubuntu-Solutions-Engineering/openstack-installer\">GitHub project</a>!</p>\n"
    },
    {
      "body": "\n[Canonical](http://www.canonical.com/) is pleased to\nwelcome [Coho Data](http://www.cohodata.com/), developer of the first\nflash-tuned scale-out storage architecture for private clouds, as an\nUbuntu Cloud partner and to our [OpenStack Interoperability Lab](http://partners.ubuntu.com/partner-programmes/openstack)\n(OIL) program. Coho provides web-scale storage for the cloud\ngeneration; delivering unparalleled performance and simplified\nmanagement at public cloud capacity pricing.\n\nAs the [OpenStack](http://www.ubuntu.com/cloud/openstack) ecosystem continues to grow rapidly, so does\nour [OpenStack Interoperability Lab](http://www.ubuntu.com/cloud/ecosystem/ubuntu-openstack-interoperability-lab). In OIL,\nCanonical conducts interoperability testing on 3,000 plus cloud configurations each month, now with\nCoho Data storage arrays along with 32 other OIL [partners on Ubuntu OpenStack](http://www.ubuntu.com/cloud/ecosystem).\nOIL provides customers with confidence that components of an OpenStack\ncloud interoperate well together – making it easier to deploy and\nconsume cloud resources. Canonical and Coho Data will also work\ntogether to simplify and automate the installation, deployment and\nmanagement of OpenStack cloud storage components. Coho Data will\nprovide[Charms](https://jujucharms.com/) to make it easy to deploy\ntheir storage arrays with OpenStack using Canonical’s[Juju](http://www.ubuntu.com/cloud/tools/juju).\n\n[Read More @ Ubuntu Insights](https://insights.ubuntu.com/2015/03/30/coho-data-partners-with-canonical-for-openstack-interoperability/)\n",
      "date": "2015-03-31T13:16:00",
      "title": "Coho Data partners with Canonical for OpenStack Operability",
      "tags": [
        "openstack",
        "cloud"
      ],
      "author": "Adam Stokes",
      "path": "coho-data-partners-with-canonical-for-openstack-operability",
      "compiled": "<p><a href=\"http://www.canonical.com/\">Canonical</a> is pleased to\nwelcome <a href=\"http://www.cohodata.com/\">Coho Data</a>, developer of the first\nflash-tuned scale-out storage architecture for private clouds, as an\nUbuntu Cloud partner and to our <a href=\"http://partners.ubuntu.com/partner-programmes/openstack\">OpenStack Interoperability Lab</a>\n(OIL) program. Coho provides web-scale storage for the cloud\ngeneration; delivering unparalleled performance and simplified\nmanagement at public cloud capacity pricing.</p>\n<p>As the <a href=\"http://www.ubuntu.com/cloud/openstack\">OpenStack</a> ecosystem continues to grow rapidly, so does\nour <a href=\"http://www.ubuntu.com/cloud/ecosystem/ubuntu-openstack-interoperability-lab\">OpenStack Interoperability Lab</a>. In OIL,\nCanonical conducts interoperability testing on 3,000 plus cloud configurations each month, now with\nCoho Data storage arrays along with 32 other OIL <a href=\"http://www.ubuntu.com/cloud/ecosystem\">partners on Ubuntu OpenStack</a>.\nOIL provides customers with confidence that components of an OpenStack\ncloud interoperate well together – making it easier to deploy and\nconsume cloud resources. Canonical and Coho Data will also work\ntogether to simplify and automate the installation, deployment and\nmanagement of OpenStack cloud storage components. Coho Data will\nprovide<a href=\"https://jujucharms.com/\">Charms</a> to make it easy to deploy\ntheir storage arrays with OpenStack using Canonical’s<a href=\"http://www.ubuntu.com/cloud/tools/juju\">Juju</a>.</p>\n<p><a href=\"https://insights.ubuntu.com/2015/03/30/coho-data-partners-with-canonical-for-openstack-interoperability/\">Read More @ Ubuntu Insights</a></p>\n"
    },
    {
      "body": "The landscape team has created a VMWare image preinstalled with Ubuntu\n14.04 LTS and Landscape Dedicated Server 15.01.1. If you wish to try\nout Landscape OpenStack Autopilot a MAAS server is still required and\nthat the hardware requirements are still met per the\n[official install documentation](http://www.ubuntu.com/download/cloud/install-ubuntu-openstack).\n\nFrom the README:\n\n```\nLandscape Dedicated Server in a VMWare Image\n============================================\n\nThis VMWare image contains a simple installation of Landscape Dedicated Server\n(LDS) in quickstart mode running on Ubuntu 14.04 LTS (\"trusty\"). This means\nthat all needed services are installed on just one VM. It is best suited for\ndemonstrations and quick trials.\n\nThe bundled license is enough to register 10 bare metal machines and 10 virtual\nmachines.\n\nThis is NOT meant for production usage!\n```\n\n## [Download](https://landscape.canonical.com/downloads/lds-15.01.1-vmware/)\n\nThis is the first time they've done anything like this so please download, try it out, and report any issues to the ubuntu-openstack-installer@lists.ubuntu.com or visit\n[the archive](https://lists.ubuntu.com/mailman/listinfo/ubuntu-openstack-installer).\n",
      "date": "2015-04-14T21:37:00",
      "title": "LDS 15.01.1 with AutoPilot VMWare image",
      "tags": [
        "ubuntu",
        "landscape"
      ],
      "author": "Adam Stokes",
      "path": "lds-15-01-1-with-autopilot-vmware-image",
      "compiled": "<p>The landscape team has created a VMWare image preinstalled with Ubuntu\n14.04 LTS and Landscape Dedicated Server 15.01.1. If you wish to try\nout Landscape OpenStack Autopilot a MAAS server is still required and\nthat the hardware requirements are still met per the\n<a href=\"http://www.ubuntu.com/download/cloud/install-ubuntu-openstack\">official install documentation</a>.</p>\n<p>From the README:</p>\n<pre><code>Landscape Dedicated Server <span class=\"hljs-keyword\">in</span> a VMWare Image\n============================================\n\nThis VMWare image <span class=\"hljs-keyword\">contains</span> a simple installation <span class=\"hljs-keyword\">of</span> Landscape Dedicated Server\n(LDS) <span class=\"hljs-keyword\">in</span> quickstart mode <span class=\"hljs-property\">running</span> <span class=\"hljs-function_start\"><span class=\"hljs-keyword\">on</span></span> Ubuntu <span class=\"hljs-number\">14.04</span> LTS (<span class=\"hljs-string\">\"trusty\"</span>). This means\n<span class=\"hljs-keyword\">that</span> all needed services are installed <span class=\"hljs-function_start\"><span class=\"hljs-keyword\">on</span></span> just one VM. It <span class=\"hljs-keyword\">is</span> best suited <span class=\"hljs-keyword\">for</span>\ndemonstrations <span class=\"hljs-keyword\">and</span> quick trials.\n\nThe bundled license <span class=\"hljs-keyword\">is</span> enough <span class=\"hljs-keyword\">to</span> register <span class=\"hljs-number\">10</span> bare metal machines <span class=\"hljs-keyword\">and</span> <span class=\"hljs-number\">10</span> virtual\nmachines.\n\nThis <span class=\"hljs-keyword\">is</span> NOT meant <span class=\"hljs-keyword\">for</span> production usage!\n</code></pre><h2 id=\"-download-https-landscape-canonical-com-downloads-lds-15-01-1-vmware-\"><a href=\"https://landscape.canonical.com/downloads/lds-15.01.1-vmware/\">Download</a></h2>\n<p>This is the first time they&#39;ve done anything like this so please download, try it out, and report any issues to the ubuntu-openstack-installer@lists.ubuntu.com or visit\n<a href=\"https://lists.ubuntu.com/mailman/listinfo/ubuntu-openstack-installer\">the archive</a>.</p>\n"
    },
    {
      "body": "\nThis is a quick introduction on extending Juju with plugins written in Go. What we'll cover:\n\n* Setting up your Go environment\n* Getting the Juju source code\n* Writing a basic plugin named **juju-lyaplugin** short for (juju-learnyouaplugin)\n* End result will be a plugin that closely resembles what **juju run** would do.\n\n# Prerequisites\n\n* Running on Ubuntu 14.04 or above\n* Go 1.2.1 or above (Article written using Go 1.2.1)\n* A basic understanding of the Go language, package imports, etc.\n\n# Setting up your Go environment\n\nThis is all a matter of preference but for the sake of this article we'll do it\nmy way :)\n\n## Install Go\n\nOn Trusty and above:\n\n```\nsudo apt-get install golang\n```\n\n## Go dependency management\n\n2 projects I use are:\n\n* https://github.com/pote/gpm - Barebones dependency manager for Go\n* https://github.com/pote/gvp - Go Versioning Packager\n\n### Install\n\n```\n$ cd /tmp && git clone https://github.com/pote/gvp.git && cd gvp && sudo ./configure && sudo make install\n$ cd /tmp && git clone https://github.com/pote/gpm.git && cd gpm && sudo ./configure && sudo make install\n```\n\nFeel free to check out their project pages for additional uses.\n\n## Create your project directory\n\n```\n$ mkdir ~/Projects/juju-learnyouaplugin\n$ cd ~/Projects/juju-learnyouaplugin\n```\n\n## Setup the project specific Go paths\n\n```\n$ source gvp in\n```\n\nThis will setup your **$GOPATH** and **$GOBIN** variables for use when resolving imports, compiling, etc.\n\n```\n$ echo $GOPATH\n/home/adam/Projects/juju-learnyouaplugin/.godeps\n$ echo $GOBIN\n/home/adam/Projects/juju-learnyouaplugin/.godeps/bin\n```\n\nFrom this point on all package dependencies will be stored in the project's **.godeps** directory.\n\n# Get the Juju code\n\nFrom your project's directory run:\n\n```\n$ go get -d -v github.com/juju/juju/...\n```\n\n# Writing the plugin\n\nNow that all the preparatory tasks are complete we can begin the fun\nstuff. Using your favorite editor open up a new file **main.go**. Within this file we need to define a few\npackage imports that are necessary for the plugin.\n\n```go\nimport (\n\t\"fmt\"\n\t\"github.com/juju/cmd\"\n\t\"github.com/juju/juju/apiserver/params\"\n\t\"github.com/juju/juju/cmd/envcmd\"\n\t\"github.com/juju/juju/juju\"\n\t\"github.com/juju/loggo\"\n\t\"github.com/juju/names\"\n\t\"launchpad.net/gnuflag\"\n\t\"os\"\n\t\"time\"\n\n\t_ \"github.com/juju/juju/provider/all\"\n)\n```\n\nLet's go through the imports and list why they are required.\n\n * **github.com/juju/cmd** - This import gives us access to the run context of a command ***[DefaultContext](https://godoc.org/github.com/juju/cmd#Context)***\n * **github.com/juju/juju/cmd/envcmd** - Provides ***[EnvCommandBase](https://godoc.org/github.com/juju/juju/cmd/envcmd#EnvCommandBase)*** for creating new commands and giving us access to the\n   [API Client](https://godoc.org/github.com/juju/juju/cmd/envcmd#EnvCommandBase.NewAPIClient) for making queries against the Juju state server.\n * **github.com/juju/juju/apiserver/params** - Provides access to 2 types [RunParams](https://godoc.org/github.com/juju/juju/apiserver/params#RunParams) and [RunResults](https://godoc.org/github.com/juju/juju/apiserver/params#RunResult) for executing the api call to [Run](https://godoc.org/github.com/juju/juju/api#Client.Run) and return the executed results.\n * **github.com/juju/juju/juju** - Provides access to ***[InitJujuHome](https://godoc.org/github.com/juju/juju/juju#InitJujuHome)*** for initializing the necessary bits like charm cache and environment. Required before running any juju cli command.\n * **github.com/juju/loggo** - Provides access to juju's logging api\n * **github.com/juju/names** - This package provides some convenience functions in particular we'll use ***[IsValidMachine](https://godoc.org/github.com/juju/names#IsValidMachine)***\n * **launchpad.net/gnuflag** - Provides the interface for our command definition like setting arguments, usage information, and execution.\n * **github.com/juju/juju/provider/all** - Registers all known providers (amazon, maas, local, etc)\n\nWith that said let's spec out the plugin type. This will hold our embedded command base and cli arguments.\n\n```go\ntype LYAPluginCommand struct {\n\tenvcmd.EnvCommandBase\n\tout      cmd.Output\n\ttimeout  time.Duration\n\tmachines []string\n\tservices []string\n\tunits    []string\n\tcommands string\n\tenvName string\n\tdescription bool\n}\n```\n\nOnce defined we can spec out our cli command and its functions.\n\n### The info function\n\nFirst part of the command is the ***[Info()](https://godoc.org/github.com/juju/cmd#SuperCommand.Info)*** function which returns\ninformation about the particular subcommand, in our case that is **lyaplugin**\n\n```go\nvar doc = `Run a command on target machine(s)\n\nThis example plugin mimics what \"juju run\" does.\n\neg.\n\njuju lyaplugin -m 1 -e local \"touch /tmp/testfile\"\n`\n\nfunc (c *LYAPluginCommand) Info() *cmd.Info {\n\treturn &cmd.Info{\n\t\tName:    \"lyaplugin\",\n\t\tArgs:    \"<commands>\",\n\t\tPurpose: \"Run a command on remote target\",\n\t\tDoc:     doc,\n\t}\n}\n```\n\n### SetFlags function\n\nNext we'll define what arguments are available to this new subcommand (**lyaplugin**).\n\n```go\nfunc (c *LYAPluginCommand) SetFlags(f *gnuflag.FlagSet) {\n\tf.BoolVar(&c.description, \"description\", false, \"Plugin Description\")\n\tf.Var(cmd.NewStringsValue(nil, &c.machines), \"machine\", \"one or more machine ids\")\n\tf.Var(cmd.NewStringsValue(nil, &c.machines), \"m\", \"\")\n\tf.StringVar(&c.envName, \"e\", \"local\", \"Juju environment\")\n\tf.StringVar(&c.envName, \"environment\", \"local\", \"\")\n}\n```\n\nHere we are providing a ***--description*** argument to satisfy a [Juju plugin requirement](https://github.com/juju/plugins#plugin-requirements). In addition a target argument **-m/--machine MACHINEID** and the ability to define which juju environment to execute this in **-e/--environment** defaults to **local** environment.\n\n### Init function\n\nHere we'll parse the cli arguments, do some basic sanity checking to make sure the passed arguments validate to our liking.\n\n```go\nfunc (c *LYAPluginCommand) Init(args []string) error {\n\tif c.description {\n\t\tfmt.Println(doc)\n\t\tos.Exit(0)\n\t}\n\tif len(args) == 0 {\n\t\treturn fmt.Errorf(\"no commands specified\")\n\t}\n\tif c.envName == \"\" {\n\t\treturn fmt.Errorf(\"Juju environment must be specified.\")\n\t}\n\tc.commands, args = args[0], args[1:]\n\tif len(c.machines) == 0 {\n\t\treturn fmt.Errorf(\"You must specify a target with --machine, -m\")\n\t}\n\n\tfor _, machineId := range c.machines {\n\t\tif !names.IsValidMachine(machineId) {\n\t\t\treturn fmt.Errorf(\"(%s) not a valid machine id.\", machineId)\n\t\t}\n\t}\n\treturn cmd.CheckEmpty(args)\n}\n```\n\nNotice the **names.IsValidMachine(machineId)** which was imported above as this is the only place where we make use of that\nparticular package.\n\n### Run function\n\nTo the heart of the command where the execution based on the cli arguments take place. I'll describe inline what is happening:\n\n```go\nfunc (c *LYAPluginCommand) Run(ctx *cmd.Context) error {\n\tc.SetEnvName(c.envName)\n```\nSet the environment name pulled from our arguments list so we known which environment to run our command against.\n\n```go\n\tclient, err := c.NewAPIClient()\n\tif err != nil {\n\t\treturn fmt.Errorf(\"Failed to load api client: %s\", err)\n\t}\n\tdefer client.Close()\n```\n\nGrab the api client for the current environment.\n\n```go\n\tvar runResults []params.RunResult\n\n\tlogger.Infof(\"Running cmd: %s on machine: %s\", c.commands, c.machines[0])\n\tparams := params.RunParams{\n\t\tCommands: c.commands,\n\t\tTimeout:  c.timeout,\n\t\tMachines: c.machines,\n\t\tServices: c.services,\n\t\tUnits:    c.units,\n\t}\n```\n\nPrepare the **RunParams** for passing to the api's **Run** function.\n\n```go\n\trunResults, err = client.Run(params)\n\tif err != nil {\n\t\tfmt.Errorf(\"An error occurred: %s\", err)\n\t}\n\tif len(runResults) == 1 {\n\t\tresult := runResults[0]\n\t\tlogger.Infof(\"Result: out(%s), err(%s), code(%d)\", result.Stdout, result.Stderr, result.Code)\n\t}\n\treturn nil\n}\n```\n\nExecute the api **Run** function and return the results from the executed command on the machine.\n\n### Entrypoint\n\nThe last bit of code is our **main** function which ties everything together.\n\n```go\nfunc main() {\n\tloggo.ConfigureLoggers(\"<root>=INFO\")\n\terr := juju.InitJujuHome()\n```\n\nInitialize the Juju environment based on the default paths or if **$JUJU_HOME** is defined.\n\n```go\n\tif err != nil {\n\t\tpanic(err)\n\t}\n\n\tctx, err := cmd.DefaultContext()\n\tif err != nil {\n\t\tpanic(err)\n\t}\n```\n\nSet the proper command context\n\n```\n\tc := &LYAPluginCommand{}\n\tcmd.Main(c, ctx, os.Args[1:])\n}\n```\nPass our plugin type/command into the supplied command Context and off you go.\n\n# Finish\n\nWith the code written, build and run the command.\n\n```\n$ go build -o juju-lyaplugin -v main.go\n```\n\nPlace the executable somewhere in your **$PATH**\n```\n$ mv juju-lyaplugin ~/bin\n```\n\nSee if Juju picks it up\n\n```\n$ juju help lyaplugin\nusage: lyaplugin [options] <commands>\npurpose: Run a command on remote target\n\noptions:\n--description  (= false)\n    Plugin Description\n-e, --environment (= \"local\")\n    Juju environment\n-m, --machine  (= )\n\n\nRun a command on target machine(s)\n\nThis example plugin mimics what \"juju run\" does.\n\neg.\n\njuju lyaplugin -m 1 -e local \"touch /tmp/testfile\"\n```\n\nSee it in your list of plugins, requires [juju-plugins](https://github.com/juju/plugins) to be installed:\n\n```\n$ juju help plugins\nJuju Plugins\n\nPlugins are implemented as stand-alone executable files somewhere in the user's PATH.\nThe executable command must be of the format juju-<plugin name>.\n\n...\ngit-charm        Clone and keep up-to-date a git repository containing a Juju charm for easy source managing.\nkill             Destroy a juju object and reap the environment.\nlyaplugin        Run a command on target machine(s)\n...\n```\n\nThis should hopefully give you a better idea where to start when you decide to dive into writing a juju plugin :)\n\n[Full source code for juju-learnyouaplugin](https://github.com/battlemidget/juju-learnyouaplugin)\n",
      "date": "2015-04-22T18:52:00",
      "title": "Extending Juju, Plugin basics in Go",
      "tags": [
        "ubuntu",
        "juju"
      ],
      "author": "Adam Stokes",
      "path": "extending-juju-plugin-basics-in-go",
      "compiled": "<p>This is a quick introduction on extending Juju with plugins written in Go. What we&#39;ll cover:</p>\n<ul>\n<li>Setting up your Go environment</li>\n<li>Getting the Juju source code</li>\n<li>Writing a basic plugin named <strong>juju-lyaplugin</strong> short for (juju-learnyouaplugin)</li>\n<li>End result will be a plugin that closely resembles what <strong>juju run</strong> would do.</li>\n</ul>\n<h1 id=\"prerequisites\">Prerequisites</h1>\n<ul>\n<li>Running on Ubuntu 14.04 or above</li>\n<li>Go 1.2.1 or above (Article written using Go 1.2.1)</li>\n<li>A basic understanding of the Go language, package imports, etc.</li>\n</ul>\n<h1 id=\"setting-up-your-go-environment\">Setting up your Go environment</h1>\n<p>This is all a matter of preference but for the sake of this article we&#39;ll do it\nmy way :)</p>\n<h2 id=\"install-go\">Install Go</h2>\n<p>On Trusty and above:</p>\n<pre><code>sudo apt-<span class=\"hljs-keyword\">get</span> install golang\n</code></pre><h2 id=\"go-dependency-management\">Go dependency management</h2>\n<p>2 projects I use are:</p>\n<ul>\n<li><a href=\"https://github.com/pote/gpm\">https://github.com/pote/gpm</a> - Barebones dependency manager for Go</li>\n<li><a href=\"https://github.com/pote/gvp\">https://github.com/pote/gvp</a> - Go Versioning Packager</li>\n</ul>\n<h3 id=\"install\">Install</h3>\n<pre><code>$ <span class=\"hljs-keyword\">cd</span> /tmp &amp;&amp; git clone http<span class=\"hljs-variable\">s:</span>//github.<span class=\"hljs-keyword\">com</span>/pote/gvp.git &amp;&amp; <span class=\"hljs-keyword\">cd</span> gvp &amp;&amp; sudo ./configure &amp;&amp; sudo <span class=\"hljs-keyword\">make</span> install\n$ <span class=\"hljs-keyword\">cd</span> /tmp &amp;&amp; git clone http<span class=\"hljs-variable\">s:</span>//github.<span class=\"hljs-keyword\">com</span>/pote/gpm.git &amp;&amp; <span class=\"hljs-keyword\">cd</span> gpm &amp;&amp; sudo ./configure &amp;&amp; sudo <span class=\"hljs-keyword\">make</span> install\n</code></pre><p>Feel free to check out their project pages for additional uses.</p>\n<h2 id=\"create-your-project-directory\">Create your project directory</h2>\n<pre><code><span class=\"hljs-variable\">$ </span>mkdir ~<span class=\"hljs-regexp\">/Projects/juju</span>-learnyouaplugin\n<span class=\"hljs-variable\">$ </span>cd ~<span class=\"hljs-regexp\">/Projects/juju</span>-learnyouaplugin\n</code></pre><h2 id=\"setup-the-project-specific-go-paths\">Setup the project specific Go paths</h2>\n<pre><code>$ <span class=\"hljs-built_in\">source</span> gvp <span class=\"hljs-keyword\">in</span>\n</code></pre><p>This will setup your <strong>$GOPATH</strong> and <strong>$GOBIN</strong> variables for use when resolving imports, compiling, etc.</p>\n<pre><code>$ echo $GOPATH\n<span class=\"hljs-regexp\">/home/</span>adam<span class=\"hljs-regexp\">/Projects/</span>juju-learnyouaplugin/.godeps\n$ echo $GOBIN\n<span class=\"hljs-regexp\">/home/</span>adam<span class=\"hljs-regexp\">/Projects/</span>juju-learnyouaplugin<span class=\"hljs-regexp\">/.godeps/</span>bin\n</code></pre><p>From this point on all package dependencies will be stored in the project&#39;s <strong>.godeps</strong> directory.</p>\n<h1 id=\"get-the-juju-code\">Get the Juju code</h1>\n<p>From your project&#39;s directory run:</p>\n<pre><code>$ <span class=\"hljs-keyword\">go</span> <span class=\"hljs-built_in\">get</span> -<span class=\"hljs-keyword\">d</span> -<span class=\"hljs-keyword\">v</span> github.<span class=\"hljs-keyword\">com</span>/juju/juju/...\n</code></pre><h1 id=\"writing-the-plugin\">Writing the plugin</h1>\n<p>Now that all the preparatory tasks are complete we can begin the fun\nstuff. Using your favorite editor open up a new file <strong>main.go</strong>. Within this file we need to define a few\npackage imports that are necessary for the plugin.</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-preprocessor\"><span class=\"hljs-keyword\">import</span> (</span>\n    <span class=\"hljs-string\">\"fmt\"</span>\n    <span class=\"hljs-string\">\"github.com/juju/cmd\"</span>\n    <span class=\"hljs-string\">\"github.com/juju/juju/apiserver/params\"</span>\n    <span class=\"hljs-string\">\"github.com/juju/juju/cmd/envcmd\"</span>\n    <span class=\"hljs-string\">\"github.com/juju/juju/juju\"</span>\n    <span class=\"hljs-string\">\"github.com/juju/loggo\"</span>\n    <span class=\"hljs-string\">\"github.com/juju/names\"</span>\n    <span class=\"hljs-string\">\"launchpad.net/gnuflag\"</span>\n    <span class=\"hljs-string\">\"os\"</span>\n    <span class=\"hljs-string\">\"time\"</span>\n\n    _ <span class=\"hljs-string\">\"github.com/juju/juju/provider/all\"</span>\n)\n</code></pre>\n<p>Let&#39;s go through the imports and list why they are required.</p>\n<ul>\n<li><strong>github.com/juju/cmd</strong> - This import gives us access to the run context of a command <strong><em><a href=\"https://godoc.org/github.com/juju/cmd#Context\">DefaultContext</a></em></strong></li>\n<li><strong>github.com/juju/juju/cmd/envcmd</strong> - Provides <strong><em><a href=\"https://godoc.org/github.com/juju/juju/cmd/envcmd#EnvCommandBase\">EnvCommandBase</a></em></strong> for creating new commands and giving us access to the\n<a href=\"https://godoc.org/github.com/juju/juju/cmd/envcmd#EnvCommandBase.NewAPIClient\">API Client</a> for making queries against the Juju state server.</li>\n<li><strong>github.com/juju/juju/apiserver/params</strong> - Provides access to 2 types <a href=\"https://godoc.org/github.com/juju/juju/apiserver/params#RunParams\">RunParams</a> and <a href=\"https://godoc.org/github.com/juju/juju/apiserver/params#RunResult\">RunResults</a> for executing the api call to <a href=\"https://godoc.org/github.com/juju/juju/api#Client.Run\">Run</a> and return the executed results.</li>\n<li><strong>github.com/juju/juju/juju</strong> - Provides access to <strong><em><a href=\"https://godoc.org/github.com/juju/juju/juju#InitJujuHome\">InitJujuHome</a></em></strong> for initializing the necessary bits like charm cache and environment. Required before running any juju cli command.</li>\n<li><strong>github.com/juju/loggo</strong> - Provides access to juju&#39;s logging api</li>\n<li><strong>github.com/juju/names</strong> - This package provides some convenience functions in particular we&#39;ll use <strong><em><a href=\"https://godoc.org/github.com/juju/names#IsValidMachine\">IsValidMachine</a></em></strong></li>\n<li><strong>launchpad.net/gnuflag</strong> - Provides the interface for our command definition like setting arguments, usage information, and execution.</li>\n<li><strong>github.com/juju/juju/provider/all</strong> - Registers all known providers (amazon, maas, local, etc)</li>\n</ul>\n<p>With that said let&#39;s spec out the plugin type. This will hold our embedded command base and cli arguments.</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">type</span> <span class=\"hljs-type\">LYAPluginCommand</span> <span class=\"hljs-keyword\">struct</span> {\n    envcmd.<span class=\"hljs-type\">EnvCommandBase</span>\n    out      cmd.<span class=\"hljs-type\">Output</span>\n    timeout  time.<span class=\"hljs-type\">Duration</span>\n    machines <span class=\"hljs-literal\">[]</span><span class=\"hljs-built_in\">string</span>\n    services <span class=\"hljs-literal\">[]</span><span class=\"hljs-built_in\">string</span>\n    units    <span class=\"hljs-literal\">[]</span><span class=\"hljs-built_in\">string</span>\n    commands <span class=\"hljs-built_in\">string</span>\n    envName <span class=\"hljs-built_in\">string</span>\n    description <span class=\"hljs-built_in\">bool</span>\n}\n</code></pre>\n<p>Once defined we can spec out our cli command and its functions.</p>\n<h3 id=\"the-info-function\">The info function</h3>\n<p>First part of the command is the <strong><em><a href=\"https://godoc.org/github.com/juju/cmd#SuperCommand.Info\">Info()</a></em></strong> function which returns\ninformation about the particular subcommand, in our case that is <strong>lyaplugin</strong></p>\n<pre><code class=\"lang-go\"><span class=\"hljs-keyword\">var</span> doc = `<span class=\"hljs-keyword\">Run</span> a command <span class=\"hljs-keyword\">on</span> target machine(s)\n\nThis example <span class=\"hljs-keyword\">plugin</span> mimics what <span class=\"hljs-string\">\"juju run\"</span> does.\n\neg.\n\njuju lyaplugin -<span class=\"hljs-keyword\">m</span> 1 -<span class=\"hljs-keyword\">e</span> <span class=\"hljs-keyword\">local</span> <span class=\"hljs-string\">\"touch /tmp/testfile\"</span>\n`\n\nfunc (c *LYAPluginCommand) Info() *cmd.Info {\n    <span class=\"hljs-keyword\">return</span> &amp;cmd.Info{\n        Name:    <span class=\"hljs-string\">\"lyaplugin\"</span>,\n        <span class=\"hljs-keyword\">Args</span>:    <span class=\"hljs-string\">\"&lt;commands&gt;\"</span>,\n        Purpose: <span class=\"hljs-string\">\"Run a command on remote target\"</span>,\n        Doc:     doc,\n    }\n}\n</code></pre>\n<h3 id=\"setflags-function\">SetFlags function</h3>\n<p>Next we&#39;ll define what arguments are available to this new subcommand (<strong>lyaplugin</strong>).</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-func\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(<span class=\"hljs-built_in\">c</span> *LYAPluginCommand)</span></span> <span class=\"hljs-type\">SetFlags</span>(f *gnuflag.<span class=\"hljs-type\">FlagSet</span>) {\n    f.<span class=\"hljs-type\">BoolVar</span>(&amp;<span class=\"hljs-built_in\">c</span>.description, <span class=\"hljs-string\">\"description\"</span>, <span class=\"hljs-built_in\">false</span>, <span class=\"hljs-string\">\"Plugin Description\"</span>)\n    f.<span class=\"hljs-type\">Var</span>(cmd.<span class=\"hljs-type\">NewStringsValue</span>(<span class=\"hljs-built_in\">nil</span>, &amp;<span class=\"hljs-built_in\">c</span>.machines), <span class=\"hljs-string\">\"machine\"</span>, <span class=\"hljs-string\">\"one or more machine ids\"</span>)\n    f.<span class=\"hljs-type\">Var</span>(cmd.<span class=\"hljs-type\">NewStringsValue</span>(<span class=\"hljs-built_in\">nil</span>, &amp;<span class=\"hljs-built_in\">c</span>.machines), <span class=\"hljs-string\">\"m\"</span>, <span class=\"hljs-string\">\"\"</span>)\n    f.<span class=\"hljs-type\">StringVar</span>(&amp;<span class=\"hljs-built_in\">c</span>.envName, <span class=\"hljs-string\">\"e\"</span>, <span class=\"hljs-string\">\"local\"</span>, <span class=\"hljs-string\">\"Juju environment\"</span>)\n    f.<span class=\"hljs-type\">StringVar</span>(&amp;<span class=\"hljs-built_in\">c</span>.envName, <span class=\"hljs-string\">\"environment\"</span>, <span class=\"hljs-string\">\"local\"</span>, <span class=\"hljs-string\">\"\"</span>)\n}\n</code></pre>\n<p>Here we are providing a <strong><em>--description</em></strong> argument to satisfy a <a href=\"https://github.com/juju/plugins#plugin-requirements\">Juju plugin requirement</a>. In addition a target argument <strong>-m/--machine MACHINEID</strong> and the ability to define which juju environment to execute this in <strong>-e/--environment</strong> defaults to <strong>local</strong> environment.</p>\n<h3 id=\"init-function\">Init function</h3>\n<p>Here we&#39;ll parse the cli arguments, do some basic sanity checking to make sure the passed arguments validate to our liking.</p>\n<pre><code class=\"lang-go\">func (c *LYAPluginCommand) Init(<span class=\"hljs-keyword\">args</span> []string) <span class=\"hljs-keyword\">error</span> {\n    <span class=\"hljs-keyword\">if</span> c.description {\n        fmt.Println(doc)\n        os.<span class=\"hljs-keyword\">Exit</span>(0)\n    }\n    <span class=\"hljs-keyword\">if</span> len(<span class=\"hljs-keyword\">args</span>) == 0 {\n        <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"no commands specified\"</span>)\n    }\n    <span class=\"hljs-keyword\">if</span> c.envName == <span class=\"hljs-string\">\"\"</span> {\n        <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"Juju environment must be specified.\"</span>)\n    }\n    c.commands, <span class=\"hljs-keyword\">args</span> = <span class=\"hljs-keyword\">args</span>[0], <span class=\"hljs-keyword\">args</span>[1:]\n    <span class=\"hljs-keyword\">if</span> len(c.machines) == 0 {\n        <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"You must specify a target with --machine, -m\"</span>)\n    }\n\n    <span class=\"hljs-keyword\">for</span> _, machineId := <span class=\"hljs-keyword\">range</span> c.machines {\n        <span class=\"hljs-keyword\">if</span> !names.IsValidMachine(machineId) {\n            <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"(%s) not a valid machine id.\"</span>, machineId)\n        }\n    }\n    <span class=\"hljs-keyword\">return</span> cmd.CheckEmpty(<span class=\"hljs-keyword\">args</span>)\n}\n</code></pre>\n<p>Notice the <strong>names.IsValidMachine(machineId)</strong> which was imported above as this is the only place where we make use of that\nparticular package.</p>\n<h3 id=\"run-function\">Run function</h3>\n<p>To the heart of the command where the execution based on the cli arguments take place. I&#39;ll describe inline what is happening:</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-func\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-params\">(<span class=\"hljs-built_in\">c</span> *LYAPluginCommand)</span></span> <span class=\"hljs-type\">Run</span>(ctx *cmd.<span class=\"hljs-type\">Context</span>) error {\n    <span class=\"hljs-built_in\">c</span>.<span class=\"hljs-type\">SetEnvName</span>(<span class=\"hljs-built_in\">c</span>.envName)\n</code></pre>\n<p>Set the environment name pulled from our arguments list so we known which environment to run our command against.</p>\n<pre><code class=\"lang-go\">    client, <span class=\"hljs-keyword\">err</span> := c.NewAPIClient()\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">err</span> != nil {\n        <span class=\"hljs-keyword\">return</span> fmt.Errorf(<span class=\"hljs-string\">\"Failed to load api client: %s\"</span>, <span class=\"hljs-keyword\">err</span>)\n    }\n    defer client.<span class=\"hljs-keyword\">Close</span>()\n</code></pre>\n<p>Grab the api client for the current environment.</p>\n<pre><code class=\"lang-go\">    <span class=\"hljs-keyword\">var</span> runResults []params.<span class=\"hljs-type\">RunResult</span>\n\n    logger.<span class=\"hljs-type\">Infof</span>(<span class=\"hljs-string\">\"Running cmd: %s on machine: %s\"</span>, <span class=\"hljs-built_in\">c</span>.commands, <span class=\"hljs-built_in\">c</span>.machines[<span class=\"hljs-number\">0</span>])\n    params := params.<span class=\"hljs-type\">RunParams</span>{\n        <span class=\"hljs-type\">Commands</span>: <span class=\"hljs-built_in\">c</span>.commands,\n        <span class=\"hljs-type\">Timeout</span>:  <span class=\"hljs-built_in\">c</span>.timeout,\n        <span class=\"hljs-type\">Machines</span>: <span class=\"hljs-built_in\">c</span>.machines,\n        <span class=\"hljs-type\">Services</span>: <span class=\"hljs-built_in\">c</span>.services,\n        <span class=\"hljs-type\">Units</span>:    <span class=\"hljs-built_in\">c</span>.units,\n    }\n</code></pre>\n<p>Prepare the <strong>RunParams</strong> for passing to the api&#39;s <strong>Run</strong> function.</p>\n<pre><code class=\"lang-go\">    runResults, err = client.<span class=\"hljs-type\">Run</span>(params)\n    <span class=\"hljs-keyword\">if</span> err != <span class=\"hljs-keyword\">nil</span> {\n        fmt.<span class=\"hljs-type\">Errorf</span>(<span class=\"hljs-string\">\"An error occurred: %s\"</span>, err)\n    }\n    <span class=\"hljs-keyword\">if</span> len(runResults) == <span class=\"hljs-number\">1</span> {\n        <span class=\"hljs-literal\">result</span> := runResults[<span class=\"hljs-number\">0</span>]\n        logger.<span class=\"hljs-type\">Infof</span>(<span class=\"hljs-string\">\"Result: out(%s), err(%s), code(%d)\"</span>, <span class=\"hljs-literal\">result</span>.<span class=\"hljs-type\">Stdout</span>, <span class=\"hljs-literal\">result</span>.<span class=\"hljs-type\">Stderr</span>, <span class=\"hljs-literal\">result</span>.<span class=\"hljs-type\">Code</span>)\n    }\n    <span class=\"hljs-keyword\">return</span> <span class=\"hljs-keyword\">nil</span>\n}\n</code></pre>\n<p>Execute the api <strong>Run</strong> function and return the results from the executed command on the machine.</p>\n<h3 id=\"entrypoint\">Entrypoint</h3>\n<p>The last bit of code is our <strong>main</strong> function which ties everything together.</p>\n<pre><code class=\"lang-go\"><span class=\"hljs-func\"><span class=\"hljs-keyword\">func</span> <span class=\"hljs-title\">main</span><span class=\"hljs-params\">()</span></span> {\n    loggo.<span class=\"hljs-type\">ConfigureLoggers</span>(<span class=\"hljs-string\">\"&lt;root&gt;=INFO\"</span>)\n    err := juju.<span class=\"hljs-type\">InitJujuHome</span>()\n</code></pre>\n<p>Initialize the Juju environment based on the default paths or if <strong>$JUJU_HOME</strong> is defined.</p>\n<pre><code class=\"lang-go\">    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">err</span> != nil {\n        panic(<span class=\"hljs-keyword\">err</span>)\n    }\n\n    ctx, <span class=\"hljs-keyword\">err</span> := cmd.DefaultContext()\n    <span class=\"hljs-keyword\">if</span> <span class=\"hljs-keyword\">err</span> != nil {\n        panic(<span class=\"hljs-keyword\">err</span>)\n    }\n</code></pre>\n<p>Set the proper command context</p>\n<pre><code>    <span class=\"hljs-rule\"><span class=\"hljs-attribute\">c </span>:<span class=\"hljs-value\">= &amp;LYAPluginCommand{}\n    cmd.<span class=\"hljs-function\">Main</span>(c, ctx, os.Args[<span class=\"hljs-number\">1</span>:])\n}</span></span>\n</code></pre><p>Pass our plugin type/command into the supplied command Context and off you go.</p>\n<h1 id=\"finish\">Finish</h1>\n<p>With the code written, build and run the command.</p>\n<pre><code>$ <span class=\"hljs-keyword\">go</span> build -o juju-lyaplugin -v main.<span class=\"hljs-keyword\">go</span>\n</code></pre><p>Place the executable somewhere in your <strong>$PATH</strong></p>\n<pre><code><span class=\"hljs-variable\">$ </span>mv juju-lyaplugin ~<span class=\"hljs-regexp\">/bin</span>\n</code></pre><p>See if Juju picks it up</p>\n<pre><code>$ juju <span class=\"hljs-keyword\">help</span> lyaplugin\nusage: lyaplugin [options] &lt;commands&gt;\npurpose: <span class=\"hljs-keyword\">Run</span> a command <span class=\"hljs-keyword\">on</span> remote target\n\noptions:\n--description  (= false)\n    <span class=\"hljs-keyword\">Plugin</span> Description\n-<span class=\"hljs-keyword\">e</span>, --environment (= <span class=\"hljs-string\">\"local\"</span>)\n    Juju environment\n-<span class=\"hljs-keyword\">m</span>, --machine  (= )\n\n\n<span class=\"hljs-keyword\">Run</span> a command <span class=\"hljs-keyword\">on</span> target machine(s)\n\nThis example <span class=\"hljs-keyword\">plugin</span> mimics what <span class=\"hljs-string\">\"juju run\"</span> does.\n\neg.\n\njuju lyaplugin -<span class=\"hljs-keyword\">m</span> 1 -<span class=\"hljs-keyword\">e</span> <span class=\"hljs-keyword\">local</span> <span class=\"hljs-string\">\"touch /tmp/testfile\"</span>\n</code></pre><p>See it in your list of plugins, requires <a href=\"https://github.com/juju/plugins\">juju-plugins</a> to be installed:</p>\n<pre><code>$ juju help plugins\nJuju Plugins\n\nPlugins are implemented <span class=\"hljs-keyword\">as</span> stand-alone executable files somewhere <span class=\"hljs-keyword\">in</span> <span class=\"hljs-keyword\">the</span> user's PATH.\nThe executable command must be <span class=\"hljs-keyword\">of</span> <span class=\"hljs-keyword\">the</span> format juju-&lt;plugin <span class=\"hljs-property\">name</span>&gt;.\n\n...\ngit-charm        Clone <span class=\"hljs-keyword\">and</span> keep up-<span class=\"hljs-keyword\">to</span>-<span class=\"hljs-type\">date</span> a git repository containing a Juju charm <span class=\"hljs-keyword\">for</span> easy source managing.\nkill             Destroy a juju object <span class=\"hljs-keyword\">and</span> reap <span class=\"hljs-keyword\">the</span> environment.\nlyaplugin        Run a command <span class=\"hljs-function_start\"><span class=\"hljs-keyword\">on</span></span> target machine(s)\n...\n</code></pre><p>This should hopefully give you a better idea where to start when you decide to dive into writing a juju plugin :)</p>\n<p><a href=\"https://github.com/battlemidget/juju-learnyouaplugin\">Full source code for juju-learnyouaplugin</a></p>\n"
    }
  ]
}